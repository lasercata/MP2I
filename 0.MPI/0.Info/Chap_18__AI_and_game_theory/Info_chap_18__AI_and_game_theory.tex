\documentclass[a4paper, 12pt, twoside]{article}


%------------------------------------------------------------------------
%
% Author                :   Lasercata
% Last modification     :   2023.03.16
%
%------------------------------------------------------------------------


%------ini
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
%\usepackage[english]{babel}


%------geometry
\usepackage[textheight=700pt, textwidth=500pt]{geometry}


%------color
\usepackage{xcolor}
\definecolor{ff4500}{HTML}{ff4500}
\definecolor{00b9ff}{HTML}{00b9ff}
\definecolor{00f}{HTML}{0000ff}
\definecolor{0ff}{HTML}{00ffff}
\definecolor{656565}{HTML}{656565}

%\renewcommand{\emph}{\textcolor{ff4500}}
%\renewcommand{\em}{\color{ff4500}}

\newcommand{\Emph}{\textcolor{ff4500}}

\newcommand{\strong}[1]{\textcolor{ff4500}{\bf #1}}
\newcommand{\st}{\color{ff4500}\bf}


%------Code highlighting
%---listings
\usepackage{listings}

\definecolor{cbg}{HTML}{272822}
\definecolor{cfg}{HTML}{ececec}
\definecolor{ccomment}{HTML}{686c58}
\definecolor{ckw}{HTML}{f92672}
\definecolor{cstring}{HTML}{e6db72}
\definecolor{cstringlight}{HTML}{98980f}
\definecolor{lightwhite}{HTML}{fafafa}

\lstdefinestyle{DarkCodeStyle}{
    backgroundcolor=\color{cbg},
    commentstyle=\itshape\color{ccomment},
    keywordstyle=\color{ckw},
    numberstyle=\tiny\color{cbg},
    stringstyle=\color{cstring},
    basicstyle=\ttfamily\footnotesize\color{cfg},
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=4,
    xleftmargin=\leftskip
}

\lstdefinestyle{LightCodeStyle}{
    backgroundcolor=\color{lightwhite},
    commentstyle=\itshape\color{ccomment},
    keywordstyle=\color{ckw},
    numberstyle=\tiny\color{cbg},
    stringstyle=\color{cstringlight},
    basicstyle=\ttfamily\footnotesize\color{cbg},
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=10pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=4,
    frame=L,
    xleftmargin=\leftskip
}

%\lstset{style=DarkCodeStyle}
\lstset{style=LightCodeStyle}
%Usage : \begin{lstlisting}[language=Caml, xleftmargin=xpt] ... \end{lstlisting}


%---Algorithm
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\SetKwInput{KwInput}{Input}
\SetKwInput{KwOutput}{Output}

\SetKwProg{Fn}{Function}{:}{}
\SetKw{KwPrint}{Print}

\newcommand\commfont[1]{\textit{\texttt{\textcolor{656565}{#1}}}}
\SetCommentSty{commfont}
\SetProgSty{texttt}
\SetArgSty{textnormal}
\SetFuncArgSty{textnormal}
%\SetProgArgSty{texttt}

\newenvironment{indalgo}[2][H]{
    \begin{algoBox}
        \begin{algorithm}[#1]
            \caption{#2}
}
{
        \end{algorithm}
    \end{algoBox}
}


%---tcolorbox
\usepackage[many]{tcolorbox}
\DeclareTColorBox{emphBox}{O{black}O{lightwhite}}{
    breakable,
    outer arc=0pt,
    arc=0pt,
    top=0pt,
    toprule=-.5pt,
    right=0pt,
    rightrule=-.5pt,
    bottom=0pt,
    bottomrule=-.5pt,
    colframe=#1,
    colback=#2,
    enlarge left by=10pt,
    width=\linewidth-\leftskip-10pt,
}

\DeclareTColorBox{algoBox}{O{black}O{lightwhite}}{
    breakable,
    arc=0pt,
    top=0pt,
    toprule=-.5pt,
    right=0pt,
    rightrule=-.5pt,
    bottom=0pt,
    bottomrule=-.5pt,
    left=0pt,
    leftrule=-.5pt,
    colframe=#1,
    colback=#2,
    width=\linewidth-\leftskip-10pt,
}


%-------make the table of content clickable
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}


%------pictures
\usepackage{graphicx}
%\usepackage{wrapfig}

\usepackage{tikz}
%\usetikzlibrary{babel}             %Uncomment this to use circuitikz
%\usetikzlibrary{shapes.geometric}  % To draw triangles in trees
%\usepackage{circuitikz}            %Electrical circuits drawing
\usetikzlibrary{patterns}


%------tabular
%\usepackage{color}
%\usepackage{colortbl}
%\usepackage{multirow}


%------Physics
%---Packages
%\usepackage[version=4]{mhchem} %$\ce{NO4^2-}$

%---Commands
\newcommand{\link}[2]{\mathrm{#1} \! - \! \mathrm{#2}}
\newcommand{\pt}[1]{\cdot 10^{#1}} % Power of ten
\newcommand{\dt}[2][t]{\dfrac{\mathrm d #2}{\mathrm d #1}} % Derivative


%------math
%---Packages
%\usepackage{textcomp}
%\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools} % For abs
\usepackage{stmaryrd} %for \llbracket and \rrbracket
\usepackage{mathrsfs} %for \mathscr{x} (different from \mathcal{x})

%---Commands
%-Sets
\newcommand{\N}{\mathbb{N}} %set N
\newcommand{\Z}{\mathbb{Z}} %set Z
\newcommand{\Q}{\mathbb{Q}} %set Q
\newcommand{\R}{\mathbb{R}} %set R
\newcommand{\C}{\mathbb{C}} %set C
\newcommand{\U}{\mathbb{U}} %set U
\newcommand{\seg}[2]{\left[ #1\ ;\ #2 \right]}
\newcommand{\nset}[2]{\left\llbracket #1\ ;\ #2 \right\rrbracket}

%-Exponantial / complexs
\newcommand{\e}{\mathrm{e}}
\newcommand{\cj}[1]{\overline{#1}} %overline for the conjugate.

%-Vectors
\newcommand{\vect}{\overrightarrow}
\newcommand{\veco}[3]{\displaystyle \vect{#1}\binom{#2}{#3}} %vector + coord

%-Limits
\newcommand{\lm}[2][{}]{\lim\limits_{\substack{#2 \\ #1}}} %$\lm{x \to a} f$ or $\lm[x < a]{x \to a} f$
\newcommand{\Lm}[3][{}]{\lm[#1]{#2} \left( #3 \right)} %$\Lm{x \to a}{f}$ or $\Lm[x < a]{x \to a}{f}$
\newcommand{\tendsto}[1]{\xrightarrow[#1]{}}

%-Integral
\newcommand{\dint}[4][x]{\displaystyle \int_{#2}^{#3} #4 \mathrm{d} #1} %$\dint{a}{b}{f(x)}$ or $\dint[t]{a}{b}{f(t)}$

%-left right
\newcommand{\lr}[1]{\left( #1 \right)}
\newcommand{\lrb}[1]{\left[ #1 \right]}
\newcommand{\lrbb}[1]{\left\llbracket #1 \right\rrbracket}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\lrangle}[1]{\left\langle #1 \right\rangle}

%-Others
\newcommand{\para}{\ /\!/\ } %//
\newcommand{\ssi}{\ \Leftrightarrow \ }
\newcommand{\eqsys}[2]{\begin{cases} #1 \\ #2 \end{cases}}

\newcommand{\med}[2]{\mathrm{med} \left[ #1\ ;\ #2 \right]}  %$\med{A}{B} -> med[A ; B]$
\newcommand{\Circ}[2]{\mathscr{C}_{#1, #2}}

\renewcommand{\le}{\leqslant}
\renewcommand{\ge}{\geqslant}

\newcommand{\oboxed}[1]{\textcolor{ff4500}{\boxed{\textcolor{black}{#1}}}} %orange boxed

\newcommand{\rboxed}[1]{\begin{array}{|c} \hline #1 \\ \hline \end{array}} %boxed with right opened
\newcommand{\lboxed}[1]{\begin{array}{c|} \hline #1 \\ \hline \end{array}} %boxed with left opened

\newcommand{\orboxed}[1]{\textcolor{ff4500}{\rboxed{\textcolor{black}{#1}}}} %orange right boxed
\newcommand{\olboxed}[1]{\textcolor{ff4500}{\lboxed{\textcolor{black}{#1}}}} %orange left boxed


%------commands
%---to quote
\newcommand{\simplecit}[1]{\guillemotleft$\;$#1$\;$\guillemotright}
\newcommand{\cit}[1]{\simplecit{\textcolor{656565}{#1}}}
\newcommand{\quo}[1]{\cit{\it #1}}

%---to indent
\newcommand{\ind}[1][20pt]{\advance\leftskip + #1}
\newcommand{\deind}[1][20pt]{\advance\leftskip - #1}

%---to indent a text
\newcommand{\indented}[2][20pt]{\par \ind[#1] #2 \par \deind[#1]}
\newenvironment{indt}[2][20pt]{#2 \par \ind[#1]}{\par \deind} %Titled indented env

%---title
\newcommand{\thetitle}[2]{\begin{center}\textbf{{\LARGE \underline{\Emph{#1} :}} {\Large #2}}\end{center}}

%---Maths environments
%-Proofs
\newenvironment{proof}[1][{}]{\begin{indt}{$\square$ #1}}{$\blacksquare$ \end{indt}}

%-Maths parts (proposition, definition, ...)
\newenvironment{mathpart}[1]{\begin{indt}{\boxed{\text{\textbf{#1}}}}}{\end{indt}}
\newenvironment{mathbox}[1]{\boxed{\text{\textbf{#1}}}\begin{emphBox}}{\end{emphBox}}
\newenvironment{mathul}[1]{\begin{indt}{\underline{\textbf{#1}}}}{\end{indt}}

\newenvironment{theo}{\begin{mathpart}{Théorème}}{\end{mathpart}}
\newenvironment{Theo}{\begin{mathbox}{Théorème}}{\end{mathbox}}

\newenvironment{prop}{\begin{mathpart}{Proposition}}{\end{mathpart}}
\newenvironment{Prop}{\begin{mathbox}{Proposition}}{\end{mathbox}}
\newenvironment{props}{\begin{mathpart}{Propriétés}}{\end{mathpart}}

\newenvironment{defi}{\begin{mathpart}{Définition}}{\end{mathpart}}
\newenvironment{meth}{\begin{mathpart}{Méthode}}{\end{mathpart}}

\newenvironment{Rq}{\begin{mathul}{Remarque :}}{\end{mathul}}
\newenvironment{Rqs}{\begin{mathul}{Remarques :}}{\end{mathul}}

\newenvironment{Ex}{\begin{mathul}{Exemple :}}{\end{mathul}}
\newenvironment{Exs}{\begin{mathul}{Exemples :}}{\end{mathul}}


%------Sections
% To change section numbering :
% \renewcommand\thesection{\Roman{section}}
% \renewcommand\thesubsection{\arabic{subsection})}
% \renewcommand\thesubsubsection{\textit \alph{subsubsection})}

% To start numbering from 0
% \setcounter{section}{-1}


%------page style
\usepackage{fancyhdr}
\usepackage{lastpage}

\setlength{\headheight}{18pt}
\setlength{\footskip}{50pt}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE, RO]{\textit{\textcolor{black}{\today}}}
\fancyhead[RE, LO]{\large{\textsl{\Emph{\texttt{\jobname}}}}}

\fancyfoot[RO, LE]{\textit{\texttt{\textcolor{black}{Page \thepage /}\pageref{LastPage}}}}
\fancyfoot[LO, RE]{\includegraphics[scale=0.12]{/home/lasercata/Pictures/1.images_profil/logo/mieux/lasercata_logo_fly_fond_blanc.png}}


%------init lengths
\setlength{\parindent}{0pt} %To avoid using \noindent everywhere.
\setlength{\parskip}{3pt}


%---------------------------------Begin Document
\begin{document}
    
    \thetitle{Chapitre 18}{Intelligence artificielle et théorie des jeux}
    
    \tableofcontents
    \listofalgorithms
    \newpage
    
    \begin{indt}{\section{Introduction}}
        L'expression \emph{intelligence artificielle} est une manière floue de désigner des algorithmes chargés comme tous les autres de résoudre des problèmes.
        Certains d'entre eux doivent jouer à des jeux, d'autres doivent répartir des données en plusieurs catégories (on parle de \emph{classification}) ou déterminer des valeurs numériques associées à des paramètres d'entrée (on parle de \emph{problème de régression}).
        Quelques traits communs à ces algorithmes sont l'usage d'heuristiques afin d'essayer d'obtenir des réponses les meilleures possibles en temps raisonnable et l'exploitation d'une grande quantité de données afin d'en construire une représentation (on parle de l'\emph{apprentissage d'un modèle de données}) qui sera exploité pour construire la réponse de l'algorithme.
        Dans ce chapitre, on se limite à l'étude des problèmes de classification et de la théorie des jeux.
    \end{indt}

    \vspace{12pt}
    
    \begin{indt}{\section{Apprentissage supervisé}}
        \begin{indt}{\subsection{Algorithme des $k$ plus proches voisins}}
            \begin{indt}{\subsubsection{Introduction}}
                \label{2.1.1}

                Pour résoudre un problème de classification, la méthode de l'apprentissage supervisé consiste à exploiter des données dont on connait déjà la classe afin de construire un algorithme de classification prenant les caractéristiques d'une donnée en entrée et renvoyant la classe à laquelle cette donnée appartient probablement.

                Les données manipulées sont en général représentées par des points de $\R^d$ ou $d$ est souvent grand.
                Par exemple, si on veut reconnaître des caractères manuscrits, l'algorithme peut prendre en entrée une image de $28 \times 28$ pixels en 256 niveaux de gris contenant un scan du caractère manuscrit à reconnaître, donc la donnée est représentée par un point de $\nset{0}{255}^d$, où $d = 28^2 = 784$.

                Si on veut répartir dans $C$ classes des données de $\R^d$, le problème consiste à construire un algorithme réalisant une fonction $\R^d \longrightarrow \nset 0 {C - 1}$ en exploitant une heuristique s'appuyant sur un ensemble de couples $(x, y) \in \R^d \times \nset 0 {C - 1}$, où $y$ est la classe de $x$, appelées données d'entrainement.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Algorithme des $k$ plus proches voisins}}
                Idée : il est possible que des données proches appartiennent à la même classe, donc on pourrait pour un point donné, renvoyer la classe du point déjà étiqueté le plus proche.

                Problème : la donnée d'entrainement la plus proche peut appartenir à une autre classe que celle du point, par example si les données d'entrainement sont mal réparties, ou bruitées, ou si le point considéré est proche de la frontière entre deux classes.

                \begin{center}
                    \begin{tikzpicture}[scale=2]
                        \draw (0, 0) rectangle (2, -1);
                        \draw[dashed] (1, .2) -- (1, -1.2);

                        \node (C0) at (.5, .2) {$C_0$};
                        \node (C1) at (1.5, .2) {$C_1$};

                        \node at (.3, -.3) [color=ff4500] {$\times$};
                        \node at (.6, -.8) [color=ff4500] {$\times$};

                        \node at (.8, -.5) [color=blue] {$\times$};

                        \node at (1.2, -.6) [color=ff4500] {$\times$};
                        \node at (1.6, -.3) [color=ff4500] {$\times$};
                        \node at (1.6, -.8) [color=ff4500] {$\times$};

                        \matrix [draw, below left, rounded corners=5pt] at (5, -.1) {
                            \node [color=ff4500, label=right:entraînement] {$\times$}; \\
                            \node [color=blue, label=right:point à classer] {$\times$}; \\
                        };
                    \end{tikzpicture}
                \end{center}

                \vspace{6pt}
                
                Pour éviter cet écueil, on considère plutôt la classe majoritaire parmi les classes des $k$ données d'entrainement les plus proches du point d'entrée, pour un $k$ fixé.

                On parle alors de l'algorithme des $k$--plus proches voisins ($k$NN pour $k$--\textit{nearest neighbors}).

                \begin{indt}{Variables d'ajustement :}
                    $-$ En cas d'égalité, il faut choisir une classe, par exemple au hasard parmi les classes majoritaires.

                    $-$ Le nombre $k$ de voisins : si $k$ est trop faible, l'algorithme sera trop sensible au bruit sur les données et si $k$ est trop grand, l'algorithme renverra surtout la classe majoritaire parmi les données d'entraînement, donc effectue une mauvaise généralisation.

                    $-$ La notion de distance : on utilise souvent la distance de \textsc{Minkowski}
                    \[
                        d(x, x') = \lr{\sum_{i = 1}^d \abs{x_i - x_i'}^p}^{\tfrac 1 p}
                    \]

                    qui donne la distance de \textsc{Manhattan} pour $p = 1$, et la distance euclidienne pour $p = 2$.
                    Le programme se limite à la distance euclidienne.
                \end{indt}

                Pour déterminer les $k$ plus proches voisins d'un point donné, on peut exploiter une file de priorité :

                \begin{indalgo}{$k$ plus proches voisins}
                    \KwInput{données d'entraînement $\lr{x_i, y_i}_{i \in \nset 1 N}$}
                    \KwInput{point à classer $x$}

                    \BlankLine

                    $F \gets$ file de priorité max vide\;

                    \For{$i$ de 1 à $k$}{
                        Insérer $i$ dans $F$ avec la priorité $d(x, x_i)$\;
                    }

                    \For{$i$ de $k + 1$ à $N$}{
                        \If{$d(x, x_i) < d(x, x_{\max F})$}{
                            Extraire le max de $F$\;
                            Insérer $i$ dans $F$ avec la priorité $d(x, x_i)$\;
                        }
                    }

                    $C \gets \set{C_i\ |\ i \in F}$\;

                    \Return un élément le plus fréquent de $C$\;
                \end{indalgo}

                Complexité : $\mathcal O(N\log k)$ en temps, et $\mathcal O(k)$ en espace.

                \vspace{12pt}
                
                Remarque : si on a beaucoup de points à classer, cet algorithme est peu efficace car il nécessite de parcourir l'intégralité des données pour chaque point à classer. On pourrait plutôt effectuer un prétraitement des données pour rendre plus efficace le calcul des $k$ plus proches voisins d'un point donné.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Arbres $k$--dimensionnels}}
                Attention : on ne parle pas du $k$ de $k$NN, mais plutôt de la dimension de l'espace des données ($d$ en \ref{2.1.1}, page \pageref{2.1.1}), mais c'est la lettre $k$ qui est utilisée dans la littérature.

                \vspace{12pt}
                
                $\bullet$ Définition : la structure d'arbre $k$--dimensionnel, ou arbre $k$-d, est une généralisation de la notion d'arbre binaire de recherche : un arbre binaire étiqueté par des éléments de $\R^k$ est un arbre $k$-d si et seulement si pour tout n\oe ud d'étiquette $x = (x_0, \ldots, x_{k - 1})$ de profondeur $i$,
                \[
                    \begin{array}{ll}
                        \forall x' = (x_0', \ldots, x_{k - 1}')\ \text{étiquette du sous-arbre gauche}, & x_j' \le x_j
                        \\
                        \forall x' = (x_0', \ldots, x_{k - 1}')\ \text{étiquette du sous-arbre droit}, & x_j' > x_j
                    \end{array}
                \]

                où $j = i \mod k$.

                \vspace{12pt}
                
                $\bullet$ Exemple en dimension 2 :

                \begin{center}
                    \begin{tikzpicture}[scale=1]
                        \draw[->] (0, 0) -- (9, 0);
                        \draw[->] (0, 0) -- (0, 9);

                        \node (x) at (9.3, -.5) {$x$};
                        \node (x) at (-.5, 9.3) {$y$};

                        \node (1) at (1, 2) [label=right:{$1$}] {$\times$};
                        \node (2) at (1, 5) [label=right:{$2$}] {$\times$};
                        \node (3) at (3, 3) [label=below:{$3$}] {$\times$};
                        \node (4) at (4, 7) [label=above left:{$4$}] {$\times$};
                        \node (5) at (5, 5) [label=left:{$5$}] {$\times$};
                        \node (6) at (6, 3) [label=above:{$6$}] {$\times$};
                        \node (7) at (7, 1.5) [label=left:{$7$}] {$\times$};
                        \node (8) at (8, 6.5) [label=left:{$8$}] {$\times$};

                        \draw[dashed] (0, 3) -- (8.5, 3);
                        \draw[dashed] (1, 0) -- (1, 8.5);
                        \draw[dashed] (5, 0) -- (5, 8.5);
                        \draw[dashed] (1, 7) -- (5, 7);
                        \draw[dashed] (7, 0) -- (7, 3);
                        \draw[dashed] (8, 3) -- (8, 8.5);
                %    \end{tikzpicture}
                %\end{center}

                %\begin{center}
                %    \begin{tikzpicture}
                        \node (5) at (12, 7) [circle, draw] {$5$}
                            child [xshift=-20pt] {node [circle, draw] {$3$}
                                child {node [circle, draw] {$1$}}
                                child {node [circle, draw] {$2$}
                                    child [xshift=20pt] {node [circle, draw] {$4$}}
                                }
                            }
                            child [xshift=20pt] {node [circle, draw] {$6$}
                                child {node [circle, draw] {$7$}}
                                child {node [circle, draw] {$8$}}
                            }
                        ;
                    \end{tikzpicture}
                \end{center}

                \vspace{12pt}
                
                $\bullet$ Remarque : dans cet exemple, on a fait en sorte de construire un arbre $k$-d équilibré en choisissant l'élément médian pour la coordonnée associée à la profondeur du n\oe ud comme étiquette.

                On écrit l'algorithme \texttt{créer\_arbre} suivant :

                \begin{indalgo}{\texttt{créer\_arbre}}
                    \SetKwFunction{creerarbre}{créer\_arbre}

                    \Fn{\creerarbre{$k$, $i$, $l$}}{
                        \KwInput{dimension $k$}
                        \KwInput{profondeur $i$}
                        \KwInput{liste de données $l$}

                        \BlankLine

                        \If{$l =$ \texttt{[]}}{
                            \Return l'arbre vide\;
                        }
                        \Else{
                            Extraire l'élément $x$ de $l$ médian pour la coordonnée $i \mod k$\;

                            $l_<,\ l_> \gets$ partition de $l$ suivant le pivot $x$\;

                            \Return \texttt{Noeud}($x$, \creerarbre{$k$, $i + 1$, $l_<$}, \creerarbre{$k$, $(i + 1)$, $l_>$})\;
                        }
                    }
                \end{indalgo}

                Complexité : à l'aide de l'algorithme de calcul de la médiane en temps linéaire (\textit{cf} chapitre 7, 2.2), la complexité est celle du tri rapide dans le meilleur cas, \textit{i.e} $\mathcal O(N\log N)$.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Recherche des $k$ plus proches voisins dans un arbre $k$-d}}
                Idée : pour trouver les $k$ plus proches voisins d'un point $x \in \R^d$ dans un arbre $k$-d $T$ de dimension $d$, on procède initialement comme pour la recherche de $x$ dans un ABR (en comparant la bonne coordonnée à chaque profondeur) puis on remonte dans l'arbre en sélectionnant les $k$ voisins, parfois en redescendant dans un sous-arbre que l'on avait ignoré.

                Exemple : on suppose être au niveau d'un n\oe ud d'étiquette $x'$ de profondeur $i$ et tel que $x_i > x_i'$.

                On cherche donc récursivement les $k$ voisins dans le sous-arbre droit.

                S'il y a moins de $k$ n\oe uds dans ce sous-arbre, il faudra considérer $x'$ comme voisin et peut-être aussi les n\oe uds du sous-arbre gauche.

                Même si l'appel récursif sélectionne $k$ voisins, on peut devoir considérer $x'$ ou les n\oe uds du sous-arbre gauche si $\abs{x_i - x_i'}$ est inférieure à la distance maximale entre $x$ et les voisins sélectionnés.

                Par exemple, si $k = 3, d = 2$, et $i$ correspond aux abscisses,

                \begin{center}
                    \begin{tikzpicture}[scale=.95]
                        \draw[->] (0, 0) -- (6.3, 0);
                        \draw[->] (0, 0) -- (0, 6.3);

                        \draw[dashed] (2, 0) -- (2, 6);

                        \node (xp) at (2, 6) [label=left:{$x'$}] {$\times$};

                        \node (x) at (3.6, 3.4) [label=right:{$x$}] {$\times$};
                        \draw (x) circle (2.5);

                        \node (vp) at (1.6, 3.2) [label=above:{$v'$}] {$\times$};
                        \node (v1) at (4.2, 4.7) [label=left:{$v_1$}] {$\times$};
                        \node (v2) at (3.1, 2) [label=right:{$v_2$}] {$\times$};
                        \node (v3) at (5.1, 1.4) [label=below right:{$v_3$}] {$+$};

                        \draw[<->] (x) to node [above right] {$d_{\max}$} (v3);
                        \draw[<->] (2.1, 3.4) to node [above] {\footnotesize{$\abs{x_i - x_i'}$}} (x);
                %    \end{tikzpicture}
                %\end{center}

                %\begin{center}
                %    \begin{tikzpicture}
                        \node (0) at (9, 5) [circle, draw] {$x'$}
                            child {node [circle, draw] {$v'$}}
                            child {node [circle, draw] {$v_2$}
                                child {node [circle, draw] {$v_3$}}
                                child {node [circle, draw] {$v_1$}}
                            }
                        ;
                    \end{tikzpicture}
                \end{center}

                D'où l'algorithme :
                \begin{indalgo}{\texttt{recherche\_voisins}, \texttt{visite}}
                    \SetKwFunction{recherchevoisins}{recherche\_voisins}
                    \SetKwFunction{visite}{visite}

                    \Fn{\recherchevoisins{$x$, $T$, $k$}}{
                        $F \gets$ file de priorité max vide\;
                        \visite{$F, x, T, 0, k$}\;

                        \Return les éléments de $F$\;
                    }

                    \BlankLine

                    \Fn{\visite{$F,\ x,\ T,\ i,\ k$}}{
                        \If{$T$ = \texttt{Noeud}($x', l, r$)}{
                            %$t_1, t_2 \gets$ si $x_i \le x_i'$, alors $(l, r)$, sinon $(r, l)$\;
                            \If{$x_i \le x_i'$}{
                                $t_1, t_2 \gets l, r$\;
                            }
                            \Else{
                                $t_1, t_2 \gets r, l$\;
                            }

                            \BlankLine

                            \visite{$F,\ x,\ t_1,\ i + 1 \mod d,\ k$}\;

                            \BlankLine

                            \If{$\abs F < k$ ou priorité $\max F \ge \abs{x_i - x_j}$}{
                                \If{$d(x, x') <$ priorité $\max F$}{
                                    Extraire $\max F$\;
                                    Insérer $x'$ dans $F$ avec la priorité $d(x, x')$\;
                                }

                                \visite{$F,\ x,\ t_2,\ i + 1 \mod d,\ k$}\;
                            }
                        }
                    }
                \end{indalgo}

                Dans le pire cas, on visite les $N$ n\oe uds de l'arbre (donc on n'a rien gagné par rapport au premier algorithme) mais le plus souvent on ne visite que de l'ordre de $\log N$ n\oe uds.
            \end{indt}
        \end{indt}

        \vspace{12pt}
        
        \begin{indt}{\subsection{Arbres de décision}}
            \begin{indt}{\subsubsection{Introduction}}
                Un arbre de décision est un outil permettant d'implémenter un algorithme de classification dont le fonctionnement est le suivant :
                étant donné un point à classer, on descend récursivement dans l'arbre en effectuant à chaque n\oe ud un test sur une coordonnée dont le résultat détermine la branche à parcourir.
                La feuille atteinte donne la classe du point.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Définition (\textit{arbre de décision})}}
                Un \emph{arbre décision} est un arbre étiqueté tel que les étiquettes des n\oe uds internes sont des coordonnées et celles des feuilles sont des classes, de telle sorte que les fils d'un n\oe ud donné correspond aux différentes valeurs possibles pour la coordonnée associée au n\oe ud.

                Si la coordonnée est \emph{catégorique}, \textit{i.e} ne peut prendre qu'un nombre fini de valeur, alors il y a autant de fils que de valeurs.
                Si la coordonnée est \emph{numérique}, les fils correspondent à des intervalles de valeurs disjoints.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Exemple}}
                Un étudiant veut savoir comment passer la soirée, sachant qu'il y a trois activités possibles : aller en soirée, étudier, ou se tourner les pouces.
                \begin{indt}{On représente les étudiants par des triplets dont les coordonnées sont :}
                    $-$ un booléen indiquant s'il y a une soirée organisée par son cercle d'amis ;

                    $-$ Un réel $> 0$ indiquant le nombre de jour avant la prochaine deadline (exemple : devoir) ;

                    $-$ Un booléen indiquant si l'étudiant est procrastinateur.
                \end{indt}

                On pourrait construire l'arbre suivant :
                \begin{center}
                    \begin{tikzpicture}
                        \node (0) at (0, 0) [rectangle, draw] {soirée}
                            child [xshift=-40pt] {node [rectangle, draw] {aller en soirée} edge from parent [above left] node {\textit{oui}}}
                            child [xshift=40pt, yshift=-20pt] {node [rectangle, draw] {deadline}
                                child [xshift=-60pt] {node [rectangle, draw] {étudier} edge from parent [above left] node {$> 1$}}
                                child [yshift=-20pt] {node [rectangle, draw] {procratistinateur}
                                    child [xshift=-30pt, yshift=-15pt] {node [rectangle, draw] {se tourner les pouces} edge from parent [above left] node {\textit{oui}}}
                                    child [xshift=30pt, yshift=-15pt] {node [rectangle, draw] {étudier} edge from parent [above right] node {\textit{non}}}
                                    edge from parent [right] node {$\in ]1 ; 7[$}
                                }
                                child [xshift=80pt] {node [rectangle, draw] {se tourner les pouces} edge from parent [above right] node {$> 7$}}
                                edge from parent [above right] node {\textit{non}}
                            }
                        ;
                    \end{tikzpicture}
                \end{center}

                L'étudiant $(V, 0.2, 5, F)$ va en soirée

                L'étudiant $(F, 4, V)$ va se tourner les pouces.

                \vspace{12pt}
                
                Remarque : dans le cadre de l'apprentissage supervisé, la question est de savoir comment construire un arbre de décision à partir de données étiquetées.
                Il faut donc  choisir la structure de l'arbre  et les tests effectués à chaque n\oe ud. Il est possible de construire un arbre qui classe parfaitement toutes les données d'entraînement ou alors de s'autoriser des erreurs pour tenir compte d'un éventuel bruit sur les données d'entraînement.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Entropie de \textsc{Shannon}}}
                $\bullet$ Idée : pour construire l'arbre de décision, une idée serait de placer en racine la coordonnée qui discrimine au mieux entre les différentes classes pour le jeu de données et de construire les sous-arbres récursivement.
                On utiliser pour cela la notion d'\emph{entropie de \textsc{Shannon}}, qui est une mesure de l'information contenue dans un jeu de données.

                \vspace{12pt}
                
                $\bullet$ Définition (\textit{entropie de \textsc{Shannon}}) :
                on considère un ensemble $S$ de $N$ données réparties dans $C$ classes $C_0, \ldots, C_{C - 1}$.

                L'entropie de \textsc{Shannon} de $S$ est la quantité
                \[
                    H(S) = -\sum_{i = 0}^{C - 1} \dfrac{\abs{C_i}}{N} \log_2 \dfrac{\abs{C_i}}{N}
                \]

                \vspace{12pt}
                
                $\bullet$ Remarque : L'entropie de \textsc{Shannon} est l'espérance du nombre de bits d'informations que l'on obtient en tirant aléatoirement uniformément un point de $S$.

                En effet, $\dfrac{\abs{C_i}} N$ est la probabilité d'obtenir un élément de la classe $C_i$, et $-\log_2 \dfrac{\abs{C_i}}N = \log_2 N - \log_2 \abs{C_i}$ est la différence entre le nombre de bits nécessaires pour représenter l'intégralité des données et le nombre de bits nécessaires pour distinguer entre elles les données de la classe $C_i$.
                C'est donc le nombre de bits qui reste afin de donner de l'information sur l'appartenance à la classe $C_i$.

                \begin{indt}{En particulier,}
                    $-$ Si $C = 1$, alors $H(S) = 0$ : la représentation des données sert uniquement à les distinguer entre elles et n'apporte aucune information sur la classe.
                    
                    $-$ L'entropie est maximale lorsque les données sont uniformément réparties $\left(\vphantom{\dfrac N C} \right.$\textit{i.e} quand $\left. \forall i \in \nset 0 {C - 1},\ \abs{C_i} = \dfrac N C \right)$.
                    Dans ce cas, $H(S) = \log_2 C$, et on obtient autant de bits que nécessaire pour distinguer les $C$ classes.
                \end{indt}

                \vspace{12pt}
                
                $\bullet$ Définition (\textit{gain d'un attribut}) :
                On considère un ensemble $S$ de $N$ données en dimension $d$, et une coordonnée (ou un attribut) $i \in \nset 1 d$ dont on note $m$ le nombre de valeurs possibles.

                Le \emph{gain} de l'attribut $i$ est la quantité
                \[
                    G(S, i) = H(S) - \sum_{j = 1}^m \dfrac{\abs{S_j}}{N} H(S_j)
                \]

                où $S_1, \ldots, S_m$ est la partition de $S$ suivant les valeurs de la coordonnée $i$.

                \vspace{12pt}
                
                $\bullet$ Remarque : le gain de l'attribut correspond à l'espérance de la perte d'entropie lorsque l'on fixe la valeur de l'attribut.
                \[
                    \begin{array}{rcl}
                        G(S, i)
                        &=& \displaystyle
                        H(S) - \sum_{j = 1}^m \dfrac{\abs{S_j}}{N} H(S_j)
                        \\
                        &=& \displaystyle
                        \sum_{j = 1}^m \dfrac{\abs{S_j}}{N} H(S)
                        - \sum_{j = 1}^m \dfrac{\abs{S_j}}{N} H(S_j)
                        \\
                        &=& \displaystyle
                        \sum_{j = 1}^m \dfrac{\abs{S_j}}{N} (H(S) - H(S_j))
                    \end{array}
                \]

                où $\dfrac{\abs{S_j}} N$ est la probabilité de tirer un point sont la coordonnée $i$ prend la $j$\textsuperscript{ème} valeur, et $H(S) - H(S_j)$ correspond à la différence entre l'entropie du jeu de données initial et l'entropie des données restantes après le choix de la $j$\textsuperscript{ème} valeur.

                \vspace{6pt}
                
                Plus un attribut est discriminant pour les classes, plus l'entropie des données restantes après le choix d'un valeur pour l'attribut doit être faible. On cherche donc à maximiser le gain de l'attribut.

                \vspace{12pt}
                
                $\bullet$ Proposition (Inégalité de \textsc{Gibls}) :
                \begin{emphBox}
                    Si $\lr{p_i}_{i \in \nset 0 {k - 1}}$, et $\lr{q_i}_{i \in \nset 0 {k - 1}}$ sont deux distributions de probabilité sur un ensemble de cardinal $k$, alors
                    \[
                        -\sum_{i = 0}^{k - 1} p_i \log_2(p_i)
                        \le
                        -\sum_{i = 0}^{k - 1} p_i \log_2(q_i)
                    \]
                \end{emphBox}

                \vspace{6pt}
                
                \begin{proof}
                    $\forall x \in \R^*_+,\ \ln(x) \le x - 1$ (concavité de $\ln$).

                    Donc
                    \[
                        \begin{array}{rcl}
                            \displaystyle
                            \sum_{i = 0}^{k - 1} p_i \ln\!\lr{\dfrac{q_i}{p_i}}
                            &\le& \displaystyle
                            \sum_{i = 0}^{k - 1} p_i \lr{\dfrac{q_i}{p_i} - 1}
                            \\
                            &=& \displaystyle
                            \sum_{i = 0}^{k - 1} (q_i - p_i)
                            \\
                            &=& 1 - 1 = 0
                        \end{array}
                    \]

                    Donc
                    \[
                        \sum_{i = 0}^{k - 1} p_i \ln q_i
                        \le
                        \sum_{i = 0}^{k - 1} p_i \ln p_i
                    \]

                    ce qui conclut car $\dfrac{-1}{\ln 2} < 0$.
                \end{proof}

                \vspace{12pt}
                
                $\bullet$ Corollaire :
                \begin{emphBox}
                    Si $S$ est un ensemble de $N$ données en dimension $d$ réparties dans les classes $C_0, \ldots, C_{C - 1}$, et si $i \in \nset 1 d$ est un attribut pouvant prendre une valeur, alors $G(S, i) \ge 0$.
                \end{emphBox}

                \vspace{6pt}
                
                \begin{proof}
                    \[
                        \begin{array}{rcl}
                            G(S, i)
                            &=& \displaystyle
                            H(S) - \sum_{j = 1}^m \dfrac{\abs{S_j}}{N} H(S_j)
                            \\
                            &=& \displaystyle
                            - \sum_{k = 0}^{C - 1} \dfrac{\abs{C_k}}{N} \log_2 \dfrac{\abs{C_k}}{N}
                            - \sum_{j = 1}^m \dfrac{\abs{S_j}}{N} \lr{
                                -\sum_{k = 0}^{C - 1} \dfrac{\abs{C_k \cap S_j}}{\abs{S_j}} \log_2 \dfrac{\abs{C_k \cap S_j}}{\abs{S_j}}
                            }
                            \\
                            &=& \displaystyle
                            -\sum_{k = 0}^{C - 1} \sum_{j = 1}^m \dfrac{\abs{C_k \cap S_j}}{N}\log_2 \dfrac{\abs{C_k}}{N}
                            - \lr{
                                -\sum_{j = 1}^m \sum_{k = 0}^{C - 1} \dfrac{\abs{C_k \cap S_j}}{N} \log_2 \dfrac{\abs{C_k \cap S_j}}{\abs{S_j}}
                            }
                        \end{array}
                    \]

                    Or
                    \[
                        \log_2 \dfrac{\abs{C_k \cap S_j}}{\abs{S_j}}
                        = \log_2 \dfrac{\abs{C_k \cap S_j}}{N}
                        - \log_2 \dfrac{\abs{S_j}}{N}
                    \]

                    Donc
                    \[
                        \begin{array}{rcl}
                            G(S, i)
                            &=&\displaystyle
                            - \sum_{k = 0}^{C - 1} \sum_{j = 1}^m \dfrac{\abs{C_i \cap S_j}}{N} \lr{\log_2 \dfrac{\abs{C_k}}{N} + \log_2 \dfrac{\abs{S_j}}{N}}
                            + \sum_{j = 1}^m \sum_{k = 0}^{C - 1} \dfrac{\abs{C_k \cap S_j}}{N} \log_2 \dfrac{\abs{C_k \cap S_j}}{N}
                        \end{array}
                    \]

                    On note $\displaystyle \lr{p_{j, k}}_{(j, k) \in \nset 1 n \times \nset 0 {C - 1}} = \lr{\dfrac{\abs{C_k \cap S_j}}{N}}_{j, k}$
                    et $\displaystyle \lr{q_{j, k}}_{j, k} = \lr{\dfrac{\abs{C_k} \abs{S_j}}{N^2}}_{j, k}$
                    et on remarque que $\lr{p_{j, k}}_{j, k}$ et $\lr{q_{j, k}}_{j, k}$ sont des distributions de probabilité, donc l'inégalité de \textsc{Gibls} donne :
                    \[
                        - \sum_{j, k} p_{j, k} \log_2 p_{j, k}
                        \le
                        - \sum_{j, k} p_{j, k}\log_2 q_{j, k}
                    \]

                    d'où $G(S, i) \ge 0$.
                \end{proof}
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Algorithme ID3}}
                $\bullet$ Principe : l'algorithme ID3 (pour \textit{Iterative Dichotomiser 3}) consiste à construire un arbre de décision en choisissant pour racine l'attribut de gain maximal et en construisant récursivement les sous-arbres en considérant comme jeu de données la partition des données selon la valeur de l'attribut choisi.

                \vspace{12pt}
                
                $\bullet$ Cas binaire : on énonce l'algorithme ID3 dans le cas où les attributs sont binaires.

                \begin{indalgo}{ID3, cas binaire}
                    \KwInput{L'ensemble $S$ des données}
                    \KwInput{L'ensemble $A$ des attributs que l'on s'autorise à utiliser dans les n\oe uds}

                    \BlankLine

                    \If{$S = \varnothing$}{
                        Construire une feuille contenant la classe la plus représentée parmi les données qui ont servi à construire son père\;
                    }
                    \ElseIf{tous les éléments de $S$ appartient à la même classe $C$}{
                        Construire une feuille contenant $C$\;
                    }
                    \ElseIf{$A = \varnothing$}{
                        Construire une feuille contenant la classe la plus représentée parmi les données de $S$\;
                    }
                    \Else{
                        $i \gets$ attribut de $A$ qui maximise $G(S, i)$\;

                        $S_0 \gets$ données de $S$ dont l'attribut $i$ vaut $0$\;
                        $S_1 \gets$ données de $S$ dont l'attribut $i$ vaut $1$\;

                        Construire le n\oe ud d'étiquette $i$, de sous-arbre gauche \texttt{ID3}($S_0, A \setminus \set i$), de sous-arbre droit \texttt{ID3}($S_1, A \setminus \set i$)\;
                    }
                \end{indalgo}

                \vspace{12pt}
                
                $\bullet$ Exemple :

                \begin{center}
                    \begin{tikzpicture}
                        \node (0) at (0, 0) [circle, draw] {$L$}
                            child [xshift=-20pt] {node [circle, draw] {$0$}}
                            child [xshift=20pt] {node [circle, draw] {$C$}
                                child [xshift=-20pt] {node [circle, draw] {$E$}
                                    child [xshift=-20pt] {node [circle, draw] {$F$}
                                        child {node [circle, draw] {$1$}}
                                        child {node [circle, draw] {$0$}}
                                    }
                                    child [xshift=20pt] {node [circle, draw] {$F$}
                                        child {node [circle, draw] {$0$}}
                                        child {node [circle, draw] {$1$}}
                                    }
                                }
                                child [xshift=20pt] {node [circle, draw] {$1$}}
                            }
                        ;
                        
                        \node (arr) at (-6, -3) {
                            \begin{tabular}{cccc|c}
                                \multicolumn{4}{c}{Attributs}
                                & Classe
                                \\
                                $E$ & $C$ & $F$ & $L$ & $R$
                                \\
                                \hline
                                1 & 1 & 1 & 1 & 1
                                \\
                                1 & 1 & 1 & 0 & 0
                                \\
                                1 & 1 & 0 & 1 & 1
                                \\
                                1 & 1 & 0 & 0 & 0
                                \\
                                1 & 0 & 1 & 1 & 1
                                \\
                                1 & 0 & 1 & 0 & 0
                                \\
                                1 & 0 & 0 & 1 & 0
                                \\
                                1 & 0 & 0 & 0 & 0
                                \\
                                0 & 0 & 1 & 1 & 0
                                \\
                                0 & 0 & 1 & 0 & 0
                                \\
                                0 & 0 & 0 & 1 & 1
                                \\
                                0 & 0 & 0 & 0 & 0
                            \end{tabular}
                        };
                    \end{tikzpicture}
                \end{center}
            \end{indt}
        \end{indt}

        \vspace{12pt}
        
        \begin{indt}{\subsection{Analyse des résultats}}
            \begin{indt}{\subsubsection{Introduction}}
                Les algorithmes d'apprentissage dépendent de paramètres (par exemple le nombre $k$ de voisins dans $k$NN ou une heuristique d'apprentissage d'arbres de décision telle qu'ID3) qu'il faut ajuster selon le cas d'application afin d'obtenir le meilleur classificateur possible.

                Choisir les meilleurs paramètres pour un algorithme d'apprentissage passe par l'essai de plusieurs valeurs de ces paramètres et par une évaluation du classificateur obtenu.

                On a donc besoin d'un moyen de mesurer els performances d'un classificateur.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Jeu d'entraînement, jeu de test}}
                Dans le cadre de l'apprentissage supervisé, on dispose de données étiquetées par le résultat attendu, donc il est possible d'évaluer les performances d'un classificateur en comparant le résultat qu'il renvoie et le résultat attendu sur chacune des données étiquettées.

                Cependant, il faut éviter d'utiliser les mêmes données pour l'apprentissage et pour les tests car l'algorithme est censé renvoyer de bons résultats sur les données d'entraînement. On n'aurait donc pas une bonne mesure de la capacité de l'algorithme à généraliser le modèle qu'il apprend.
                Il est alors d'usage de répartir les données en deux jeux : un jeu d'entraînement qui contient les données qui serviront à l'apprentissage, et un jeu de test qui contient les données qui serviront aux mesures de performance.

                Construire ces jeux de données est un enjeux majeur car de mauvais choix peuvent donner des résultats grossièrement faux. Par exemple, si on applique l'algorithme ID3 à un jeu d'entraînement dont toutes les données appartiennent à la même classe, l'arbre de décision obtenu est une feuille réduite à cette classe donc le classificateur est une fonction constante qui se trompera sur toutes les données d'autres classes.
                Disposer d'une grande quantité de données d'entraînement est aussi important.

                Les données sont en général réparties entre les deux jeux avec de l'ordre de 80\% de données d'entraînement et 20\% de données de test. Une manière de respecter la répartition des classes dans le jeu d'entraînement consiste à tirer les données d'entraînement avec un tirage aléatoire uniforme.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Sur-apprentissage / sous-apprentissage}}
                L'objectif de l'apprentissage est de deviner des règles implicites qui régissent la distribution des classes, à partir d'un jeu de données, et de généraliser ces règles pour construire un modèle permettant de déterminer la classe de données pour lesquelles on ne dispose pas d'information.
                Le sur-apprentissage consiste en une mauvaise généralisation liée à une trop grande précision sur le jeu d'entraînement.

                Par exemple, pour un algorithme de régression, si les données sont bruitées, il y a sur-apprentissage si la fonction produite par l'algorithme "colle" trop aux données d'entraînement et reproduit le bruit des données au lieu d'apprendre uniquement la tendance générale.

                Par exemple, il est toujours possible d'obtenir une erreur nulle sur les données d'entraînement par interpolation, mais cela ne garantit pas la qualité de la régression en dehors de ces données.

                %............................................................
                %\newline
                %\quo{Courbe quadratique avec des point approximant la courbe dont certains sont aberrants, et une courbe qui passe exactement par les point d'entraînement, mais qui ne représente pas bien la courbe.}
                %\newline
                %............................................................

                \begin{center}
                    \begin{tikzpicture}[domain=0:5]
                        \draw[->] (0, 0) to (6, 0);
                        \draw[->] (0, 0) to (0, 6);
                        
                        \draw [color=ff4500] plot (\x, {-.8 * (\x - 1) * (\x - 4) + 3.2});

                        %\node (1) at (0, 0) {$\times$};
                        %\node (2) at (.5, 1.8) {$\times$};
                        %\node (3) at (1, 3.2) {$\times$};
                        %\node (4) at (1.5, 4.2) {$\times$};
                        %\node (5) at (2.5, 5) {$\times$};
                        %\node (6) at (3.5, 4.2) {$\times$};
                        %\node (7) at (4, 3.2) {$\times$};
                        %\node (8) at (4.5, 1.8) {$\times$};
                        %\node (9) at (5, 0) {$\times$};

                        \node (1) at (0, 0) {$\times$};
                        \node (2) at (.4, 2.1) {$\times$};
                        \node (3) at (1, 2.8) {$\times$};
                        \node (4) at (1.5, 4.2) {$\times$};
                        \node (5) at (2.5, 5.5) {$\times$};
                        \node (6) at (3.4, 4.0) {$\times$};
                        \node (7) at (4.2, 3.3) {$\times$};
                        \node (8) at (4.4, 1.8) {$\times$};
                        \node (9) at (5, 0) {$\times$};

                        %\draw [color=blue] plot [smooth] coordinates {(1) (2) (.6, 1.8) (3) (1.20, 4.1) (4) (2, 4.3) (5) (2.9, 5.5) (6) (7) (4.25, 2.2) (8) (9)};
                        \draw [color=blue] plot [smooth] coordinates {(1) (2) (3) (4) (5) (6) (7) (8) (9)};
                    \end{tikzpicture}
                \end{center}

                Il y a sous-apprentissage lorsque l'algorithme ne tient pas assez compte des données d'entraînement et n'apprend donc pas assez de règles pour obtenir un bon résultat.

                Par exemple : régression linéaire sur les mêmes données.

                %............................................................
                %\newline
                %\quo{Même courbe quadratique, mais approximation aberrante avec une droite.}
                %\newline
                %............................................................

                \begin{center}
                    \begin{tikzpicture}[domain=0:5]
                        \draw[->] (0, 0) to (6, 0);
                        \draw[->] (0, 0) to (0, 6);
                        
                        \draw [color=ff4500] plot (\x, {-.8 * (\x - 1) * (\x - 4) + 3.2});
                        \node (1) at (0, 0) {$\times$};

                        \node (2) at (.4, 2.1) {$\times$};
                        \node (3) at (1, 2.8) {$\times$};
                        \node (4) at (1.5, 4.2) {$\times$};
                        \node (5) at (2.5, 5.5) {$\times$};
                        \node (6) at (3.4, 4.0) {$\times$};
                        \node (7) at (4.2, 3.3) {$\times$};
                        \node (8) at (4.4, 1.8) {$\times$};
                        \node (9) at (5, 0) {$\times$};

                        \draw[color=blue] (.3, 2.5) to (5, 4);
                    \end{tikzpicture}
                \end{center}

                Pour des algorithmes d'apprentissage qui ajustent leurs paramètres en cours d'apprentissage, il est alors nécessaire d'avoir un troisième jeu de données, appelé jeu de validation, qui sert à détecter le sur-apprentissage afin d'interrompre l'algorithme.
                Une répartition fréquente des données entre jeu d'entraînement, jeu de validation, et jeu de test est de l'ordre de 60\% / 20\% / 20\%.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Matrice de confusion}}
                $\bullet$ Remarque : les résultats obtenus par exécution du classificateur résultant de l'apprentissage sur les données du jeu de test permettent de calculer le taux d'erreur, \textit{i.e} le rapport entre le nombre de tests pour lesquels le résultat est faux et le nombre total de tests.

                Cependant, ce taux ne donne qu'une information partielle sur les performances de classification car il n'indique rien sur la nature des erreurs.
                Dans le cadre des problèmes de classification, la notion de \emph{matrice de confusion} permet d'effectuer une analyse plus poussée.

                \vspace{12pt}
                
                $\bullet$ Définition (\textit{matrice de confusion}) : on considère un problème de classification à $C$ classes $C_0, \ldots, C_{C - 1}$.

                La \emph{matrice de confusion} d'un classificateur pour un jeu de test donné est la matrice de taille $C \times C$ telle que $\forall i, j \in \nset 0 {C - 1}$, le coefficient $(i, j)$ de la matrice est le nombre de données de test appartenant à la classe $C_i$ pour lesquelles le classificateur a renvoyé la classe $C_j$.

                \vspace{12pt}
                
                $\bullet$ La matrice suivante pour un problème à trois classes :
                \[
                    \begin{pmatrix}
                        6 & 0 & 2
                        \\
                        0 & 5 & 0
                        \\
                        1 & 1 & 5
                    \end{pmatrix}
                \]

                Les réponses correctes sont situées la diagonale donc le taux d'erreur est la somme des valeurs qui ne sont pas sur la diagonale divisée par la somme de toutes les valeurs.
                Ici : $\dfrac{4}{20} = \dfrac 1 5$, soit $20\%$.

                \begin{indt}{La matrice indique également :}
                    $-$ que le classificateur ne se trompe jamais sur les données de la classe $C_1$ ;

                    $-$ que lorsque le classificateur se trompe sur une donnée de la classe $C_0$, c'est qu'il y a confusion uniquement avec la classe $C_2$ et qu'il y a $\dfrac 2 8 = \dfrac 1 4$ soit $25\%$ des données sur lesquelles il y a confusion ;

                    $-$ le taux d'erreur pour les données de chaque classe ;

                    $-$ que lorsque le classificateur répond $C_0$, il donne une bonne réponse dans $\dfrac 6 7$, soit environ $85.7\%$ des cas ;

                    $-$ etc.
                \end{indt}
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Mesures de précision dans le cas d'un classificateur binaire (H.P)}}
                $\bullet$ Dans le cas d'un problème de classification binaire, le classificateur n'a que deux réponses possibles, que l'on peut assimiler à "vrai" et "faux".
                C'est donc un algorithme qui essaie de résoudre un problème de décision.

                \begin{indt}{La matrice de confusion pour un tel algorithme est de taille $2 \times 2$, et si on assimile la classe $C_0$ à "vrai" et la classe $C_1$ à "faux", on dit que le coefficient}
                    $-$ $(0, 0)$ représente les vrai positifs ;

                    $-$ $(0, 1)$ représente les faux négatifs ;

                    $-$ $(1, 0)$ représente les faux positifs ;

                    $-$ $(1, 1)$ représente les vrai négatifs.
                \end{indt}

                Dans ce cas, il est d'usage de définir certaines quantités, appelées \emph{mesures de précision}, qui permettent d'évaluer la qualité du classificateur.

                \vspace{12pt}
                
                \begin{indt}{$\bullet$ Définition : étant donné une matrice de confusion $2 \times 2$, on définit :}
                    $-$ la \emph{sensibilité} : c'est le taux de vrais positifs, \textit{i.e} le rapport entre le nombre de vrais positifs et le nombre de données positives (vrais positifs et faux négatifs)

                    Cela représente la capacité du classificateur à reconnaître des données de la classe $C_0$.

                    \vspace{6pt}
                    
                    $-$ La \emph{spécificité} : c'est le taux de vrais négatifs, donc cela représente la capacité du classificateur à reconnaître les données de la classe $C_1$.

                    \vspace{6pt}
                    
                    $-$ La \emph{précision} : c'est le rapport entre le nombre de vrais positifs et le nombre de réponses positives de classificateur.
                    Cela représente la fiabilité du classificateur lorsqu'il répond "vrai".
                \end{indt}

                \[
                    \begin{pmatrix}
                        a & b
                        \\
                        c & d
                    \end{pmatrix}
                \]

                Sensibilité : $\dfrac{a}{a + b}$

                Spécificité : $\dfrac{d}{c + d}$

                Précision : $\dfrac{a}{a + c}$

                \vspace{12pt}
                
                $\bullet$ Remarque : au-delà de ces mesures, on peut également tracer la courbe ROC (\textit{Receiver Operator Characteristic}) qui représente en abscisse le pourcentage de faux positifs et en ordonnées le pourcentage de vrais positifs. Un point correspond à une exécution d'un classificateur sur un je de test. On fait en général varier les paramètres d'un algorithme d'apprentissage et on place des points pour chacun des classificateurs obtenus, ce qui permet d'obtenir une courbe, appelée courbe ROC, représentant les performances de l'algorithme d'apprentissage.

                \vspace{12pt}
                
                Exemple :

                \begin{center}
                    \begin{tikzpicture}
                        \draw[->] (0, 0) to (5, 0);
                        \draw[->] (0, 0) to (0, 5);

                        \draw (0, 0) to (4.5, 4.5);

                        \node at (3, 2) [color=red] {$\times$};

                        \node (1) at (.25, 1.5) {$\times$};
                        \node (2) at (.6, 2.8) {$\times$};
                        \node (3) at (1.2, 3.9) {$\times$};
                        \node (4) at (2.3, 4.3) {$\times$};
                        \node (5) at (3.5, 4.45) {$\times$};

                        \draw[color=ff4500] plot [smooth, tension=.6] coordinates {(0, 0) (1) (2) (3) (4) (5) (4.5, 4.5)};

                        \fill [pattern = dots] % needs \usetikzlibrary{patterns}
                            (0, 0)
                            -- plot [smooth, tension=.6] coordinates {(0, 0) (1) (2) (3) (4) (5) (4.5, 4.5)}
                            -- (4.5, 4.5);
                    \end{tikzpicture}
                \end{center}

                La diagonale représente les cas où on renvoie autant de bonnes réponses que de mauvaises.
                Cela représente donc un algorithme qui ferait un tirage aléatoire pour répondre.

                Un point situé sous cette courbe représente un algorithme qui ferait moins bien que le hasard.

                On mesure en général la qualité d'un algorithme d'apprentissage par la valeur de l'aire située entre sa courbe ROC et la  diagonale.

                L'objectif est de trouver un algorithme pour lequel cette aire est maximale puis d'ajuster ses paramètres pour obtenir un classificateur dont le point est proche de celui du coin supérieur gauche.
            \end{indt}
        \end{indt}
    \end{indt}

    \vspace{12pt}
    
    \begin{indt}{\section{Apprentissage non supervisé}}
        \begin{indt}{\subsection{Classification hiérarchique ascendante}}
            \begin{indt}{\subsubsection{Introduction}}
                Dans le cadre de l'apprentissage non supervisé, les données dont on dispose ne sont plus étiquetées par l'information que l'algorithme d'apprentissage doit savoir retrouver.
                L'algorithme doit plutôt inférer de nouvelles connaissances sur les données en découvrant une structure sous-jacente aux données.

                Dans ce cadre, le problème de classification est plutôt appelé problème de \emph{regroupement} (\textit{clustering}) car il ne s'agit plus de redécouvrir des classes existantes, mais d'en former en regroupant les données d'entraînement, de sorte à maximiser la similarité des données au sein des classes et la dissimilarité entre données de classe différentes.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Classification hiérarchique ascendante}}
                L'algorithme de classification ascendante (CHA), ou regroupement hiérarchique ascendant, consiste à partir de données isolées dans des classes singletons et à fusionner progressivement des classes jusqu'à la réalisation d'une condition d'arrêt.

                Pour choisir les classes à fusionner, on se donne une mesure de la dissimilarité entre les classes, que l'on appellera abusivement \emph{distance}, et on fusionne les deux classes les plus proches.

                \begin{indt}{Pour définir une distance sur les classes, on prend une distance $d$ sur les données, et on peut par exemple choisir parmi les distances suivantes :}
                    $-$ La distance minimale :
                    \[
                        d(C_1, C_2) = \min_{(x, y) \in C_1 \times C_2} d(x, y)
                    \]

                    qui correspond à la notion naturelle de distance en mathématiques ;
                    
                    \vspace{6pt}
                    
                    $-$ La distance maximale :
                    \[
                        d(C_1, C_2) = \max_{(x, y) \in C_1 \times C_2} d(x, y)
                    \]

                    qui permet de créer des classes de faible "diamètre" ;

                    \vspace{6pt}
                    
                    $-$ La distance des centres de gravité :
                    \[
                        d(C_1, C_2) = d(b_1, b_2)
                    \]

                    où $b_1$ et $b_2$ sont les (iso)barycentres de $C_1$, $C_2$ ;

                    \vspace{6pt}
                    
                    $-$ La distance de \textsc{Ward} :
                    \[
                        d(C_1, C_2) = \sqrt{\dfrac{\abs{C_1} \abs{C_2}}{\abs{C_1} + \abs{C_2}}} d(b_1, b_2)
                    \]
                \end{indt}

                Les distances de \textsc{Ward} et des centres de gravité donnent des algorithmes qui sont moins sensibles au bruit sur les données.

                Une contrainte importante est la monotonie de la distance : la fusion de deux classes ne doit par réduire la distance aux autres classes, \textit{i.e}
                \[
                    \min\!\lr{d(C_1, C_2), d(C_1, C_3)} \le d(C_1, C_2 \cup C_3)
                \]

                Une fois la distance choisie, l'algorithme s'exprime ainsi :

                \begin{indalgo}{Classification hiérarchique ascendante}
                    \For{chaque donnée $x$}{
                        Créer une classe réduite à $\set x$\;
                    }

                    \While{condition d'arrêt n'est pas satisfaite}{
                        $C_1, C_2 \gets$ classes qui minimisent $d(C_1, C_2)$\;
                        Fusionner $C_1$ et $C_2$\;
                    }

                    \Return l'ensemble des classes\;
                \end{indalgo}

                Il y a plusieurs choix possibles de condition d'arrêt :
                un nombre prédéterminé de classes à atteindre, un majorant sur la distance entre deux classes que l'on s'autorise à fusionner, un majorant sur la distance entre les données d'une même classe, ...
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Avantages et inconvénients}}
                Un inconvénient de cet algorithme est sa complexité : lorsque le jeu de données est grand (ce qui est en général le cas), le temps de calcul explose, ce qui en fait un algorithme peu pratique.

                Un autre inconvénient réside dans l'absence de remise en question. Lorsque des données sont réunies dans une même classes, on ne peut plus les séparer.

                Le principal avantage de cet algorithme est sa souplesse tirée de la grande variété de distances et de conditions d'arrêt que l'on peut choisir. De plus, on n'a pas besoin de connaître \textit{a priori} le nombre de classes.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Pourquoi \emph{hiérarchique} ?}}
                L'algorithme CHA est qualifié de \emph{hiérarchique} car on peut en tirer une structure arborescente (en fait une forêt). Pour cela, on dessine un dendrogramme, \textit{i.e} un graphe représentant l'organisation hiérarchique des fusions.

                Exemple :

                \begin{center}
                    \begin{tikzpicture}
                        \foreach \i in {1, ..., 7}{
                            \node (\i) at (\i, 0) {$\times$};
                        }

                        \draw[rounded corners=5pt] (3) to (3, 1) to (4, 1) to (4);
                        \draw[rounded corners=5pt] (6) to (6, 2) to (7, 2) to (7);
                        \draw[rounded corners=5pt] (2) to (2, 3) to (3.5, 3) to (3.5, 1);
                        \draw[rounded corners=5pt] (5) to (5, 4) to (6.5, 4) to (6.5, 2);
                        \draw[rounded corners=5pt] (2.75, 3) to (2.75, 5) to (5.75, 5) to (5.75, 4);
                        \draw[rounded corners=5pt] (1) to (1, 6) to (4.25, 6) to (4.25, 5);
                    \end{tikzpicture}
                \end{center}

                Remarque :
                On distingue la classification hiérarchique ascendante de la classification hiérarchique descendante qui consiste à partir d'une seule classe réunissant toutes les données et à chaque itération à partionner l'une des classes en deux sous-classes.
                La structure arborescente obtenue ressemble alors aux arbres de décision car les n\oe uds internes permettent de séparer des données et les feuilles contiennent les classes construites.
            \end{indt}
        \end{indt}

        \vspace{12pt}
        
        \begin{indt}{\subsection{Algorithme des $k$-moyennes}}
            \begin{indt}{\subsubsection{Introduction}}
                L'objectif de l'algorithme des $k$-moyennes consiste à répartir les données dans un nombre prédéterminé $k$ des classes (à ne pas confondre avec le $k$ de $k$NN ou des arbres $k$-d).
                L'algorithme fonctionne en plusieurs itérations et les données peuvent changer de classe au cours des itérations.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Algorithme des $k$-moyennes}}
                On se donne une distance $d$ sur l'espace des données.

                Code :
                \begin{indalgo}{$k$-moyennes}
                    $\mu_0, \ldots, \mu_{k - 1} \gets k$ données arbitraires\;

                    \BlankLine

                    \While{pas de convergence (\textit{i.e} tant que les $\mu_i,\ C_i$ changent)}{
                        \For{chaque donnée $x$}{
                            Associer $x$ à la classe $C_i$ telle que $d(x, \mu_i)$ est minimale\;
                        }

                        \For{chaque $i \in \nset 0 {k - 1}$}{
                            $\mu_i \gets$ (iso)barycentre de $C_i$\;
                        }
                    }

                    \Return les $C_i$\;
                \end{indalgo}

                Le principe de cet algorithme est de partir d'un regroupement arbitraire (souvent aléatoire) et de l'ajuster jusqu'à l'obtention d'un résultat "satisfaisant", en considérant que l'on classe les données par rapport à la distance de ces données aux centres des classes.
                La définition de ce qu'est un résultat satisfaisant vient du problème d'optimisation que l'on cherche à résoudre : étant donné un ensemble fini $D \subseteq \R^p$ et un entier $k \in \N^*$, déterminer une partition $(C_0, \ldots, C_{k - 1})$ de $D$, qui minimise
                \[
                    \sum_{i = 0}^{k - 1} \sum_{x \in C_i} d(x, \mu_i)^2
                \]

                où
                \[
                    \mu_i = \dfrac 1 {\abs{C_i}} \sum_{x \in C_i} x
                \]

                est l'isobarycentre de $C_i$.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Analyse de l'algorithme}}
                On suppose ici que $d$ est la distance euclidienne.

                \vspace{12pt}
                
                $\bullet$ Proposition [admise] :
                \begin{emphBox}
                    La fonction objectif
                    \[
                        \sum_{i = 0}^{k - 1} \sum_{x \in C_i} d(x, \mu_i)^2
                    \]

                    décroit au cours des itérations et l'algorithme termine.
                \end{emphBox}

                \vspace{12pt}
                
                $\bullet$ Corollaire :
                \begin{emphBox}
                    L'algorithme des $k$-moyennes détermine un minimum local pour la fonction de coût.
                \end{emphBox}

                \vspace{12pt}
                
                $\bullet$ Remarque : ce minimum n'est pas nécessairement global.
                
                Par exemple : on prend $p = 1$, $D = \set{1, 2, 3, 4}$, et $k = 2$.

                On suppose qu'en cas d'égalité $d(x, \mu_0) = d(x, \mu_1)$, le point $x$ est affecté à la classe $C_i$ telle que $\mu_i < \mu_{1 - i}$.

                Si les points initiaux sont $\mu_0 = 1$ et $\mu_1 = 4$,

                \begin{center}
                    \begin{tikzpicture}
                        \foreach \i in {1, ..., 4}{
                            \node (\i) at (\i, 0) {$\times$};
                        }

                        \draw[rounded corners=5pt, color=ff4500] (.75, .25) rectangle (2.25, -.25);
                        \draw[rounded corners=5pt, color=blue] (2.75, .25) rectangle (4.25, -.25);
                    \end{tikzpicture}
                \end{center}

                $\mu_0 = 1.5,\ \mu_1 = 3.5$.

                Les $\mu_i$ ne changent pas, l'algorithme se termine.

                Le regroupement est de coût $4 \cdot \lr{\dfrac 1 2}^2 = 1$

                Si les points initiaux sont plutôt $\mu_0 = 2$ et $\mu_1 = 4$, on obtient :
                \begin{center}
                    \begin{tikzpicture}
                        \foreach \i in {1, ..., 4}{
                            \node (\i) at (\i, 0) {$\times$};
                        }

                        \draw[rounded corners=5pt, color=ff4500] (.75, .25) rectangle (3.25, -.25);
                        \draw[rounded corners=5pt, color=blue] (3.75, .25) rectangle (4.25, -.25);
                    \end{tikzpicture}
                \end{center}

                Les $\mu_i$ ne changent pas, et l'algorithme se termine.

                Le regroupement est de coût $1^2 + 0^2 + 1^2 + 0^2 = 2$.

                Ce problème peut également survenir lorsque les données ont une répartition "naturelle" entre les classes.

                Par exemple, pour $p = 2$ et $k = 3$, avec les données suivantes :

                \begin{center}
                    \begin{tikzpicture}
                        \node (1) at (0, 0) [circle, fill] {};
                        \node (2) at (1.1, -.1) [circle, fill] {};
                        \draw[color=ff4500] (1.1, -.1) circle (.4);
                        \node (3) at (-1, -1) [circle, draw] {};
                        \node (4) at (0.3, -1) [circle, draw] {};
                        \draw[color=ff4500] (0.3, -1) circle (.4);
                        \node (5) at (0, -2) [circle, draw] {};
                        \node (6) at (1.3, -1.2) [circle, draw] {};

                        \node (7) at (4, 0) [circle, draw] {};
                        \node (8) at (5, 0) [circle, draw] {};
                        \node (9) at (6, -.8) [circle, draw] {};
                        \draw[color=ff4500] (6, -.8) circle (.4);
                        \node (10) at (3.8, -1) [circle, draw] {};
                        \node (11) at (4, -2) [circle, draw] {};
                        \node (12) at (5, -.8) [circle, draw] {};
                        \node (13) at (5.2, -1.7) [circle, draw] {};

                        \node (13) at (9, 0) [circle, draw] {};
                        \node (14) at (9, -1) [circle, draw] {};
                        \node (15) at (10, -1) [circle, draw] {};
                        \node (16) at (10, 0) [circle, fill] {};
                        \node (17) at (9.5, 1) [circle, draw] {};
                    \end{tikzpicture}
                \end{center}

                Les points initiaux colorées en noir donnent bien la répartition que l'on attend.

                Les points cerclés en orange donnent le regroupement suivant :

                \begin{center}
                    \begin{tikzpicture}
                        \node (1) at (0, 0) [circle, draw] {};
                        \node (2) at (1.1, -.1) [circle, draw] {};
                        \node (3) at (-1, -1) [circle, draw] {};
                        \node (4) at (0.3, -1) [circle, draw] {};
                        \node (5) at (0, -2) [circle, draw] {};
                        \node (6) at (1.3, -1.2) [circle, draw] {};

                        \draw[color=ff4500, rounded corners=5pt] (-1.3, .3) rectangle (.3+.3, -2.3);
                        \draw[color=blue, rounded corners=5pt] (1.1-.3, .3) rectangle (1.3+.3, -1.2-.3);

                        \node (7) at (4, 0) [circle, draw] {};
                        \node (8) at (5, 0) [circle, draw] {};
                        \node (9) at (6, -.8) [circle, draw] {};
                        \node (10) at (3.8, -1) [circle, draw] {};
                        \node (11) at (4, -2) [circle, draw] {};
                        \node (12) at (5, -.8) [circle, draw] {};
                        \node (13) at (5.2, -1.7) [circle, draw] {};

                        \node (13) at (9, 0) [circle, draw] {};
                        \node (14) at (9, -1) [circle, draw] {};
                        \node (15) at (10, -1) [circle, draw] {};
                        \node (16) at (10, 0) [circle, draw] {};
                        \node (17) at (9.5, 1) [circle, draw] {};

                        \draw[color=00b9ff, rounded corners=5pt] (3.8-.3, 1.3) rectangle (10.3, -2.3);
                    \end{tikzpicture}
                \end{center}

                En pratique, on exécute plusieurs fois l'algorithme avec une sélection aléatoire des points initiaux et on conserve le "meilleur" résultat.
                Cela nécessite en général de construire un jeu de test étiqueté ou de définir une mesure de la qualité d'un regroupement, ce qui est la difficulté majeure de l'apprentissage non supervisé.

                \vspace{12pt}
                
                \begin{indt}{Avantages :}
                    $-$ L'algorithme des $k$-moyennes est bien plus rapide que l'algorithme CHA et, de plus, il n'est pas nécessaire d'attendre la convergence pour obtenir un résultat acceptable ;

                    \begin{indt}{$-$ Cet algorithme présente également une certaine souplesse :}
                        $+$ Grand choix de distances possibles ;

                        $+$ On peut initialiser l'algorithme de manières différentes (par exemple : tirage aléatoire de la classe initiale de chaque donnée ou tirage aléatoire des $k$ centres parmi les points de l'ensemble convexe des données sans que ces points soient nécessairement des données) ;

                        $+$ Possibilité de calculer les "centres" autrement que par un calcul de barycentre.
                    \end{indt}
                \end{indt}

                \vspace{12pt}
                
                \begin{indt}{Inconvénients :}
                    $-$ Le minimum local atteint n'est pas forcément le regroupement recherché ;

                    $-$ Il faut connaître \textit{a priori} le nombre de classes recherché ;

                    $-$ On fait l'hypothèse que les données sont réparties dans des classes relativement convexe (\textit{cf} diagramme de \textsc{Voronoï})
                \end{indt}
            \end{indt}
        \end{indt}
    \end{indt}

    \vspace{12pt}
    
    \begin{indt}{\section{Jeux à deux joueurs}}
        \begin{indt}{\subsection{Modélisation}}
            \begin{indt}{\subsubsection{Introduction}}
                L'objectif de cette partie est d'introduire les concepts de base de la théorie des jeux, en se focalisant sur les jeux à deux joueurs, appelés $J_1$ et $J_2$, sans hasard (donc pas de jeux de dés par exemple), à information complète, \textit{i.e} les joueurs ont la connaissance parfaite de l'état du jeu à tout moment (donc la plupart des jeux de cartes seront pas considérés).
                On se limite également à des jeux d'accessibilité, \textit{i.e} pour lesquels la condition de victoire est d'atteindre un certain état du jeu.
                Les notions abordées doivent permettre l'écriture d'un programme capable de jouer au jeu étudié.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Exemple : le jeu de Chomp}}
                \label{4.1.2}

                $\bullet$ Définition : dans le jeu de Chomp, $J_1$ et $J_2$ se disputent une tablette de chocolat rectangulaire, dont le carré dans le coin supérieur gauche est empoisonné.
                Tour à tour, les joueurs choisissent un carré, et mangent les carrés situé en dessous et à droite de celui-ci.
                Le joueur contraint à manger le carré empoisonné a perdu.

                \vspace{12pt}
                
                $\bullet$ Exemple : partie sur une tablette $3 \times 4$

                \begin{center}
                    \begin{tikzpicture}[scale=.5]
                        \draw[fill, ff4500] (0, 0) rectangle (1, -1);
                        \draw[step=1cm] (0, 0) grid (4, -3);
                        \node at (2.5, -2.5) {$\times$};
                        \node at (2, 1) {$J_1$};

                        \draw[->] (4.5, -1.5) to (5.5, -1.5);

                        % Tablette 2
                        \draw[fill, ff4500] (6, 0) rectangle (7, -1);
                        \draw (6, 0) grid (10, -2);
                        \draw (6, -2) rectangle (8, -3);
                        \draw (7, -2) -- (7, -3);

                        \node at (9.5, -1.5) {$\times$};
                        \node at (8, 1) {$J_2$};

                        \draw[->] (10.5, -1.5) to (11.5, -1.5);

                        % Tablette 3
                        \draw[fill, ff4500] (12, 0) rectangle (13, -1);
                        \draw (12, 0) grid (15, -2);
                        \draw (15, 0) rectangle (16, -1);
                        \draw (12, -2) rectangle (14, -3);
                        \draw (13, -2) -- (13, -3);

                        \node at (15.5, -.5) {$\times$};
                        \node at (14, 1) {$J_1$};

                        \draw[->] (16.5, -1.5) to (17.5, -1.5);

                        % Tablette 4
                        \draw[fill, ff4500] (18, 0) rectangle (19, -1);
                        \draw (18, 0) grid (21, -2);
                        \draw (18, -2) grid (20, -3);

                        \node at (19.5, -1.5) {$\times$};
                        \node at (19.5, 1) {$J_2$};

                        \draw[->] (19.5, -3.5) to (19.5, -4.5);

                        % Tablette 5
                        \draw[fill, ff4500] (18, -5) rectangle (19, -6);
                        \draw (18, -5) grid (21, -6);
                        \draw (18, -5) grid (19, -8);

                        \node at (18.5, -6.5) {$\times$};
                        \node at (19.5, -9) {$J_1$};

                        \draw[->] (17.5, -6.5) to (16.5, -6.5);

                        % Tablette 6
                        \draw[fill, ff4500] (13, -6) rectangle (14, -7);
                        \draw (13, -6) grid (16, -7);

                        \node at (14.5, -6.5) {$\times$};
                        \node at (14.5, -9) {$J_2$};

                        \draw[->] (12.5, -6.5) to (11.5, -6.5);

                        % Tablette 7
                        \draw[fill, ff4500] (10, -6) rectangle (11, -7);
                        \draw (10, -6) rectangle (11, -7);
                        \node at (10.5, -6.5) {$\times$};
                        \node at (10.5, -9) {$J_1$};
                    \end{tikzpicture}
                \end{center}

                Ici, c'est $J_2$ qui gagne.

                \vspace{12pt}
                
                $\bullet$ Modélisation : on peut représenter le jeu de Chomp par un graphe orienté dont les états sont les différents états possibles de la tablette et dont les arcs correspondent aux changements d'état de la tablette associés à des coups légaux. On peut visualiser une partie comme le fait, pour $J_1$ et $J_2$, de déplacer tour à tour un jeton d'état en état du graphe en suivant les arcs.
                Le joueur qui parvient à placer le jeton sur l'état où il ne reste plus qu'un carré a gagné.

                \vspace{12pt}
                
                $\bullet$ Exemple : graphe du jeu de Chomp sur une tablette $2 \times 3$

                \begin{center}
                    \begin{tikzpicture}[scale=1.3]
                        \node (A) at (0, 0) [label=above:$A$] {
                            \tikz[scale=.5]{
                                \draw[fill, ff4500] (0, 0) rectangle (1, -1);
                                \draw (0, 0) grid (3, -2);
                            }
                        };
                        \node (B) at (-3, -2) [label=above:$B$] {
                            \tikz[scale=.5]{
                                \draw[fill, ff4500] (0, 0) rectangle (1, -1);
                                \draw (0, 0) grid (3, -1);
                                \draw (0, -1) rectangle (1, -2);
                            }
                        };
                        \node (C) at (0, -2.4) [label=below:$C$] {
                            \tikz[scale=.5]{
                                \draw[fill, ff4500] (0, 0) rectangle (1, -1);
                                \draw (0, 0) grid (3, -1);
                                \draw (0, -1) grid (2, -2);
                            }
                        };
                        \node (D) at (3, -2) [label=above:$D$] {
                            \tikz[scale=.5]{
                                \draw[fill, ff4500] (0, 0) rectangle (1, -1);
                                \draw (0, 0) grid (2, -2);
                            }
                        };
                        \node (E) at (-1.5, -4) [label=above:$E$] {
                            \tikz[scale=.5]{
                                \draw[fill, ff4500] (0, 0) rectangle (1, -1);
                                \draw (0, 0) grid (3, -1);
                            }
                        };
                        \node (F) at (1.5, -4) [label=above:$F$] {
                            \tikz[scale=.5]{
                                \draw[fill, ff4500] (0, 0) rectangle (1, -1);
                                \draw (0, 0) grid (1, -2);
                            }
                        };
                        \node (G) at (-3, -6) [label=left:$G$] {
                            \tikz[scale=.5]{
                                \draw[fill, ff4500] (0, 0) rectangle (1, -1);
                                \draw (0, 0) grid (1, -2);
                                \draw (0, 0) grid (2, -1);
                            }
                        };
                        \node (H) at (3, -6) [label=right:$H$] {
                            \tikz[scale=.5]{
                                \draw[fill, ff4500] (0, 0) rectangle (1, -1);
                                \draw (0, 0) grid (2, -1);
                            }
                        };
                        \node (I) at (0, -7) [label=below:$I$] {
                            \tikz[scale=.5]{
                                \draw[fill, ff4500] (0, 0) rectangle (1, -1);
                                \draw (0, 0) grid (1, -1);
                            }
                        };

                        \draw[->] (A) to (B);
                        \draw[->] (A) to (C);
                        \draw[->] (A) to (D);
                        \draw[->] (A) to (E);
                        \draw[->] (A) to (F);

                        \draw[->] (B) to (E);
                        \draw[->] (B) to (F);
                        \draw[->] (B) to (G);

                        \draw[->] (C) to (B);
                        \draw[->] (C) to (D);
                        \draw[->] (C) to (E);
                        \draw[->] (C) to (F);

                        \draw[->] (D) to (F);
                        \draw[->] (D) to (H);
                        \draw[->] (D) to (G);

                        \draw[->] (E) to (H);
                        \draw[->] (E) to (I);

                        \draw[->] (F) to (I);

                        \draw[->] (G) to (F);
                        \draw[->] (G) to (H);

                        \draw[->] (H) to (I);
                    \end{tikzpicture}
                \end{center}

                \begin{indt}{$\bullet$ Remarques :}
                    $-$ Une partie est représentée par un chemin dans le graphe de l'état initial vers l'unique état terminal.
                    \'Etant donné un tel chemin, le gagnant est déterminé par le joueur initial et la parité de la longueur du chemin.

                    $-$ On préfère souvent distinguer les états dans lesquels c'est au tour de $J_1$ de jouer de ceux dans lesquels c'est au tour de $J_2$.
                    On duplique donc les sommets et on crée un graphe biparti.

                    Sur le graphe précédant, voici un extrait du graphe obtenu :

                    \begin{center}
                        \begin{tikzpicture}[scale=1.2]
                            \foreach \i/\j in {A/1, B/2, C/3, D/4, E/5, F/6, G/7, H/8, I/9}{
                                \node (\i1) at ({\j}, 0) {${\i}_1$};
                                \node (\i2) at ({\j}, -2) {${\i}_2$};
                            }

                            \foreach \i in {B, ..., F}{
                                \draw[->] (A1) to (\i2);
                                \draw[->] (A2) to (\i1);
                            }

                            \foreach \i in {E, F, H}{
                                \draw[->] (\i1) to (I2);
                                \draw[->] (\i2) to (I1);
                            }
                        \end{tikzpicture}
                    \end{center}

                    Si on suppose que c'est toujours $J_1$ qui commence, alors on peut simplifier ce graphe.

                    Par exemple : $A_2$ est inutile donc $C_1$ aussi car il devient de degré entrant nul.
                \end{indt}
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Vocabulaire}}
                $\bullet$ Un jeu à deux joueurs est donné par un graphe orienté biparti $G = (S, A)$, aussi appelé \emph{arène}.
                En notant $S_1, S_2$ une partition convenable de $S$, on dit que les éléments de $S_1$ (resp. $S_2$) sont les états \emph{contrôlés} par $J_1$ (resp. $J_2$).

                Les arcs de $G$ sont appelés des \emph{coups} : un arc $(s, t)$ décrit un coup possible depuis $s$ pour le joueur qui contrôle cet état.

                \vspace{12pt}
                
                $\bullet$ Une partie étant constituée d'une suite de coups alternant les deux joueurs, on définit une partie depuis l'état $s$ comme un chemin de sommet initial $s$, maximal.
                Un tel chemin est alors nécessairement soit infini, soit fini et tel que son dernier sommet est de degré sortant nul. Les sommets de degré sortant nul sont appelés \emph{états terminaux}.

                On suppose dans la suite que le graphe $G$ est acyclique, donc qu'il n'existe pas de partie infinie.

                \vspace{12pt}
                
                $\bullet$ Parmi les états terminaux, on distingue les états gagnants pour $J_1$, les états gagnants pour $J_2$, et les états nuls.

                Attention, un état gagnant pour $J_1$ n'est pas forcément contrôlé par $J_1$ (\textit{cf} Chomp). Cela dépend du jeu.

                On appelle \emph{partie gagnante} pour $J_1$ (resp. $J_2$) toute partie se terminant dans un état gagnant pour $J_1$ (resp. $J_2$) et \emph{partie nulle} toute partie se terminant dans un état nul.

                \vspace{12pt}
                
                $\bullet$ Exemple : dans le jeu de Chomp, la partie suivante :

                \begin{center}
                    \begin{tikzpicture}[scale=.5]
                        % Tablette 1
                        \draw[fill, ff4500] (0, 0) rectangle (1, -1);
                        \draw (0, 0) grid (3, -2);

                        \node at (2.5, -1.5) {$\times$};
                        \node at (1.5, -3) {$J_1$};

                        \draw[->] (3.5, -1) to (4.5, -1);

                        % Tablette 2
                        \draw[fill, ff4500] (5, 0) rectangle (6, -1);
                        \draw (5, 0) grid (7, -2);
                        \draw (7, 0) rectangle (8, -1);

                        \node at (7.5, -.5) {$\times$};
                        \node at (6.5, -3) {$J_2$};

                        \draw[->] (8.5, -1) to (9.5, -1);

                        % Tablette 3
                        \draw[fill, ff4500] (10, 0) rectangle (11, -1);
                        \draw (10, 0) grid (12, -2);

                        \node at (11.5, -1.5) {$\times$};
                        \node at (11, -3) {$J_1$};

                        \draw[->] (12.5, -1) to (13.5, -1);

                        % Tablette 4
                        \draw[fill, ff4500] (14, 0) rectangle (15, -1);
                        \draw (14, 0) grid (16, -1);
                        \draw (14, 0) grid (15, -2);

                        \node at (15.5, -.5) {$\times$};
                        \node at (15, -3) {$J_2$};

                        \draw[->] (16.5, -1) to (17.5, -1);

                        % Tablette 5
                        \draw[fill, ff4500] (18, 0) rectangle (19, -1);
                        \draw (18, 0) grid (19, -2);

                        \node at (18.5, -1.5) {$\times$};
                        \node at (19, -3) {$J_1$};

                        \draw[->] (19.5, -1) to (20.5, -1);

                        % Tablette 6
                        \draw[fill, ff4500] (21, -.5) rectangle (22, -1.5);
                        \draw (21, -.5) rectangle (22, -1.5);

                        \node at (21.5, -1) {$\times$};
                        \node at (21.5, -3) {$J_2$};
                    \end{tikzpicture}
                \end{center}

                est décrite par le chemin $A_1, C_2, D_1, G_2, F_1, I_2$ dans le graphe de \ref{4.1.2} (page \pageref{4.1.2}).
                C'est une partie gagnante pour $J_1$. Les états terminaux du graphe sont $I_1$ et $I_2$ respectivement gagnants pour $J_2$ et $J_1$.
                Il n'y a donc pas d'état nul ni de partie nulle.

                \vspace{12pt}
                
                $\bullet$ Exemple : le \emph{tic-tac-toe}

                $J_1$ et $J_2$ doivent à tour de rôle placer leur symbole personnel (traditionnellement un rond ou une croix) dans une grille $3 \times 3$, de sorte à aligner sur une ligne, une colonne, ou une diagonale trois occurrences de leur symbole.

                Les états du jeux sont les différents états de la grille, ce qui donne un graphe ayant plus de $5 000$ sommets, et plus de $16 000$ arcs.

                Dans les états terminaux, la grille n'est pas nécessairement remplie.

                Par exemple,
                \[
                    \begin{array}{c|c|c}
                        \times & & \bullet
                        \\
                        \hline
                               & \times & \bullet
                        \\
                        \hline
                        \times & \bullet & \times
                    \end{array}
                \]

                est un état terminal, gagnant pour le joueur dont le symbole est $\times$.

                On peut d'ailleurs affirmer que dans toute partie d'état initial la grille vide, et qui mène à cet état, c'est ce joueur qui a commencé.

                D'autres états terminaux peuvent correspondre à une grille remplie, comme
                \[
                    \begin{array}{c|c|c}
                        \bullet & \times & \times
                        \\
                        \hline
                        \times & \times & \bullet
                        \\
                        \hline
                        \bullet & \bullet & \bullet
                    \end{array}
                \]
                pour lequel on peut affirmer que pour toute partie menant à cet état, le joueur dont le symbole est $\bullet$ a commencé et a joué le dernier coup nécessairement sur la dernière rangée.

                Dans ce jeu, il existe des états nuls, par exemple
                \[
                    \begin{array}{c|c|c}
                        \times & \times & \bullet
                        \\
                        \hline
                        \bullet & \times & \times
                        \\
                        \hline
                        \times & \bullet & \bullet
                    \end{array}
                \]

                Dans le cas où l'état précédant dans une partie est le suivant :
                \[
                    \begin{array}{c|c|c}
                        \times & \times & \bullet
                        \\
                        \hline
                        \bullet & \times & \times
                        \\
                        \hline
                        & \bullet & \bullet
                    \end{array}
                \]
                on pourrait déjà affirmer que la partie sera nulle car c'est le joueur dont le symbole est $\times$ qui le contrôle, alors que si cet état était contrôlé par l'autre joueur, alors ce dernier gagnerait nécessairement, d'où l'importance de travailler sur le graphe biparti, qui donne la connaissance du joueur au trait.

                \vspace{12pt}
                
                $\bullet$ Remarque : déterminer à l'avance quels sont les états qui mènent à des parties gagnantes pour l'un des joueurs ou nulles est au c\oe ur de la prise de décision des joueurs. Il est donc nécessaire de trouver des algorithmes efficaces permettant d'évaluer la la situation de jeu afin d'établir une stratégie.
            \end{indt}
        \end{indt}

        \vspace{12pt}
        
        \begin{indt}{\subsection{Stratégies}}
            \begin{indt}{\subsubsection{Stratégies sans mémoire}}
                $\bullet$ Définition : Soit $G = (S, A)$ un jeu à deux joueurs pour lequel on note $S_1$ l'ensemble des états contrôlés par $J_1$, et $S_2$ celui des états contrôlés par $J_2$.

                Pour $i \in \set{1, 2}$, une stratégie sans mémoire pour $J_i$ est une fonction $f : S_i \longrightarrow S$ telle que $\forall e \in S_i$ non terminal, $(e, f(e)) \in A$.

                Une partie est jouée selon la stratégie $f$ si, en notant $s_0, \ldots, s_n$ cette partie, $\forall j \in \nset 0 {n - 1}\ |\ s_j \in S_i$, alors $s_{j + 1} = f(s_j)$.
                
                \vspace{12pt}
                
                $\bullet$ Remarque : la stratégie est dite \emph{sans mémoire} car elle ne dépend que de l'état courant du jeu et pas de ce qui s'est passé avant.

                Un objectif est de réussir à construire une stratégie qui garantisse si possible la victoire du joueur qui l'applique, tout en espérant qu'il existe une implémentation efficace pour une telle stratégie.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Stratégies et positions gagnantes}}
                $\bullet$ Définition (\emph{stratégie gagnante}) : Soit $G = (S, A)$ un jeu à deux joueurs pour lequel on note $S_1$ (resp. $S_2$) l'ensemble des états contrôlés par $J_1$ (resp. $J_2$).

                Une stratégie $f$ est dite \emph{gagnante} depuis l'état $s_0 \in S$ pour le joueur $i$ si et seulement si toute partie jouée selon cette stratégie à partir de l'état $s_0$ est gagnante pour le joueur $i$.

                \vspace{12pt}
                
                $\bullet$ Exemple : pour le jeu de Chomp sur une tablette $2 \times 3$ (modélisée par le graphe en \ref{4.1.2}, page \pageref{4.1.2}), la stratégie suivante est gagnante pour $J_1$ depuis $A1$ :
                \[
                    \begin{array}{rcl}
                        f
                        & : & A_1 \longmapsto B_1
                        \\
                        && B_1 \longmapsto G_2
                        \\
                        && C_1 \longmapsto B_2
                        \\
                        && D_1 \longmapsto G_2
                        \\
                        && E_1 \longmapsto I_2
                        \\
                        && F_1 \longmapsto I_2
                        \\
                        && G_1 \longmapsto H_2
                        \\
                        && H_1 \longmapsto H_2
                        \\
                        && I_1 \longmapsto A_1
                    \end{array}
                \]

                $J_2$ admet une stratégie gagnante depuis $B_2$ :
                \[
                    \begin{array}{rcl}
                        g
                        & : & A_2 \longmapsto C_1
                        \\
                        && B_2 \longmapsto G_1
                        \\
                        && C_2 \longmapsto B_1
                        \\
                        && D_2 \longmapsto G_1
                        \\
                        && E_2 \longmapsto I_1
                        \\
                        && F_2 \longmapsto I_1
                        \\
                        && G_2 \longmapsto H_1
                        \\
                        && H_2 \longmapsto I_1
                        \\
                        && I_2 \longmapsto A_1
                    \end{array}
                \]

                \vspace{12pt}
                
                $\bullet$ Remarque : si $J_1$ et $J_2$ jouent tous les deux leur stratégie, c'est tout de même $J_1$ qui va gagner car celle de $J_2$ n'est gagnante que depuis des états vers lesquels $J_1$ ne va pas jouer.

                \vspace{12pt}
                
                $\bullet$ Définition (\emph{position gagnante}) : Soit $G = (S, A)$ un jeu à deux joueurs, et $e \in S$ un état du jeu.

                L'état $e$ est une \emph{position gagnante} pour le joueur $i$ si et seulement si il existe une stratégie gagnante depuis cet état pour ce joueur.

                \vspace{12pt}
                
                $\bullet$ Exemple : dans le jeu de Chomp sur une tablette $2 \times 3$, les positions gagnantes pour le joueur $i$ sont $A_i, B_i, D_i, E_i, F_i, H_i, C_{3 - i}, G_{3 - i}, I_{3 - i}$.

                \vspace{12pt}
                
                $\bullet$ Proposition :
                \begin{emphBox}
                    Dans le jeu de Chomp sur une tablette $p \times q$ avec $(p, q) \neq (1, 1)$, la position initiale est gagnante pour le premier joueur (on suppose que $J_1$ commence).
                \end{emphBox}

                \vspace{6pt}
                
                \begin{proof}
                    On montre d'abord que toute position est gagnante soit pour $J_1$ soit pour $J_2$, par récurrence forte sur le nombre de carrés de chocolat.

                    $-$ S'il ne reste qu'un carré : l'état est terminal et gagnant pour le joueur qui ne le contrôle pas.

                    $-$ On suppose la propriété vraie pour tous les états à moins de $n$ carrés de chocolat.

                    On considère un état $s$ à $n + 1$ carrés. On note $J_i$ le joueur qui contrôle cet état.

                    Par hypothèse de récurrence, pour tout coup $(s, t)$ possible, comme $t$ a moins de $n$ carrées, $t$ est une position gagnante soit pour $J_1$, soit pour $J_2$.

                    \begin{indt}{Deux options :}
                        $+$ Il existe un coup $(s, t)$ tel que $t$ est une position gagnante pour $J_i$, alors $s$ est une position gagnante pour $J_i$ (il suffit de jouer ce coup puis d'appliquer une stratégie gagnante depuis $t$) ;

                        $+$ Pour tous les coups $(s, t)$, $t$ est une position gagnante pour $J_{3 - i}$ : alors $s$ est une position gagnante pour $J_{3 - i}$ car quelque soit le coup joué, $J_{3 - i}$ peut appliquer une stratégie gagnante depuis l'état atteint.
                    \end{indt}

                    \vspace{6pt}
                    
                    Remarque : ce raisonnement s'applique à tout jeu sans cycle ni état terminal nul en appliquant une induction bien fondée selon l'ordre topologique inverse sur le graphe.

                    \vspace{6pt}
                    
                    $-$ On suppose que la position initiale est gagnante pour $J_2$.
                    Il existe donc une stratégie gagnante pour $J_2$ depuis la position initiale.
                    En particulier si $J_1$ ne mange que le carré en bas à droite, il existe un coup pour $J_2$ qui mène à une position contrôlée par $J_1$ encore gagnante pour $J_2$.

                    \begin{center}
                        \begin{tikzpicture}[scale=.5]
                            \draw (0, 0) rectangle (9, -6);
                            \draw (8, -5) rectangle (9, -6);

                            \draw (5, -3) rectangle (6, -4);
                            \draw[dashed] (5, -3) -- (5, -6);
                            \draw[dashed] (5, -3) -- (9, -3);

                            \node (J1) at (10, -6.5) {$J_1$};
                            \draw[->] (J1) to (8.5, -5.5);

                            \node (J2) at (6, -7.5) {$J_2$};
                            \draw[->] (J2) to (5.5, -3.5);
                        \end{tikzpicture}
                    \end{center}

                    Or le carré en bas à droite est inclus dans les carrés situées en dessous et à droite du carré correspondant au coup de $J_2$.

                    Ainsi, si $J_1$ mange plutôt ce carré pour son premier coup, il atteint une position qui était gagnante pour $J_2$, mais en inversant le joueur qui contrôle cet état. Il peut donc à partir de cet état appliquer la stratégie gagnante de $J_2$ et gagner la partie : absurde

                    La position initiale est donc gagnante pour $J_1$
                \end{proof}

                \vspace{12pt}
                
                $\bullet$ Remarque : la technique utilisée dans cette démonstration est appelée \emph{vol de stratégie} : $J_1$ vole la stratégie de $J_2$ en l'appliquant en premier. Ce n'est pas un démonstration constructive donc cela ne permet pas de déterminer une stratégie gagnante.

                En revanche, on peut déduire de la première partie de la démonstration un algorithme permettant de calculer une stratégie gagnante.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Attracteur}}
                $\bullet$ Remarque : on se place du point de vue de $J_1$ pour simplifier, mais tout se transpose à $J_2$.

                $\bullet$ Définition (\emph{attracteur}) : Soit $G = (S, A)$ un jeu à deux joueurs pour lequel l'ensemble des états contrôlés par $J_1$ (resp. $J_2$) est noté $S_1$ (resp. $S_2$).

                On note $W_1$ l'ensemble est états terminaux gagnants pour $J_1$.

                On définit
                \[
                    \begin{cases}
                        A_0 = W_1
                        \\
                        \!\!
                        \begin{array}{rcl}
                            \forall n \in \N,\
                            A_{n + 1} = A_n
                            &\cup&
                            \set{s \in S_1\ |\ \exists t \in A_n\ |\ (s, t) \in A}
                            \\
                            &\cup& \set{s \in S_2\ |\ \forall t \in S,\ (s, t) \in A \Rightarrow t \in A_n}
                        \end{array}
                        \vspace{-18pt}
                    \end{cases}
                \]

                \vspace{12pt}

                L'\emph{attracteur} de $W_1$ est l'ensemble
                \[
                    \bigcup_{n \in \N} A_n
                \]

                \vspace{12pt}
                
                $\bullet$ Théorème :
                \begin{emphBox}
                    Avec les même notations, l'attracteur de $W_1$ est l'ensemble des points gagnants pour $J_1$.
                \end{emphBox}

                \vspace{6pt}
                
                \begin{proof}
                    $\forall s \in S$, on note
                    \[
                        n_s =
                        \begin{cases}
                            \min\set{n \in \N\ |\ s \in A_n}
                            & \displaystyle \text{si}\ s \in \bigcup_{n \in \N} A_n
                            \\
                            +\infty
                            & \text{sinon}
                        \end{cases}
                    \]

                    On montre par récurrence forte que $\forall n \in \N,\ \forall s \in S\ |\ n_s = n$, $s$ est une position gagnante pour $J_1$.

                    $-$ $n = 0$ : si $s \in A_0 = W_1$, $s$ est par définition de $W_1$ gagnante pour $J_1$.

                    $-$ Si la propriété est vraie jusqu'au rang $n$, soit $s \in S\ |\ n_s = n + 1$.

                    Par définition,
                    \[
                        s \in A_{n + 1} \setminus A_n
                        \subseteq \set{s \in S_1\ |\ \exists t \in A_n\ |\ (s, t) \in A_n}
                        \cup \set{s \in S_2\ |\ \forall t \in S,\ (s, t) \in A \Rightarrow t \in A_n}
                    \]

                    $+$ Si $s \in S_1,\ \exists t \in A_n\ |\ (s, t) \in A$.

                    Comme $t \in A_n,\ n_t \le n$, donc par H.R, $t$ est une position gagnante pour $J_1$.
                    Donc $s$ est une position gagnante pour $J_1$ ($J_1$ joue $(s, t)$ puis applique une stratégie gagnante depuis $t$).

                    $+$ Si $s \in S_2,\ \forall t \in S,\ (s, t) \in A \Rightarrow t \in A_n$.

                    De même, $\forall t \in S,\ (s, t) \in A \Rightarrow t$ est une position gagnante pour $J_1$.

                    Donc $s$ est une position gagnante pour $J_1$ car quel que soit le coup joué par $J_2$, $J_1$ pourra appliquer une stratégie gagnante depuis l'état atteint.

                    \vspace{6pt}
                    
                    $-$ Réciproquement, si
                    \[
                        s \notin \bigcup_{n \in \N} A_n
                    \]
                    alors $n_s = +\infty$.

                    On montre que $s$ est soit gagnante pour $J_2$, soit nulle.

                    On procède par induction bien fondée selon l'ordre topologique inverse (existe car $G$ est acyclique).

                    \begin{indt}{$+$ Si $s$ est terminal : comme}
                        \[
                            s \notin \bigcup_{n \in \N} A_n
                        \]
                        alors $s \notin W_1 = A_0$, donc $s$ est un élément terminal nul ou gagnant pour $J_2$.
                    \end{indt}

                    \begin{indt}{$+$ Si $s$ est tel que}
                        \[
                            \forall s' \notin \bigcup_{n \in \N},\ s' < s
                        \]
                        selon l'ordre topologique inverse, $s'$ est une position gagnante pour $J_2$ ou nulle.

                        \begin{indt}{$*$ Si $s$ est contrôlé par $J_2$ :}
                            comme $n_s = +\infty,\ \forall t \in S\ |\ (s, t) \in A,\ n_t = +\infty$ (sinon $n_s \le n_t + 1$).

                            Alors par hypothèse d'induction, $\forall t \in S\ |\ (s, t) \in A$ (\textit{i.e} $t < s$), $t$ est gagnant pour $J_2$ ou nul, donc quel que soit le coup joué par $J_1$, il est possible pour $J_2$ d'obtenir au moins la nulle, donc $s$ est soit gagnant pour $J_2$, soit nul.
                        \end{indt}

                        \begin{indt}{$*$ Si $s$ est contrôlé par $J_2$ :}
                            comme $n_s = +\infty,\ \exists t \in S\ |\ (s, t) \in A$, et $n_t = +\infty$ (sinon $\exists N \in \N\ |\ n\forall t \in S\ |\ (s, t) \in A, n_t \le N$, d'où $n_s \le N + 1$).

                            Comme $t < s$, par hypothèse d'induction, $t$ est gagnant pour $J_2$ ou nul.

                            Donc $J_2$ obtient au moins la nulle en jouant $(s, t)$.

                            Donc $s$ est gagnant pour $J_2$ ou nul.
                        \end{indt}
                    \end{indt}
                \end{proof}

                \vspace{12pt}
                
                \begin{indt}{$\bullet$ Remarque : cette démonstration permet de construire une stratégie gagnante pour $J_1$ (depuis les états de l'attracteur $W_1$) :}
                    $-$ Si $n_s = +\infty$, le coup importe peu car si $J_2$ joue parfaitement, $J_1$ obtiendra au mieux la nulle.

                    $-$ Si $n_s < +\infty$, jouer un coup $(s, t) \in A\ |\ n_t < +\infty$.
                \end{indt}

                Il "suffit" pour cela de calculer (efficacement) l'attracteur de $W_1$. Cela ne fonctionne que si le graphe du jeu n'est pas trop grand.

                %\vspace{12pt}
                
                %\boxed{\rm Exo} : algorithme en temps linéaire qui 

                \vspace{12pt}
                
                $\bullet$ Calcul de l'attracteur :
                On procède par un parcours du graphe (transposé) du jeu en considérant les états selon l'ordre topologique inverse.

                On part des états terminaux et on leur associe leur statut : gagnant pour $J_1$, gagnant pour $J_2$, ou nul.

                Puis on "remonte" dans le graphe : pour chaque état dont le statut de tous les successeurs est connu (garanti par le choix de l'ordre topologique inverse), on détermine le statut de cet état en fonction du joueur qui contrôle l'état et des status des successeurs (comme dans la démonstration).

                \vspace{6pt}
                
                Complexité :

                $-$ Calcul du graphe transposé : $\mathcal O(\abs S + \abs A)$.

                $-$ Tri topologique du graphe transposé : $\mathcal O(\abs S + \abs A)$.

                $-$ Parcours des sommets selon ce tri, en observant leurs successeurs dans le graphe du jeu : $\mathcal O(\abs S + \abs A)$.

                Donc au total, $\mathcal O(\abs S + \abs A)$.

                \vspace{12pt}
                
                \boxed{\rm Exo} Modification de l'algorithme pour calculer une stratégie à la volée + code.
            \end{indt}
        \end{indt}

        \vspace{12pt}
        
        \begin{indt}{\subsection{Algorithme min-max}}
            \begin{indt}{\subsubsection{Principe}}
                Dans la perspective d'écrire un programme capable de jouer, on se place du point de vue où l'on dispose d'un état donné pour lequel on essaie de déterminer un couple. Contrairement au calcul des attracteurs dans lequel on remonte depuis les états terminaux, on essaie ici d'explorer le graphe à partir de l'état donné pour déterminer son statut, en supposant que l'adversaire joue parfaitement.

                \begin{indt}{Ainsi, on construit un arbre tel que :}
                    $-$ la racine de l'arbre est l'état donné ;

                    $-$ pour chaque n\oe ud interne, les fils de ce n\oe ud sont les états que l'on peut atteindre en un coup.
                \end{indt}

                En particulier, les n\oe uds de profondeur paire sont contrôles par le joueur et ceux de profondeur impaire par l'adversaire.

                \begin{indt}{L'algorithme min-max est alors l'algorithme récursif qui consiste à calculer une évaluation numérique pour chaque n\oe ud ($1$ pour les positions gagnantes, $-1$ pour les positions perdantes, et $0$ pour les positions nulles) de la manière suivante :}
                    $-$ Si le n\oe ud est une feuille, \textit{i.e} un état terminal, on lui attribue l'évaluation associée à son statut.

                    \begin{indt}{$-$ Si le n\oe ud est interne, il y a deux possibilités :}
                        $+$ Si le n\oe ud est de profondeur paire : comme le joueur contrôle cet état et cherche à maximiser ses chances de gain, l'évaluation de n\oe ud est le maximum des évaluations de ses fils (et on peut retenir un coup associé) ;

                        $+$ Le n\oe ud est de profondeur impaire : comme l'adversaire contrôle cet état et comme on suppose qu'il joue parfaitement, sachant qu'il cherche à minimiser les chances de gain du joueur, l'évaluation du n\oe ud est le minimum des évaluations des ses fils.
                    \end{indt}
                \end{indt}

                \vspace{12pt}
                
                \begin{indt}{Remarques :}
                    \begin{indt}{$-$ C'est une réécriture du calcul des attracteurs :}
                        Pour chaque état contrôlé par le joueur, son évaluation vaut 1 si et seulement si il existe un coup vers un état d'évaluation 1.

                        Pour chaque état contrôlé par l'adversaire, son évaluation vaut 1 si et seulement si tous les coups mènent vers des états d'évaluation 1.
                    \end{indt}

                    Un programme qui jouerait selon cet algorithme serait donc beaucoup moins efficace qu'un programme qui précalculerait les attracteurs pour jouer ensuite selon le résultat de ce précalcul. En revanche, cet algorithme est assez simple pour que l'on puisse le modifier de sorte à pouvoir l'appliquer dans des cas où le graphe est trop grand pour réaliser un calcul des attracteurs.

                    \vspace{6pt}
                    
                    $-$ On parle d'algorithme \emph{min-max} car l'évaluation d'un état se fait \textit{via} un parcours de l'arbre en alternant des calculs de min et de max.

                    \vspace{6pt}
                    
                    $-$ Il y a souvent plusieurs séries de coups qui mènent d'un même état de départ à un même état d'arrivée, donc certains sous-arbres sont identiques : on peut éviter de recalculer les évaluations en effectuant une mémoïsation (ce qui revient à partager les sous-arbres). Cela consiste à effectuer l'exploration du graphe du jeu directement.
                \end{indt}
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Heuristiques}}
                En pratique, le graphe du jeu est souvent trop grand pour être représenté en mémoire (par exemple : pour les dames, il y a de l'ordre de $10^{32}$ états, pour les échecs il y a de l'ordre de $10^{52}$ états, pour le go, il y a de l'ordre de $> 10^{100}$ états).
                Même la mémoïsation ne permet pas d'appliquer cet algorithme, mais il est possible d'en conserver le principe en fixant une profondeur maximale pour l'exploration.

                Le principe le l'évaluation reste le même mais il faut donner une valeur aux n\oe uds de la profondeur $p$ fixée qui ne sont pas terminaux. On utilise pour cela une fonction $h$, appelée \emph{heuristique}, des états vers $\R \cup \set{\pm \infty}$.

                \begin{indt}{Sa spécification est la suivante :}
                    $-$ Les états terminaux gagnants prennent la valeur $+\infty$ ;

                    $-$ Les états terminaux perdants prennent la valeur $-\infty$ ;

                    $-$ Les autres états prennent une valeur dans $\R$.
                \end{indt}

                Il est d'usage d'attribuer la valeur $0$ aux états terminaux nuls, mais ce n'est pas un obligation.
                La seule contrainte est que plus la valeur attribuée à un état est grande, plus cet état est jugé favorable au joueur.

                Pour jouer à un jeu, il est donc possible d'écrire un algorithme qui implémente l'algorithme min-max, limité à la profondeur $p$ et qui évalue chaque état terminal et chaque état de profondeur $p$ par l'heuristique $h$.

                \vspace{12pt}
                
                $\bullet$ Exemple :

                $-$ Exécution sur l'arbre suivant, pour lequel les évaluations de l'heuristique sont placées aux feuilles :

                \begin{center}
                    \begin{tikzpicture}
                        \node (0) at (0, 0) [circle, draw] {1}
                            child {node [circle, draw, xshift=-40pt] {$-1$}}
                            child {node [circle, draw, xshift=-30pt] {1}
                                child {node [circle, draw, xshift=-10pt] {3}
                                    child {node [circle, draw] {$-4$}}
                                    child {node [circle, draw] {$3$}}
                                }
                                child {node [circle, draw, xshift=10pt] {1}
                                    child {node [circle, draw] {1}}
                                }
                            }
                            child {node [circle, draw, xshift=30pt] {$-5$}
                                child {node [circle, draw] {$2$}}
                                child {node [circle, draw] {$-5$}}
                                child {node [circle, draw] {$1$}}
                            }
                            child {node [circle, draw, xshift=40pt] {$0$}}
                        ;
                    \end{tikzpicture}
                \end{center}

                \begin{tabular}{cc}
                    Profondeur
                    \\
                    \hline
                    0 & max
                    \\
                    1 & min
                    \\
                    2 & max
                    \\
                    $3 = p$ & $h$
                \end{tabular}

                Coup choisi par l'algorithme : de la racine vers 1.

                \vspace{12pt}
                
                $-$ Heuristique pour le jeu du puissance 4 :

                Principe : les joueurs placent des jetons colorés sur une grille $6 \times 7$ de la manière suivante : à tour de rôle les joueurs choisissent une colonne sur laquelle il reste une case vide et placent un jeton de leur couleur sur la case vide située le plus en bas sur cette colonne.
                Un joueur gagne dès qu'il parvient à aligner quatre jetons de sa couleur, horizontalement, verticalement, ou en diagonale.

                Idée d'heuristique : on attribue à chaque case la valeur suivante : le nombre d'alignements qu'il est possible de réaliser à l'aide d'un jeton placé sur cette case, de manière indépendante du remplissage actuel de la grille :
                \[
                    \begin{matrix}
                        3 & 4 & 5 & 7 & 5 & 4 & 3
                        \\
                        4 & 6 & 8 & 10 & 8 & 6 & 4
                        \\
                        5 & 8 & 11 & 13 & 11 & 8 & 5
                        \\
                        5 & 8 & 11 & 13 & 11 & 8 & 5
                        \\
                        4 & 6 & 8 & 10 & 8 & 6 & 4
                        \\
                        3 & 4 & 5 & 7 & 5 & 4 & 3
                    \end{matrix}
                \]

                Pour les états non terminaux, l'heuristique attribue l'évaluation suivante : la différence entre la somme des valeurs des cases occupées par des jetons du joueur qui applique l'heuristique et la somme des valeurs des cases occupées par des jetons de l'autre joueur (\textit{i.e} l'adversaire).

                Par exemple, pour l'état suivant :
                \begin{center}
                    \begin{tabular}{|c|c|c|c|c|c|c|}
                        &
                        & \textcolor{blue}{$\circ$}
                        &&&&
                        \\
                        &
                        & \textcolor{ff4500}{$\bullet$}
                        & \textcolor{blue}{$\circ$}
                        & \textcolor{ff4500}{$\bullet$}
                        &&
                        \\
                        & \textcolor{blue}{$\circ$}
                        & \textcolor{ff4500}{$\bullet$}
                        & \textcolor{ff4500}{$\bullet$}
                        & \textcolor{blue}{$\circ$}
                        &&
                        \\
                        \textcolor{ff4500}{$\bullet$}
                        & \textcolor{blue}{$\circ$}
                        & \textcolor{blue}{$\circ$}
                        & \textcolor{blue}{$\circ$}
                        & \textcolor{ff4500}{$\bullet$}
                        & \textcolor{ff4500}{$\bullet$}
                        & $\phantom{\bullet}$
                        \\
                        \hline
                    \end{tabular}
                \end{center}

                l'heuristique évalue pour le joueur bleu (\textcolor{blue}{$\circ$}) :
                \[
                    4 + 5 + 7 + 6 + 8 + 13 + 11
                    - 3 - 5 - 4 - 8 - 10 - 11 - 11
                    = +2
                \]

                donc une position légèrement favorable pour le joueur bleu.

                \vspace{12pt}
                
                $\bullet$ Remarque : comme le branchement n'est pas constant, travailler avec la même profondeur pour toutes les branches n'est pas forcément pertinent : certaines branches vont nécessiter beaucoup plus de temps de calcul que les autres.
                Une possibilité pour équilibrer la charge consiste à appliquer un parcours en profondeur itéré : on augmente progressivement la profondeur en donnant la priorité aux branches qui contiennent plus de n\oe uds et en s'arrêtant lorsque le temps attribué au programme pour le calcul du coup est écoulé.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{\'Elagage $\alpha$--$\beta$}}
                Principe : de manière similaire à un algorithme par séparation et évaluation, il est parfois possible de ne pas explorer certaines branches de l'arbre en exploitant la connaissance de bornes sur l'évaluation d'un n\oe ud.

                Par exemple :

                \begin{center}
                    \begin{tikzpicture}
                        \node (0) at (0, 0) [circle, draw] {4}
                            child {node [circle, draw, xshift=-80pt] {3}
                                child {node [circle, draw] {3}
                                    child {node {} edge from parent [dashed]}
                                }
                                child {node [circle, draw] {4}
                                    child {node {} edge from parent [dashed]}
                                }
                                child {node [circle, draw] {5}
                                    child {node {} edge from parent [dashed]}
                                }
                            }
                            child {node [circle, draw] {1}
                                child {node [circle, draw] {2}
                                    child {node {} edge from parent [dashed]}
                                }
                                child {node [circle, draw] {3}
                                    child {node {} edge from parent [dashed]}
                                }
                                child {node [circle, draw] {1}
                                    child {node {} edge from parent [dashed]}
                                }
                            }
                            child {node [circle, draw, xshift=80pt] {4}
                                child {node [circle, draw] {5}
                                    child {node {} edge from parent [dashed]}
                                }
                                child {node [circle, draw] {4}
                                    child {node {} edge from parent [dashed]}
                                }
                                child {node [circle, draw] {8}
                                    child {node [circle, draw] {6}
                                        child {node {} edge from parent [dashed]}
                                    }
                                    child {node [circle, draw] {8}
                                        child {node {} edge from parent [dashed]}
                                    }
                                }
                            }
                        ;
                    \end{tikzpicture}
                \end{center}

                On suppose que l'exploration se fait de gauche à droite.
                Lorsque le n\oe ud 2 est évalué, comme son père est un n\oe ud min, on sait que l'évaluation de ce dernier sera inférieure ou égale à 2.

                Or la racine est un n\oe ud max dont l'un des fils a déjà une évaluation connu égale à 3. On sait donc que la branche menant au père du n\oe ud 2 ne permettra pas de réaliser le maximum. On peut donc interrompre l'évaluation de cette branche (donc ne pas évaluer les n\oe uds 3 et 1).

                De même, lorsque l'évaluation du n\oe ud 6 est connue, il devient inutile d'évaluer son frère car leur père aura une évaluation supérieure ou égale à 6, donc supérieure au minimum courant nécessaire à l'évaluation du n\oe ud 4.

                \vspace{12pt}
                
                $\bullet$ Coupure $\alpha$, coupure $\beta$ :

                On ajoute deux paramètres à l'algorithme min--max, nommés $\alpha$ et $\beta$, qui représentent respectivement les bornes inférieures et supérieures de l'intervalle des évaluations "utiles" d'un n\oe ud.
                Si une évaluation est assurée de sortir de cet intervalle, il est inutile de poursuivre son calcul car elle ne sera pas prise en compte pour les calculs de min et de max.

                $-$ Si le n\oe ud courant est un n\oe ud min, alors son père est un n\oe ud max.
                Dans ce cas, si l'un des fils du n\oe ud courant prend une évaluation inférieure à $\alpha$, alors c'est aussi le cas de l'évaluation du n\oe ud courant, et il est inutile de continuer.

                \begin{center}
                    \begin{tikzpicture}
                        \node (0) at (0, 0) [circle, draw] {$p$}
                            child {node [circle, draw, xshift=-40pt] {$x_1$}}
                            child {node [circle, draw] {$x_n$}}
                            child {node [circle, draw] {$n$}
                                child {node [circle, draw] {$f$}}
                                child {node {$\ldots \vphantom{a}$}}
                            }
                        ;

                        \node at (-1.3, -1.45) {$\ldots$};
                    \end{tikzpicture}
                \end{center}

                On considère $\alpha = \max(\mathrm{eval}(x_i))$.

                Si $\mathrm{eval}(f) \le \alpha$, alors $\mathrm{eval}(n) \le \alpha$, donc $n$ ne sera pas choisi pour le calcul de $\mathrm{eval}(p)$.
                On coupe donc les autres branches issues de $n$.

                On parle ici de \emph{coupure $\alpha$}.

                \vspace{6pt}
                
                $-$ Si le n\oe ud courant est un n\oe ud max, alors son père est un n\oe ud min.
                Dans ce cas, si l'un des fils du n\oe ud courant prend une valeur supérieure à $\beta$, alors c'est aussi le cas du n\oe ud courant, et on peut élaguer.

                Avec le même dessin, on considère maintenant $\beta = \min(\mathrm{eval}(x_i))$.

                Si $\mathrm{eval}(f) \ge \beta$, alors $\mathrm{eval}(n) \ge \beta$, et $n$ ne servira pas au calcul de $\mathrm{eval}(p)$.

                Les autres branches issues de $n$ sont élaguées et on parle de \emph{coupure $\beta$}.

                \vspace{12pt}
                
                $\bullet$ Algorithme :

                Initialement, on prend $\alpha = -\infty$, et $\beta = +\infty$ car on ne dispose d'aucune information sur les évaluations.

                \begin{indalgo}{Min--max avec élagage $\alpha$--$\beta$}
                    \KwInput{N\oe ud $n$ (un état du jeu)}
                    \KwInput{Profondeur maximale $p$}
                    \KwInput{heuristique $h$}
                    \KwInput{bornes $\alpha$ et $\beta$}

                    \BlankLine

                    \If{$n$ est terminal}{
                        \Return $h(n)$
                        \tcp*{Valeur exacte associée à un état terminal}
                    }

                    \If{$p = 0$}{
                        \Return $h(n)$
                        \tcp*{Estimation associée à un état non terminal \textit{via} l'heuristique}
                    }

                    \If{$n$ est un n\oe ud min}{
                        \tcp{Le test nécessite la connaissance de la profondeur courante par exemple.}
                        $M \gets +\infty$
                        \tcp*{Majorant de $\mathrm{eval}(n)$}

                        \For{chaque fils $f$ de $n$}{
                            \tcp{pour chaque coup depuis $n$}

                            $v \gets \text{\texttt{min-max}}(f, p - 1, h, \alpha, \beta)$\;

                            \If{$v < M$}{
                                $M \gets v$\;
                            }

                            \If{$M \le \alpha$}{
                                \Return $M$
                                \tcp*{coupure $\alpha$}
                            }

                            $\beta \gets \min(\beta, M)$
                            \tcp*{permet des coupure $\beta$ pour les fils non encore traités de $n$, si leur évaluation dépasse le min connu}
                        }

                        \Return $M$\;
                    }

                    \Else{
                        \tcp{$n$ est un n\oe ud max}

                        $m \gets -\infty$
                        \tcp*{minorant pour $\mathrm{eval}(n)$}

                        \For{chaque fils $f$ de $n$}{
                            $v \gets \text{\texttt{min-max}}(f, p - 1, h, \alpha, \beta)$\;

                            \If{$v > m$}{
                                $ù \gets v$\;
                            }
                            \If{$m \ge \beta$}{
                                \Return $m$
                                \tcp*{coupure $\beta$}
                            }

                            $\alpha \gets \min{\alpha, m}$\;
                        }

                        \Return $m$\;
                    }
                \end{indalgo}

                $\bullet$ Exemple :
                \begin{center}
                    \begin{tikzpicture}[scale=.8]
                        \node (0) at (0, 0) [circle, draw] {10}
                            child {node [circle, draw, xshift=-120pt] {10}
                                child {node [circle, draw, xshift=-50pt] {10}
                                    child {node [circle, draw, xshift=-15pt] {10}
                                        child {node [circle, draw] {10}}
                                        child {node [circle, draw] {11}}
                                    }
                                    child {node [circle, draw, xshift=15pt] {9}
                                        child {node [circle, draw] {9}}
                                        child {node [circle, draw, ff4500] {\textcolor{black}{12}} edge from parent [ff4500] node [above right] {$\alpha$}}
                                    }
                                }
                                child {node [circle, draw, xshift=50pt] {14}
                                    child {node [circle, draw, xshift=-15] {14}
                                        child {node [circle, draw] {14}}
                                        child {node [circle, draw] {15}}
                                    }
                                    child {node [circle, draw, xshift=15, ff4500] {}
                                        child {node [circle, draw] {13}}
                                        child {node [circle, draw] {14}}
                                        edge from parent [ff4500] node [above right] {$\beta$}
                                    }
                                }
                            }
                            child {node [circle, draw, xshift=120pt] {5}
                                child {node [circle, draw, xshift=-50pt] {5}
                                    child {node [circle, draw, xshift=-15pt] {5}
                                        child {node [circle, draw] {5}}
                                        child {node [circle, draw, ff4500] {\textcolor{black} 2} edge from parent [ff4500] node [above right] {$\alpha$}}
                                    }
                                    child {node [circle, draw, xshift=15pt] {4}
                                        child {node [circle, draw] {4}}
                                        child {node [circle, draw, ff4500] {\textcolor{black}{1}} edge from parent [ff4500] node [above right] {$\alpha$}}
                                    }
                                }
                                child {node [circle, draw, xshift=50pt, ff4500] {}
                                    child {node [circle, draw, xshift=-15pt] {}
                                        child {node [circle, draw] {3}}
                                        child {node [circle, draw] {22}}
                                    }
                                    child {node [circle, draw, xshift=15pt] {}
                                        child {node [circle, draw] {20}}
                                        child {node [circle, draw] {21}}
                                    }
                                    edge from parent [ff4500] node [above right] {$\alpha$}
                                }
                            }
                        ;
                    \end{tikzpicture}
                \end{center}
            \end{indt}
        \end{indt}
    \end{indt}

    \vspace{12pt}
    
    \begin{indt}{\section{Recherche informée}}
        \begin{indt}{\subsection{Contexte}}
            \begin{indt}{\subsubsection{Graphe d'états}}
                De nombreux problèmes peuvent être modélisés à l'aide de graphes : les n\oe uds sont appelés \emph{états} et correspondent aux états du système que l'on modélise, et les arcs, appelé \emph{transitions}, représentant les actions qu'il est possible d'effectuer pour change d'état.
                On cherche en général à trouver une suite d'actions permettant de passer d'un état initial à un état cible, \textit{i.e} un chemin entre ces états dans le graphe.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Exemple}}
                $-$ Pour les jeux à un joueur, par exemple le Rubik's cube, les états sont les configurations du jeux, et les arcs les coups légaux.

                $-$ Pour la recherche d'itinéraire sur un plan, on peut par exemple considérer que les états sont les intersections, et les arcs les portions de rues reliant deux intersections consécutives (ou alors se placer à une échelle plus fine).

                $-$ Pour la planification de trajectoire en robotique, les états peuvent inclure la position dans l'espace du robot, mais aussi sa vitesse, son accélération (\textit{via} une discrétisation) et les arcs peuvent représenter les opérations de contrôle effectuées sur le robot.

                $-$ Etc.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Pondération}}
                Dans les problèmes modélisés par un graphe d'états, on cherche souvent à trouver une solution optimale (par exemple : nombre minimal de coups pour résoudre le Rubik's cube, itinéraire le plus court, ...). Cela passe par une pondération des arcs du graphe d'état, qui représentent le coût associé à chaque action Le problème posé est donc celui de la recherche de plus court chemin dans un graphe pondéré.

                Problème : les algorithmes de calcul de plus court chemin vus en chapitre 10 5. ne peuvent pas s'appliquer à des graphes trop grands pour être représentés en mémoire ce qui est souvent le cas dans les problèmes d'intelligence artificielle.
                Même si l'algorithme de \textsc{Floyd--Warshall} ne peut être réalisé dans ce cas, il reste possible d'explorer l'algorithme de \textsc{Dijkstra} en changeant les structures de données utilisées : il peut être impossible de conserver une estimation de la distance au sommet de départ pour chacun des n\oe uds dans un tableau, mais l'usage d'un dictionnaire permet de conserver cette estimation pour les n\oe uds rencontrés en cours d'exploration.
                On espère alors trouver le sommet cible avant de saturer la mémoire.
                Cependant, l'algorithme de \textsc{Dijkstra} manque d'efficacité en pratique car on ne sait pas "dans quelle direction" chercher le sommet cible. Il est parfois possible d'exploiter une information supplémentaire pour guider la recherche et limiter le nombre de sommets parcourus.
                C'est ce que l'on appelle la \emph{recherche informée}.
            \end{indt}
        \end{indt}

        \begin{indt}{\subsection{Algorithme $A^*$}}
            \begin{indt}{\subsubsection{Heuristiques}}
                L'information dont on dispose pour guider la recherche est représentée par une fonction, appelée \emph{heuristique}, estimant le coût nécessaire à la résolution du problème depuis chaque état.

                \vspace{12pt}
                
                $\bullet$ Définition : Soit $G = (S, A, w)$ un GO pondéré par des poids positifs, et $t \in S_n$ un sommet cible.

                Une \emph{heuristique} pour la recherche de $t$ est une fonction
                \[
                    h : S \longrightarrow \R_+
                \]

                telle que
                \[
                    h(t) = 0
                \]

                L'heuristique $h$ est dite \emph{admissible} si et seulement si
                \[
                    \forall s \in S,\
                    h(s) \le d(s, t)
                \]

                où $\displaystyle d(s, t) = \min_{p\ \text{chemin de $s$ à $t$}}(w(p))$, \textit{i.e} si et seulement si $h$ ne surestime jamais le coût de la résolution.

                L'heuristique $h$ est dite \emph{monotone} si et seulement si
                \[
                    \forall (u, v) \in A,\
                    h(u) \le w(u, v) + h(v)
                \]

                \vspace{12pt}
                
                $\bullet$ Proposition :
                \begin{emphBox}
                    Soit $G = (S, A, w)$ un GOP tel que $w : A \longrightarrow \R_+$, $t \in S$, $h : S \longrightarrow \R_+$ une heuristique.

                    Si $h$ est monotone, alors $h$ est admissible.
                \end{emphBox}

                \vspace{6pt}
                
                \begin{proof}
                    Soit $s \in S$, et $s_0 \cdots s_n$ un chemin de $s$ à $t$ de poids
                    \[
                        \sum_{i = 0}^{n - 1} w(s_i, s_{i + 1})
                    \]

                    Par récurrence, on montre que
                    \[
                        \forall i \in \nset 0 n,\
                        h(s_i) \le \sum_{j = i}^{n - 1} w(s_j, s_{j + 1})
                    \]

                    $-$ Initialisation :
                    \[
                        h(s_n) = h(t) = 0 = \sum_{j = n}^{n - 1} w(s_j, s_{j + 1})
                    \]
                    
                    $-$ Hérédité :
                    \[
                        \begin{array}{rcll}
                            h(s_{i - 1})
                            &\le& \displaystyle
                            w(s_{i - 1}, s_i) + h(s_i)
                            & \text{car $h$ monotone}
                            \\
                            &\le& \displaystyle
                            w(s_{i - 1}, s_i) + \sum_{j = i}^{n - 1} w(s_j, s_{j + 1})
                            & \text{par H.R}
                            \\
                            &=& \displaystyle
                            \sum_{j = i - 1}^{n - 1} w(s_j, s_{j + 1})
                        \end{array}
                    \]

                    Conclusion :
                    \[
                        h(s) = h(s_0)
                        \le
                        \sum_{j = 0}^{n - 1} w(s_j, s_{j + 1})
                        = d(s, t)
                    \]
                \end{proof}

                \vspace{12pt}
                
                $\bullet$ Exemple : la fonction nulle est toujours monotone donc admissible.

                Dans le cas de la recherche d'itinéraire, la distance à vol d'oiseau (distance euclidienne) est également monotone (d'après l'inégalité triangulaire).
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Algorithme $A^*$}}
                $\bullet$ Principe : l'algorithme $A^*$ est une adaptation de l'algorithme de \textsc{Dijkstra} pour tenir compte d'une heuristique : la priorité d'un sommet rencontré dans la file de priorité n'est plus l'estimation de sa distance au sommet de départ, mais la somme de cette estimation et de la valeur de l'heuristique pour ce sommet, \textit{i.e} une estimation du coût pour passer du sommet initial au sommet cible \textit{via} ce sommet.

                Attention : en raison de l'usage de l'heuristique, lorsqu'un sommet est extrait de la file de priorité, on ne connaît pas forcément sa distance au sommet initial, mais seulement un majorant de cette distance.
                Il peut donc être nécessaire de réinsérer ce sommet dans la file afin d'affiner les estimations.

                \vspace{12pt}
                
                $\bullet$ Exemple :
                \begin{center}
                    \begin{tikzpicture}[scale=1.5]
                        \node (s) at (0, 0) [circle, draw] {$s$};
                        \node (a) at (1, 1) [circle, draw] {$a$};
                        \node (b) at (2, 0) [circle, draw] {$b$};
                        \node (t) at (4, 0) [circle, draw] {$t$};

                        \draw[->] (s) to node [below] {3} (b);
                        \draw[->] (s) to node [above left] {1} (a);
                        \draw[->] (a) to node [above right] {1} (b);
                        \draw[->] (b) to node [below] {5} (t);
                    \end{tikzpicture}
                \end{center}

                avec $h(a) = 6$, et $h(b) = 3$.

                Depuis $s$, $a$ et $b$ sont insérés avec les priorités $w(s, a) + h(a) = 7$ et $w(s, b) + h(b) = 6$.
                Le sommet $b$ est alors extrait, et on insère $t$ dans la file avec la priorité $w(s, b) + w(b, t) + h(t) = 8$.

                Même si $t$ est rencontré, on poursuit l'algorithme car on n'a pas forcément trouvé le plus court chemin de $s$ à $t$.

                Le sommet $a$ est alors extrait et on remarque que $w(s, a) + w(a, b) + h(b) = 5 < 6$, ancienne priorité de $b$.
                On réinsère donc $b$ dans la file avec la priorité 5, correspondant au chemin $s \rightarrow a \rightarrow b$.

                L'extraction de $b$ mène à la mise à jour de la priorité de $t$, qui devient $w(s, a) + w(a, b) + w(b, t) + h(t) = 7$ correspondant bien au poids du plus court chemin de $s$ à $t$.

                \vspace{12pt}
                
                $\bullet$ Algorithme :

                \begin{indalgo}{$A^*$}
                    \KwInput{$G = (S, A, w)$ avec $w : A \longrightarrow \R_+$}
                    \KwInput{heuristique $h$}
                    \KwInput{source $s \in S$}
                    \KwInput{cible $t \in S$}

                    \BlankLine

                    \texttt{d[$s$]} $\gets 0$\;
                    \texttt{p[$s$]} $\gets s$
                    \tcp*{prédécesseur}

                    $F \gets$ file de priorité min vide\;

                    \BlankLine

                    Insérer $s$ dans $F$ avec priorité $h(s)$\;

                    $u \gets s$\;

                    \BlankLine

                    \While{$u \neq t$ et $F \neq \varnothing$}{
                        $u \gets$ extraction du min de $F$\;

                        \For{tout voisin $v$ de $u$}{
                            \If{\texttt{d[$v$]} n'est pas défini ou \texttt{d[$u$]} $+ w(u, v) <$ \texttt{d[$v$]}}{
                                \texttt{d[$v$]} $\gets$ \texttt{d[$u$]} $+ w(u, v)$\;
                                \texttt{p[$v$]} $\gets u$\;

                                \If{$v \in F$}{
                                    Mettre à jour la priorité de $v$ avec \texttt{d[$v$]} $+ h(v)$\;
                                }
                                \Else{
                                    Insérer $v$ dans $F$ avec la priorité \texttt{d[$v$]} $+ h(v)$
                                }
                            }
                        }
                    }

                    \If{$u = t$}{
                        \Return le chemin de $s$ à $t$ calculé grâce à \texttt{p}\;
                    }
                    \Else{
                        \'Echec\;
                    }
                \end{indalgo}

                Remarque: si l'heuristique est la fonction nulle, on retrouve l'algorithme de \textsc{Dijkstra}.

                \vspace{12pt}
                
                $\bullet$ Proposition :
                \begin{emphBox}
                    Si $h$ est admissible, alors l'algorithme $A^*$ renvoie un plus court chemin de $s$ à $t$ s'il existe.
                \end{emphBox}

                \vspace{6pt}
                
                \begin{proof}
                    S'il existe un chemin $s_0 \cdots s_n$ de $s$ à $t$, alors l'algorithme $A^*$ ne peut pas échouer.

                    Sinon, on considère
                    \[
                        i = \max\!\set{j \in \nset 0 n\ |\ s_j\ \text{a été extrait de la file par l'algorithme}}
                \]

                    $-$ $i$ existe bien car $s_0 = s$ est bien inséré, donc extrait.

                    $-$ $i \neq n$ car sinon $s_n = t$ est extrait donc $u$ prend la valeur $t$ et la boucle est interrompue et un chemin est renvoyé.

                    $-$ Lorsque $s_i$ est extrait, comme $(s_i, s_{i + 1}) \in A$, on considère $s_{i + 1}$. Dans ce cas, soit $s_{i + 1}$ est déjà passé dans la file de priorité (et y est peut-être encore), soit on insère $s_{i + 1}$ dans la file. Dans tous les cas, $s_{i + 1}$ sera extrait car la file est vide en fin d'algorithme puisque l'algorithme échoue.

                    Contradiction avec la maximalité de $i$.

                    \vspace{6pt}
                    
                    On considère maintenant le cas où l'algorithme renvoie un chemin de $s$ à $t$ dont on note $d$ le poids.

                    Remarque : au moment de son extraction, $t$ est de priorité \texttt{d[$t$]} $+ h(t) =$ \texttt{d[$t$]} $= d$.

                    On suppose qu'il existe un chemin $s_0 \cdots s_n$ de $s$ à $t$ de poids minimal $d' < d$.

                    On montre par récurrence que $\forall i \in \nset 0 n$, $s_i$ prendra la priorité
                    \[
                        d(s, s_i) + h(s_i) \le d'
                    \]
                    avant que $t$ ne soit extrait.

                    $-$ $i = 0$ : $s = s_0$ est inséré avec priorité $h(s) = d(s, s) + h(s) \le d' = d(s, t)$ car $h$ est admissible.

                    $-$ Hérédité : si $s_k$ prend la priorité $d(s, s_i) + h(s_i) \le d'$ avant l'extraction de $t$, alors la priorité de $s_i$ est inférieure ou égale à $d' < d$, priorité avec laquelle $t$ est extrait, donc $s_i$ est extrait avant $t$.

                    Au moment de l'extraction de $s_i$, comme $(s_i, s_{i + 1}) \in A$, on considère la priorité de $s_{i + 1}$.

                    Soit $s_{i + 1}$ a déjà la priorité
                    \[
                        d(s, s_{i + 1}) + h(s_{i + 1})
                        \le d(s, s_{i + 1}) + d(s_{i + 1}, t)
                        = d'
                    \]
                    soit cette priorité est plus grande.

                    Dans ce cas, \texttt{d[$s_i$]} $ + w(s_i, s_{i + 1}) = d(s, s_{i + 1}) <$ \texttt{d[$s_{i + 1}$]} donc on met à jour la priorité de $s_{i + 1}$ avec la bonne valeur.

                    Ainsi, $s_n = t$ prend une priorité $\le d' < d$ avant son extraction : absurde.

                    \vspace{6pt}
                    
                    \boxed{\rm Exo} Montrer que l'algorithme termine bien s'il existe un chemin de $s$ à $t$.
                \end{proof}
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Complexité}}
                L'algorithme $A^*$ peut avoir une complexité exponentielle en le nombre d'arcs d'un plus court chemin de $s$ à $t$ en raison des réinsertions de sommets.

                Cependant, dans le cas où l'heuristique est monotone, on peut montrer comme pour l'algorithme de \textsc{Dijkstra} que lorsqu'un sommet est extrait, on connaît sa distance au sommet source (\boxed{\rm Exo}, preuve d'invariant).

                Ainsi, chaque sommet peut provoquer l'insertion / la mise à jour de la priorité de tous ses voisins au moment de sa première extraction, donnant une file de taille $\mathcal O(\abs A)$, puis chaque extraction ne donnera lieu qu'à l'examen des voisins en $\mathcal O(\abs S)$ sans insertion supplémentaire. Comme chaque opération sur la file est de complexité $\mathcal O(\log \abs A) = \mathcal O(\log\abs S)$, on obtient une complexité
                \[
                    \mathcal O(\abs S \abs A \log \abs S)
                \]
            \end{indt}
        \end{indt}
    \end{indt}
    
\end{document}
%--------------------------------------------End
