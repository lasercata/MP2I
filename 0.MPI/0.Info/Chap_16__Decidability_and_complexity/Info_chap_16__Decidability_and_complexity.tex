\documentclass[a4paper, 12pt, twoside]{article}


%------------------------------------------------------------------------
%
% Author                :   Lasercata
% Last modification     :   2023.01.03
%
%------------------------------------------------------------------------


%------ini
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
%\usepackage[english]{babel}


%------geometry
\usepackage[textheight=700pt, textwidth=500pt]{geometry}


%------color
\usepackage{xcolor}
\definecolor{ff4500}{HTML}{ff4500}
\definecolor{00f}{HTML}{0000ff}
\definecolor{0ff}{HTML}{00ffff}
\definecolor{656565}{HTML}{656565}

%\renewcommand{\emph}{\textcolor{ff4500}}
%\renewcommand{\em}{\color{ff4500}}

\newcommand{\Emph}{\textcolor{ff4500}}

\newcommand{\strong}[1]{\textcolor{ff4500}{\bf #1}}
\newcommand{\st}{\color{ff4500}\bf}


%------Code highlighting
%---listings
\usepackage{listings}

\definecolor{cbg}{HTML}{272822}
\definecolor{cfg}{HTML}{ececec}
\definecolor{ccomment}{HTML}{686c58}
\definecolor{ckw}{HTML}{f92672}
\definecolor{cstring}{HTML}{e6db72}
\definecolor{cstringlight}{HTML}{98980f}
\definecolor{lightwhite}{HTML}{fafafa}

\lstdefinestyle{DarkCodeStyle}{
    backgroundcolor=\color{cbg},
    commentstyle=\itshape\color{ccomment},
    keywordstyle=\color{ckw},
    numberstyle=\tiny\color{cbg},
    stringstyle=\color{cstring},
    basicstyle=\ttfamily\footnotesize\color{cfg},
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=4,
    xleftmargin=\leftskip
}

\lstdefinestyle{LightCodeStyle}{
    backgroundcolor=\color{lightwhite},
    commentstyle=\itshape\color{ccomment},
    keywordstyle=\color{ckw},
    numberstyle=\tiny\color{cbg},
    stringstyle=\color{cstringlight},
    basicstyle=\ttfamily\footnotesize\color{cbg},
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=10pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=4,
    frame=L,
    xleftmargin=\leftskip
}

%\lstset{style=DarkCodeStyle}
\lstset{style=LightCodeStyle}
%Usage : \begin{lstlisting}[language=Caml, xleftmargin=xpt] ... \end{lstlisting}


%---Algorithm
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\SetKwInput{KwInput}{Input}
\SetKwInput{KwOutput}{Output}

\SetKwProg{Fn}{Function}{:}{}
\SetKw{KwPrint}{Print}

\newcommand\commfont[1]{\textit{\texttt{\textcolor{656565}{#1}}}}
\SetCommentSty{commfont}
\SetProgSty{texttt}
\SetArgSty{textnormal}
\SetFuncArgSty{textnormal}
%\SetProgArgSty{texttt}

\newenvironment{indalgo}[2][H]{
    \begin{algoBox}
        \begin{algorithm}[#1]
            \caption{#2}
}
{
        \end{algorithm}
    \end{algoBox}
}


%---tcolorbox
\usepackage[many]{tcolorbox}
\DeclareTColorBox{emphBox}{O{black}O{lightwhite}}{
    breakable,
    outer arc=0pt,
    arc=0pt,
    top=0pt,
    toprule=-.5pt,
    right=0pt,
    rightrule=-.5pt,
    bottom=0pt,
    bottomrule=-.5pt,
    colframe=#1,
    colback=#2,
    enlarge left by=10pt,
    width=\linewidth-\leftskip-10pt,
}

\DeclareTColorBox{algoBox}{O{black}O{lightwhite}}{
    breakable,
    arc=0pt,
    top=0pt,
    toprule=-.5pt,
    right=0pt,
    rightrule=-.5pt,
    bottom=0pt,
    bottomrule=-.5pt,
    left=0pt,
    leftrule=-.5pt,
    colframe=#1,
    colback=#2,
    width=\linewidth-\leftskip-10pt,
}


%-------make the table of content clickable
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}


%------pictures
\usepackage{graphicx}
%\usepackage{wrapfig}

\usepackage{tikz}
%\usetikzlibrary{babel}             %Uncomment this to use circuitikz
%\usetikzlibrary{shapes.geometric}  % To draw triangles in trees
%\usepackage{circuitikz}            %Electrical circuits drawing


%------tabular
%\usepackage{color}
%\usepackage{colortbl}
%\usepackage{multirow}


%------Physics
%---Packages
%\usepackage[version=4]{mhchem} %$\ce{NO4^2-}$

%---Commands
\newcommand{\link}[2]{\mathrm{#1} \! - \! \mathrm{#2}}
\newcommand{\pt}[1]{\cdot 10^{#1}} % Power of ten
\newcommand{\dt}[2][t]{\dfrac{\mathrm d #2}{\mathrm d #1}} % Derivative


%------math
%---Packages
%\usepackage{textcomp}
%\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools} % For abs
\usepackage{stmaryrd} %for \llbracket and \rrbracket
\usepackage{mathrsfs} %for \mathscr{x} (different from \mathcal{x})

%---Commands
%-Sets
\newcommand{\N}{\mathbb{N}} %set N
\newcommand{\Z}{\mathbb{Z}} %set Z
\newcommand{\Q}{\mathbb{Q}} %set Q
\newcommand{\R}{\mathbb{R}} %set R
\newcommand{\C}{\mathbb{C}} %set C
\newcommand{\U}{\mathbb{U}} %set U
\newcommand{\seg}[2]{\left[ #1\ ;\ #2 \right]}
\newcommand{\nset}[2]{\left\llbracket #1\ ;\ #2 \right\rrbracket}

%-Exponantial / complexs
\newcommand{\e}{\mathrm{e}}
\newcommand{\cj}[1]{\overline{#1}} %overline for the conjugate.

%-Vectors
\newcommand{\vect}{\overrightarrow}
\newcommand{\veco}[3]{\displaystyle \vect{#1}\binom{#2}{#3}} %vector + coord

%-Limits
\newcommand{\lm}[2][{}]{\lim\limits_{\substack{#2 \\ #1}}} %$\lm{x \to a} f$ or $\lm[x < a]{x \to a} f$
\newcommand{\Lm}[3][{}]{\lm[#1]{#2} \left( #3 \right)} %$\Lm{x \to a}{f}$ or $\Lm[x < a]{x \to a}{f}$
\newcommand{\tendsto}[1]{\xrightarrow[#1]{}}

%-Integral
\newcommand{\dint}[4][x]{\displaystyle \int_{#2}^{#3} #4 \mathrm{d} #1} %$\dint{a}{b}{f(x)}$ or $\dint[t]{a}{b}{f(t)}$

%-left right
\newcommand{\lr}[1]{\left( #1 \right)}
\newcommand{\lrb}[1]{\left[ #1 \right]}
\newcommand{\lrbb}[1]{\left\llbracket #1 \right\rrbracket}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\lrangle}[1]{\left\langle #1 \right\rangle}

%-Others
\newcommand{\para}{\ /\!/\ } %//
\newcommand{\ssi}{\ \Leftrightarrow \ }
\newcommand{\eqsys}[2]{\begin{cases} #1 \\ #2 \end{cases}}

\newcommand{\med}[2]{\mathrm{med} \left[ #1\ ;\ #2 \right]}  %$\med{A}{B} -> med[A ; B]$
\newcommand{\Circ}[2]{\mathscr{C}_{#1, #2}}

\renewcommand{\le}{\leqslant}
\renewcommand{\ge}{\geqslant}

\newcommand{\oboxed}[1]{\textcolor{ff4500}{\boxed{\textcolor{black}{#1}}}} %orange boxed

\newcommand{\rboxed}[1]{\begin{array}{|c} \hline #1 \\ \hline \end{array}} %boxed with right opened
\newcommand{\lboxed}[1]{\begin{array}{c|} \hline #1 \\ \hline \end{array}} %boxed with left opened

\newcommand{\orboxed}[1]{\textcolor{ff4500}{\rboxed{\textcolor{black}{#1}}}} %orange right boxed
\newcommand{\olboxed}[1]{\textcolor{ff4500}{\lboxed{\textcolor{black}{#1}}}} %orange left boxed


%------commands
%---to quote
\newcommand{\simplecit}[1]{\guillemotleft$\;$#1$\;$\guillemotright}
\newcommand{\cit}[1]{\simplecit{\textcolor{656565}{#1}}}
\newcommand{\quo}[1]{\cit{\it #1}}

%---to indent
\newcommand{\ind}[1][20pt]{\advance\leftskip + #1}
\newcommand{\deind}[1][20pt]{\advance\leftskip - #1}

%---to indent a text
\newcommand{\indented}[2][20pt]{\par \ind[#1] #2 \par \deind[#1]}
\newenvironment{indt}[2][20pt]{#2 \par \ind[#1]}{\par \deind} %Titled indented env

%---title
\newcommand{\thetitle}[2]{\begin{center}\textbf{{\LARGE \underline{\Emph{#1} :}} {\Large #2}}\end{center}}

%---Maths environments
%-Proofs
\newenvironment{proof}[1][{}]{\begin{indt}{$\square$ #1}}{$\blacksquare$ \end{indt}}

%-Maths parts (proposition, definition, ...)
\newenvironment{mathpart}[1]{\begin{indt}{\boxed{\text{\textbf{#1}}}}}{\end{indt}}
\newenvironment{mathbox}[1]{\boxed{\text{\textbf{#1}}}\begin{emphBox}}{\end{emphBox}}
\newenvironment{mathul}[1]{\begin{indt}{\underline{\textbf{#1}}}}{\end{indt}}

\newenvironment{theo}{\begin{mathpart}{Théorème}}{\end{mathpart}}
\newenvironment{Theo}{\begin{mathbox}{Théorème}}{\end{mathbox}}

\newenvironment{prop}{\begin{mathpart}{Proposition}}{\end{mathpart}}
\newenvironment{Prop}{\begin{mathbox}{Proposition}}{\end{mathbox}}
\newenvironment{props}{\begin{mathpart}{Propriétés}}{\end{mathpart}}

\newenvironment{defi}{\begin{mathpart}{Définition}}{\end{mathpart}}
\newenvironment{meth}{\begin{mathpart}{Méthode}}{\end{mathpart}}

\newenvironment{Rq}{\begin{mathul}{Remarque :}}{\end{mathul}}
\newenvironment{Rqs}{\begin{mathul}{Remarques :}}{\end{mathul}}

\newenvironment{Ex}{\begin{mathul}{Exemple :}}{\end{mathul}}
\newenvironment{Exs}{\begin{mathul}{Exemples :}}{\end{mathul}}


%------Sections
% To change section numbering :
% \renewcommand\thesection{\Roman{section}}
% \renewcommand\thesubsection{\arabic{subsection})}
% \renewcommand\thesubsubsection{\textit \alph{subsubsection})}

% To start numbering from 0
% \setcounter{section}{-1}


%------page style
\usepackage{fancyhdr}
\usepackage{lastpage}

\setlength{\headheight}{18pt}
\setlength{\footskip}{50pt}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE, RO]{\textit{\textcolor{black}{\today}}}
\fancyhead[RE, LO]{\large{\textsl{\Emph{\texttt{\jobname}}}}}

\fancyfoot[RO, LE]{\textit{\texttt{\textcolor{black}{Page \thepage /}\pageref{LastPage}}}}
\fancyfoot[LO, RE]{\includegraphics[scale=0.12]{/home/lasercata/Pictures/1.images_profil/logo/mieux/lasercata_logo_fly_fond_blanc.png}}


%------init lengths
\setlength{\parindent}{0pt} %To avoid using \noindent everywhere.
\setlength{\parskip}{3pt}


%---------------------------------Begin Document
\begin{document}
    
    \thetitle{Chapitre 16}{Décidabilité et complexité}
    
    \tableofcontents
    \newpage
    
    \begin{indt}{\section{Décidabilité}}
        \begin{indt}{\subsection{Modèles de calcul et universalité}}
            \begin{indt}{\subsubsection{Introduction}}
                L'objet de ce chapitre est l'étude de ce qu'il est possible de calculer avec un algorithme, avec ou sans contrainte de complexité temporelle.

                Afin de pouvoir énoncer précisément des propriétés, il faut une définition formelle de la notion d'algorithme.
            \end{indt}

            \begin{indt}{\subsubsection{Modèles de calcul historiques (H.P)}}
                $\bullet$ Nous avons vu dans le chapitre 14 plusieurs modèles de calcul, dont certains étaient équivalents (AFD, AFND, $\varepsilon$-AFND) et d'autres plus généraux (grammaires non contextuelle).
                On peut se demander s'il existe un modèle de calcul le plus général, capable de caractériser ce qu'il est possible de calculer mécaniquement.

                $\bullet$ Plusieurs modèles de calcul ont étés proposés dans les années 1930, et se sont révélés équivalents et plus généraux que les modèles précédents : les machines de \textsc{Turing}, et le $\lambda$-calcul de \textsc{Church}.

                Les modèles les plus généraux conçus ultérieurement, comme les fonctions récursives, sont équivalents à ces deux modèles et on admet l'hypothèse, nommée thèse de \textsc{Church}--\textsc{Turing}, que ces modèles caractérisent vraiment la notion d'algorithme.
                On dit aujourd'hui qu'un langage de programmation est \emph{Turing-complet} s'il est capable d'écrire les mêmes algorithmes que ceux implémentables par machine de \textsc{Turing}.

                \vspace{6pt}
                
                $\bullet$ machine de \textsc{Turing} : informellement, une machine de \textsc{Turing} est une machine finie travaillant sur un ruban infini qui lui sert de mémoire.
                La machine dispose d'une tête de lecture lui permettant d'accéder à une case du ruban et de règles de transition décrivant les opérations réalisées sur les cases et les déplacements de la tête de lecture.

                %\begin{center}
                %    \begin{tabular}{ccccccccccc}
                %        \hline
                %        $\cdots$ & \vline & $u_1$ & \vline & $u_2$ & \vline & $\cdots$ & \vline & $u_n$ & \vline & $\cdots$
                %        \\
                %        \hline
                %                 &&&& $\uparrow$
                %        \\
                %                 &&& \multicolumn{3}{c}{\boxed{\rm machine}}
                %    \end{tabular}
                %\end{center}

                \begin{center}
                    \begin{tikzpicture}
                        \node (r) at (0, 0) {
                            $
                                \begin{array}{c|c|c|c|c|c}
                                    \hline
                                    \cdots & u_1 & u_2 & \cdots & u_n & \cdots
                                    \\
                                    \hline
                                \end{array}
                            $
                        };
                        \node (m) at (-.4, -1) [rectangle, draw] {machine};

                        \draw[->] (m) to (-.4, -.3);
                    \end{tikzpicture}
                \end{center}

                \`A la manière des automates, les machines de \textsc{Turing} ont un ensemble fini d'états, d'où la définition suivante :

                \begin{emphBox}
                    Une machine de \textsc{Turing} est un octuplet
                    \[
                        \lr{\Sigma, \Gamma, B, Q, q_0, q_a, q_r, \delta}
                    \]
                    où

                    $-$ $\Sigma$ est l'alphabet d'entrée 

                    ....................................................

                    $-$ $\Gamma$ est l'alphabet de ruban, ou de travail, tel que $\Sigma \subseteq \Gamma$ ;

                    $-$ $B \in \Gamma \setminus \Sigma$ est le symbole "blanc" représantant les cases vides ;

                    $-$ $Q$ est un ensemble fini non vide d'états ;

                    $-$ $q_0 \in Q$ est l'état initial ;

                    $-$ $q_a, q_r \in Q$ sont les états finaux de la machine : $q_a$ est appelé l'état acceptant, $q_r$ l'état rejetant ;

                    $-$ $\delta$ est la fonction de transition :
                    \[
                        \begin{array}{ccccc}
                            \delta
                            & : & \lr{Q \setminus \set{q_a, q_r}} \times \Gamma
                            & \longrightarrow & Q \times \Gamma \times \set{\leftarrow, \rightarrow}
                            \\
                            && (q, a)
                            & \longmapsto
                            & (q', b, d)
                        \end{array}
                    \]
                \end{emphBox}

                Si $\delta(q, a) = (q', b, d)$, alors lorsque la machine lit le symbole $a$ sur le ruban en étant dans l'état $q$, elle écrit le symbole $b$ à la place, déplace sa tête de lecture selon le déplacement $d$ et passe dans l'état $q'$.

                La machine accepte un mot $u \in \Sigma^*$ si et seulement si, en partant de l'état initial avec le ruban $B^\infty u B^\infty$ et la tête de lecture sur la première de $u$ (si elle existe), l'exécution mène à l'état $q_a$. Elle rejette $u$ si et seulement si elle atteint l'état $q_r$ et elle peut également ne pas terminer.

                \vspace{6pt}
                
                Une machine de \textsc{Turing} peut aussi calculer une fonction : l'argument est placé sur le ruban et le contenu du ruban à la fin de l'exécution est le résultat de la fonction.

                \vspace{12pt}
                
                $\bullet$ Exemple :
                \[
                    M = \lr{\set{0, 1}, \set{0, 1, B}, B, \set{q_0, q_1, q_2, q_a, q_r}, q_0, q_a, q_r, \delta}
                \]
                où $\delta$ est définie par la table :
                \begin{center}
                    \begin{tabular}{c|ccc}
                        & 0 & 1 & $B$
                        \\
                        \hline
                        $q_0$ & $(q_0, 0, \rightarrow)$ & $(q_1, 1, \rightarrow)$ & $(q_a, B, \leftarrow)$
                        \\
                        $q_1$ & $(q_1, 0, \rightarrow)$ & $(q_1, 1, \rightarrow)$ & $(q_2, B, \leftarrow)$
                        \\
                        $q_2$ & $(q_a, B, \rightarrow)$ & $(q_a, B, \rightarrow)$ & /
                    \end{tabular}
                \end{center}

                Avec $\lrangle{000}_2$ en entrée :
                \[
                    \begin{array}{ccc}
                        \begin{array}{ccccccccc}
                            q_0
                            \\
                            \hline
                            \cdots & \vline & 0 & \vline & 0 & \vline & 0 & \vline & \cdots
                            \\
                            \hline
                            && \uparrow
                        \end{array}
                        &
                        &
                        \begin{array}{ccccccccc}
                            q_0
                            \\
                            \hline
                            \cdots & \vline & \Emph 0 & \vline & 0 & \vline & 0 & \vline & \cdots
                            \\
                            \hline
                            &&&&  \uparrow
                        \end{array}
                        \\
                        \begin{array}{ccccccccc}
                            q_0
                            \\
                            \hline
                            \cdots
                            & \vline & 0 & \vline & \Emph 0 & \vline & 0 & \vline & \cdots
                            \\
                            \hline
                            &&&&&& \uparrow
                        \end{array}
                        &
                        &
                        \begin{array}{ccccccccc}
                            q_0
                            \\
                            \hline
                            \cdots
                            & \vline & 0 & \vline & 0 & \vline & \Emph 0 & \vline & \cdots
                            \\
                            \hline
                            &&&&&&&&  \uparrow
                        \end{array}
                        \\
                        \begin{array}{ccccccccc}
                            q_a
                            \\
                            \hline
                            \cdots
                            & \vline & 0 & \vline & 0 & \vline & 0 & \vline & \cdots
                            \\
                            \hline
                            &&&&&& \uparrow
                        \end{array}
                    \end{array}
                \]

                Avec $\lrangle{010}_2$ en entrée :
                \[
                    \begin{array}{ccc}
                        \begin{array}{ccccccccc}
                            q_0
                            \\
                            \hline
                            \cdots & \vline & 0 & \vline & 1 & \vline & 0 & \vline & \cdots
                            \\
                            \hline
                            && \uparrow
                        \end{array}
                        &
                        &
                        \begin{array}{ccccccccc}
                            q_0
                            \\
                            \hline
                            \cdots & \vline & \Emph 0 & \vline & 1 & \vline & 0 & \vline & \cdots
                            \\
                            \hline
                            &&&&  \uparrow
                        \end{array}
                        \\
                        \begin{array}{ccccccccc}
                            q_1
                            \\
                            \hline
                            \cdots
                            & \vline & 0 & \vline & \Emph 1 & \vline & 0 & \vline & \cdots
                            \\
                            \hline
                            &&&&&& \uparrow
                        \end{array}
                        &
                        &
                        \begin{array}{ccccccccc}
                            q_1
                            \\
                            \hline
                            \cdots
                            & \vline & 0 & \vline & 1 & \vline & \Emph 0 & \vline & \cdots
                            \\
                            \hline
                            &&&&&&&&  \uparrow
                        \end{array}
                        \\
                        \begin{array}{ccccccccc}
                            q_2
                            \\
                            \hline
                            \cdots
                            & \vline & 0 & \vline & 1 & \vline & 0 & \vline & \cdots
                            \\
                            \hline
                            &&&&&& \uparrow
                        \end{array}
                        &
                        &
                        \begin{array}{ccccccccc}
                            q_a
                            \\
                            \hline
                            \cdots
                            & \vline & 0 & \vline & 1 & \vline & \Emph B & \vline & \cdots
                            \\
                            \hline
                            &&&&&&&& \uparrow
                        \end{array}
                    \end{array}
                \]

                Avec $\lrangle{111}_2$ en entrée :
                \[
                    \begin{array}{ccc}
                        \begin{array}{ccccccccc}
                            q_0
                            \\
                            \hline
                            \cdots & \vline & 1 & \vline & 1 & \vline & 1 & \vline & \cdots
                            \\
                            \hline
                            && \uparrow
                        \end{array}
                        &
                        &
                        \begin{array}{ccccccccc}
                            q_1
                            \\
                            \hline
                            \cdots & \vline & \Emph 1 & \vline & 1 & \vline & 1 & \vline & \cdots
                            \\
                            \hline
                            &&&&  \uparrow
                        \end{array}
                        \\
                        \begin{array}{ccccccccc}
                            q_1
                            \\
                            \hline
                            \cdots
                            & \vline & 1 & \vline & \Emph 1 & \vline & 1 & \vline & \cdots
                            \\
                            \hline
                            &&&&&& \uparrow
                        \end{array}
                        &
                        &
                        \begin{array}{ccccccccc}
                            q_1
                            \\
                            \hline
                            \cdots
                            & \vline & 1 & \vline & 1 & \vline & \Emph 1 & \vline & \cdots
                            \\
                            \hline
                            &&&&&&&&  \uparrow
                        \end{array}
                        \\
                        \begin{array}{ccccccccc}
                            q_2
                            \\
                            \hline
                            \cdots
                            & \vline & 1 & \vline & 1 & \vline & 1 & \vline & \cdots
                            \\
                            \hline
                            &&&&&& \uparrow
                        \end{array}
                        &
                        &
                        \begin{array}{ccccccccc}
                            q_a
                            \\
                            \hline
                            \cdots
                            & \vline & 1 & \vline & 1 & \vline & \Emph B & \vline & \cdots
                            \\
                            \hline
                            &&&&&&&& \uparrow
                        \end{array}
                    \end{array}
                \]

                 Cette machine de \textsc{Turing} calcule la fonction
                 \[
                     \begin{array}{ccc}
                         \set{0, 1}^* & \longrightarrow & \set{0, 1}^*
                         \\
                         x & \longmapsto & y
                     \end{array}
                 \]
                 avec $\lrangle y _2 = \floor{\dfrac{\lrangle x _2} 2}$

                 On dit plus généralement que la machine calcule
                 \[
                     \begin{array}{ccc}
                         \N & \longrightarrow & \N
                         \\
                         n & \longmapsto & \floor{\dfrac n 2}
                     \end{array}
                 \]

                 De même, si on supprime $q_2$ et on remplace $\delta$ par la table
                 \[
                     \begin{array}{c|ccc}
                         & 0 & 1 & B
                         \\
                         \hline
                         q_0 & (q_0, 0, \rightarrow) & (q_0, 1, \rightarrow) & (q_1, B, \leftarrow)
                         \\
                         q_1 & (q_a, 0, \rightarrow) & (q_r, 1, \rightarrow) & /
                     \end{array}
                 \]

                 On obtient une machine qui reconnaît le langage $\set{u \in \set{0, 1}^*\ |\ \lrangle u _2 \equiv 0\ [2]}$.

                 Autrement dit, la machine calcule $2\N$.

                 \vspace{12pt}
                 
                 $\bullet$ Les modèles du $\lambda$-calcul et des machines de \textsc{Turing} sont pertinents pour l'étude théorique de la calculabilité grâce à leur "simplicité", mais ne sont pas pratiques pour l'écriture d'algorithmes concrets. C'est pourquoi on utilise en général un modèle différent pour l'écriture des algorithmes.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Modèle de calcul au programme de la MPI}}
                Le modèle de calcul considéré est celui d'un programme C ou OCaml qui s'exécute sur une machine à mémoire infinie.

                En particulier, il n'y a jamais de dépassement de capacité de la pile d'exécution et on peut toujours allouer de la mémoire sur le tas.

                Il est aisé de simuler une machine de \textsc{Turing} avec un programme C ou OCaml.
                Le sens réciproque est beaucoup plus difficile.

                Nous appelons \emph{algorithme} tout objet qui est un programme C ou OCaml, une machine de \textsc{Turing}, ou un $\lambda$-calcul.

                On s'autorisera l'usage du pseudo-code pour l'écriture d'algorithmes.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Caclulabilité}}
                \label{1.1.4}

                Le terme \emph{fonction} étant ambigu (fonction mathématique, fonctions dans un programme), on utilisera ce terme uniquement pour les fonctions mathématiques. Un algorithme peut être vu comme une réalisation d'une fonction mathématique partielle : celle qui à chaque entrée de l'algorithme sur la pile d'exécution se termine associe la valeur de retour de l'algorithme.

                \vspace{12pt}
                
                $\bullet$ Définition (\emph{fonction calculable}) : une fonction $f : A \longrightarrow B$ est dite \emph{calculable} s'il existe un algorithme $M$ tel que $\forall a \in A$, l'exécution de $M$ sur $a$ termine en temps fini, et renvoie $f(a)$.

                \vspace{12pt}
                
                $\bullet$ Remarques :

                $-$ Il est "facile" de montrer qu'une fonction est calculable : il "suffit" d'exhiber un algorithme qui convient.

                Il est en revanche beaucoup plus difficile de montrer qu'une fonction n'est pas calculable : il faut montrer qu'aucun algorithme ne peut convenir.

                \vspace{6pt}
                
                \begin{indt}{$-$ On va se limiter aux fonctions de $\N \longrightarrow \N$. En effet :}
                    $+$ si $A$ est fini, on peut se contenter de tabuler les valeurs de $f$ et d'écrire un algorithme qui va chercher dans la table la bonne valeur.

                    $+$ Si $A$ est indémontrable, on a un problème de représentation de l'entrée : on a besoin de représentation infinies, ce qui est peu pertinent dans l'optique d'étudier ce qu'une machine réelle peut calculer.

                    $+$ On utilise en général des encodages pour représenter les données manipulées et un encodage binaire peut être vu comme un entier non signé (donc un entier naturel).
                \end{indt}

                \vspace{12pt}
                
                $\bullet$ Proposition :

                \begin{emphBox}
                    Il existe une infinité de fonctions non calculables.
                \end{emphBox}

                \vspace{6pt}
                
                \begin{proof}
                    Il suffit de montrer que $\N^\N$ est indénombrable car l'ensemble des algorithmes est dénombrable (l'ensemble des codes sources s'injecte dans l'ensemble des chaînes de caractères, dénombrable).

                    $\N^\N$ est indénombrable car $\set{0, 1}^\N$ l'est déjà d'après le théorème de \textsc{Cantor} (on voit une fonction $\N \longrightarrow \set{0, 1}$ comme la fonction indicatrice d'une partie de $\N$).

                    \vspace{12pt}
                    
                    Argument diagonal (pour montrer que $\set{0, 1}^\N$ n'est pas dénombrable) : on suppose que $\set{0, 1}^\N$ est dénombrable. Alors on peut numéroter les suites de $\set{0, 1}$ :
                    \[
                        \begin{array}{ccccc}
                            s_0 & 0 & 0 & 0 & \cdots
                            \\
                            s_1 & 1 & 0 & 0 & \cdots
                            \\
                            s_2 & 0 & 1 & 0 & \cdots
                            \\
                            \vdots
                        \end{array}
                    \]

                    On a $\forall n \in \N,\ s_n = \lr{s_{n, k}}_{k \in \N} \in \set{0, 1}^\N$, \textit{i.e} $\lr{s_{n, k}}_{n, k \in \N} \in \lr{\set{0, 1}^\N}^\N$.

                    Soit $\forall n \in \N,\ u_n = 1 - s_{n, n}$. Alors :
                    \[
                        \lr{u_n}_{n \in \N} \in \set{0, 1}^\N
                    \]

                    Mais $\forall n \in \N,\ s_n \neq \lr{u_k}_{k \in \N}$ : absurde.
                \end{proof}
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Universalité}}
                \label{1.1.5}

                $\bullet$ On utilise souvent un argument diagonal pour montrer qu'une fonction n'est pas calculable : on procède par l'absurde en supposant l'existence d'un algorithme $M$ convenable et en construisant un algorithme qui utilise $M$, souvent en faisant référence à son propre code source, pour aboutir à une absurdité (\textit{cf} \ref{1.2.4}, page \pageref{1.2.4}).

                \begin{indt}{Ce type de démonstration nécessite deux propriétés essentielles :}
                    $-$ L'autoréférence, \textit{i.e} la possibilité de faire référence à son propre code source. C'est possible car l'ensemble des algorithmes est dénombrable : on peut faire référence à un algorithme par son numéro.

                    $-$ La simulation : il faut pouvoir simuler l'exécution d'un algorithme afin d'exploiter le résultat.
                \end{indt}

                \vspace{12pt}
                
                $\bullet$ Théorème :
                \begin{emphBox}
                    Il existe un algorithme, appelé machine universelle, d'entrée un algorithme $M$ et une entrée $x$ pour $M$, qui simule l'exécution de $M$ sur $x$.
                \end{emphBox}

                \begin{proof}
                    (démonstration informelle)

                    On passe par les machines de \textsc{Turing}.

                    Comme les machines à plusieurs rubans sont équivalentes aux machines à un ruban, on construit une machine qui a le code de $M$ sur son ruban d'entrée, l'état courant de $M$ dans l'exécution sur $x$, dans un deuxième ruban et le ruban de travail de $M$ dans un troisième ruban.
                \end{proof}
            \end{indt}
        \end{indt}

        \vspace{12pt}
        
        \begin{indt}{\subsection{Décidabilité}}
            \begin{indt}{\subsubsection{Introduction}}
                On s'intéresse maintenant à des fonctions particulières : les \emph{prédicats}, \textit{i.e} les fonctions à valeur dans les booléens (ou $\set{0, 1}$).
                Ces fonctions sont importantes car elles expriment des propriétés des éléments de l'ensemble qui constitue le domaine du prédicat : on veut pouvoir déterminer si un objet satisfait une propriété à l'aide d'un algorithme.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Problèmes de décision, d'optimisation}}
                \label{1.2.2}

                $\bullet$ Définition (\textit{problème de décision}) :
                Un problème de décision sur un domaine $A$ est défini par une fonction totale $P$ de $A$ dans l'ensemble des booléens.

                Un élément $a \in A$ est appelé une \emph{instance} du problème $P$ et un algorithme $M$ résout $P$ si et seulement si $\forall a \in A,\ M$ appliqué à $a$ termine et revoie $P(a)$.

                \vspace{12pt}
                
                $\bullet$ Remarques :

                $-$ On utilise rarement la définition d'un prédicat pour caractériser un problème de décision mais on préfère utiliser un énoncé en langue naturelle.

                Exemple : SAT : \simplecit{étant donné une formule propositionnelle $A$, $A$ est-elle satisfiable ?}

                plutôt que
                \[
                    \begin{array}{ccccl}
                        \mathrm{SAT}
                        & : & \mathrm{Formules\_prop}
                        & \longrightarrow & \set{0, 1}
                        \\
                        && A & \longmapsto &
                        \begin{cases}
                            0 & \text{si}\ \vDash \neg A
                            \\
                            1 & \text{sinon}
                        \end{cases}
                    \end{array}
                \]

                Attention lors de l'expression d'un problème de décision, ne pas se limiter à une instance : par exemple, l'énoncé \simplecit{la formule $X \vee \neg X$ est-elle satisfiable ?} n'est pas un problème de décision car la réponse à cette question est \simplecit{oui} ou \simplecit{non}, mais pas un algorithme, même s'il est possible d'utiliser un algorithme pour déterminer cette réponse.

                Remarque : on pourrait reformuler cette question pour écrire un problème de décision (de domaine $\set{X \vee \neg X}$) mais comme dans le cas de la calculabilité, les problèmes de décision de domaine fini sont peu intéressants car on peut tabuler les réponses et écrire un algorithme allant chercher dans la table la réponse à l'instance considérée.

                Attention, même si ces problèmes sont triviaux du point de vue de la décidabilité, ils peuvent être beaucoup plus complexes d'un point de vue algorithmique car il peut être en pratique impossible de tabuler les réponses.

                Exemple : étant donné une position au jeu d'échecs, le joueur au trait est-il gagnant ?

                \vspace{6pt}
                
                $-$ De nombreux problèmes de décision intéressants découlent de problèmes d'optimisation.

                \vspace{12pt}
                
                $\bullet$ Définition (\textit{problème d'optimisation}) :
                Un problème d'optimisation sur un domaine d'entrées $A$ et un domaine de solutions $B$ est caractérisé par une relation $\mathcal R \subseteq A \times B$ qui lie les instances $a \in A$ aux solutions $b \in B$ possibles pour cette instance, et une fonction de coût $c : B \longrightarrow \R_+$.

                Une \emph{solution} à un problème d'optimisation est un algorithme $M$ qui termine et renvoie une solution $b_{\rm min} \in B$ telle que
                \[
                    \begin{cases}
                        a \mathcal R b_{\rm min}
                        \\
                        c(b_{\rm min}) = \min \set{c(b)\ |\ a \mathcal R b}
                    \end{cases}
                \]

                \vspace{12pt}
                
                $\bullet$ Exemple : étant donné un graphe $G = (S, A')$, trouver une coloration de $G$ ayant un nombre minimal de couleurs.
                \[
                    \begin{array}{rcl}
                        A
                        &=& \text{ensemble des graphes}
                        \\
                        B
                        &=& \text{ensemble des colorations}
                        \\
                        G \mathcal R f
                        &\ssi&
                        \begin{cases}
                            \mathrm{dom}(f) = S
                            \\
                            \forall a = \set{s, s'} \in A',\ f(s) \neq f(s')
                        \end{cases}
                        \\
                        &\ssi& f\ \text{est une coloration valide de}\ G
                        \\
                        c
                        &=& \text{fonction qui à chaque coloration associe le nombre de couleurs utilisées}
                    \end{array}
                \]

                \vspace{12pt}
                
                $\bullet$ On transforme un problème d'optimisation en problème de décision en introduisant un plafond sur les coûts $c_{\rm max}$ et en considérant le prédicat
                \[
                    \begin{array}{ccccc}
                        P_{c_{\rm max}}
                        & : & A & \longrightarrow & \set{0, 1}
                        \\
                        && a & \longmapsto &
                        \begin{cases}
                            1 & \text{si}\ \exists b \in B\
                            \begin{array}{|l}
                                a \mathcal R b
                                \\
                                c(b) \le c_{\rm max}
                            \end{array}
                            \\
                            0 & \text{sinon}
                        \end{cases}
                    \end{array}
                \]

                Exemple : un graphe $G$ est-il 3-coloriable ? ou 4-coloriable ?

                On peut également inclure le plafond dans le domaine du problème de décision :
                \[
                    \begin{array}{ccccl}
                        P
                        & : & A \times \R^+ & \longrightarrow & \set{0, 1}
                        \\
                        && (a, c_{\rm max}) & \longmapsto &
                        \begin{cases}
                            1 & \text{si}\ \exists b \in B\
                            \begin{array}{|l}
                                a \mathcal R b
                                \\
                                c(b) \le c_{\rm max}
                            \end{array}
                            \\
                            0 & \text{sinon}
                        \end{cases}
                    \end{array}
                \]

                Exemple : étant donné un graphe $G$ et un entier $k$, $G$ est-il $k$-coloriable ?
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Problèmes décidables / indécidables}}
                $\bullet$ Définition : un problème de décision caractérisé par un prédicat $P$ est dit \emph{décidable} si et seulement si il existe un algorithme qui le résout, ou de façon équivalente, si et seulement si $P$ est calculable.

                Dans le cas contraire, $P$ est dit \emph{indécidable}.

                \vspace{12pt}
                
                $\bullet$ Exemples :

                $-$ Une liste d'entiers est-elle triée ? (domaine : ensemble des listes d'entiers)

                $-$ Un entier est-il premier ? (domaine : $\N$)

                $-$ Un graphe est-il acyclique ? (domaine : ensemble des graphes)

                $-$ Un mot $m$ est-il accepté par un AFD $M$ ? (domaine : produit cartésien de $\Sigma^*$ et de l'ensemble des automates finis déterministes sur $\Sigma$, pour $\Sigma$ fixé).
                \vspace{12pt}
                
                $\bullet$ Proposition
                \begin{emphBox}
                    Il existe une infinité de problèmes indécidables
                \end{emphBox}
                
                \begin{proof}
                    \textit{Cf} \ref{1.1.4}, page \pageref{1.1.4}.
                \end{proof}
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Problème de l'arrêt}}
                \label{1.2.4}

                $\bullet$ Définition : le \emph{problème de l'arrêt} est le problème de décision suivant : étant donné un algorithme $M$ et une entrée $e$ pour $M$, l'exécution de $M$ sur $e$ termine-t-elle ?

                \vspace{12pt}
                
                $\bullet$ Remarque : en pratique, le domaine de ce problème de décision est contraint à partir de l'ensemble des codes sources des algorithmes car il faut une représentation manipulable par un algorithme (comme en \ref{1.1.4}, page \pageref{1.1.4}, on s'intéresse aux algorithmes d'entrées des chaînes de caractère ou des écritures binaires).

                \vspace{12pt}
                
                $\bullet$ Théorème
                \begin{emphBox}
                    Le problème de l'arrêt est indécidable.
                \end{emphBox}

                \vspace{6pt}
                
                \begin{proof}
                    Par l'absurde, avec un argument diagonal comme évoqué en \ref{1.1.5}, page \pageref{1.1.5}.

                    On suppose qu'il existe un algorithme $H$ qui résout le problème de l'arrêt.

                    On construit l'algorithme $D$ d'entrées un algorithme $M$ et de pseudo-code :
                    \begin{indalgo}{$D$}
                        Simuler $H$ sur l'entrée $(M, M)$\;

                        \If{résultat est vrai}{
                            Boucler indéfiniment\;
                        }
                        \Else{
                            Terminer\;
                        }
                    \end{indalgo}

                    On observe alors l'exécution de $D$ sur l'entrée $D$.

                    $-$ Si $H$ renvoie vrai pour l'entrée $(D, D)$, c'est que $D$ termine sur son propre code.
                    Mais dans ce cas, $D$ boucle indéfiniment : absurde.

                    $-$ Si $H$ revoie faux pour l'entrée $(D, D)$, c'est que $D$ ne termine pas sur son propre code.

                    Mais dans ce cas, $D$ termine bien d'après la suite du code : absurde.

                    $H$ réalisant une fonction totale, il termine toujours, donc on a traité tous les cas.
                \end{proof}

                \vspace{12pt}
                
                $\bullet$ Remarque : c'est une réécriture du paradoxe du barbier : un algorithme qui ne termine pas sur le code de tout algorithme qui termine sur son propre code termine-t-il sur son propre code ?
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Problèmes semi-décidables (H.P)}}
                \label{1.2.5}

                $\bullet$ Définition : un problème de décision caractérisé par un prédicat $P$ est dit semi-décidable si et seulement si il existe un algorithme $M$ tel que $\forall a \in A$,

                $-$ Si $P(a)$, alors $M$ termine sur $a$, et renvoie vrai ;

                $-$ Si $\neg P(a)$, alors soit $M$ termine sur $a$ et renvoie faux, soit $M$ ne termine pas sur $a$.

                \vspace{12pt}
                
                $\bullet$ Proposition :
                \begin{emphBox}
                    Le problème de l'arrêt est semi-décidable.
                \end{emphBox}

                \vspace{6pt}
                
                \begin{proof}
                    Sur l'entrée $(M, e)$, il suffit de simuler $M$ sur $e$ puis de renvoyer vrai.

                    Si $M$ termine sur $e$, l'algorithme renvoie bien vrai, sinon il ne termine pas.
                \end{proof}

                \vspace{12pt}
                
                $\bullet$ Proposition
                \begin{emphBox}
                    Soit $P$ un problème de décision.

                    On appelle $\mathrm{co}(P)$ le problème de décision associé au prédicat $\neg P$.

                    Si $P$ et $\mathrm{co}(P)$ sont semi-décidables, alors $P$ est décidable.
                \end{emphBox}

                \vspace{6pt}
                
                \begin{proof}
                    On se donne des algorithmes $M_P$ et $M_{\mathrm{co}(P)}$ tels que $\forall A \in \set{P, \mathrm{co}(P)}$, $M_A$ termine et revoie vrai sur toute instance $a$ telle que $A(a)$ et ne termine pas ou renvoie faux sinon.

                    On construit l'algorithme suivant, qui résout $P$ :

                    \begin{indalgo}{}
                        \KwInput{une instance $a$}

                        \BlankLine

                        Simuler en parallèle $M_P$ et $M_{\mathrm{co}(P)}$ sur $a$\;

                        \If{$M_P$ termine}{
                            Renvoyer son résultat\;
                        }
                        \If{$\mathrm{co}(P)$ termine}{
                            Renvoyer la négation de son résultat\;
                        }
                    \end{indalgo}

                    On sait que cet algorithme termine sur toute entrée $a$ car soit $P(a)$, soit $\neg P(a)$ (tiers exclus).
                \end{proof}

                \vspace{12pt}
                
                $\bullet$ Corollaire :
                \begin{emphBox}
                    co Arrêt n'est pas semi-décidable.
                \end{emphBox}

                \'Etant donné un algorithme $M$ et une entrée $e$, l'exécution de $M$ sur $e$ est-elle finie ?

                \vspace{12pt}
                
                $\bullet$ Remarque : la réciproque de la proposition est vraie \boxed{\rm Exo}.

                \vspace{12pt}
                
                $\bullet$ Exemple : un autre problème non semi-décidable : \simplecit{étant donné un algorithme $M$, est-ce que $M$ ne renvoie pas vrai sur son propre code source, \textit{i.e} est-ce que $M$ appliqué à son code renvoie faux ou ne termine pas ?}

                Par un argument diagonal : si $D$ termine et renvoie vrai sur tout $M$ respectant la propriété et renvoie faux ou ne termine pas sur les autres.

                Si l'exécution de $D$ sur $D$ :

                $-$ ne termine pas, alors par définition de la semi-décidabilité, $D$ doit renvoyer vrai sur son code : absurde

                $-$ termine avec le résultat faux, de même : absurde

                $-$ termine avec le résultat vrai, alors $D$ ne renvoie pas vrai sur son code : absurde

                \vspace{21pt}
                
                Remarque : le co-problème de ce problème de décision est semi-décidable et indécidable.

                Il existe des problèmes  non semi-décidables dont le co-problème n'est pas semi-décidable (\textit{cf} TD$_{45}$).
            \end{indt}
        \end{indt}

        \vspace{12pt}
        
        \begin{indt}{\subsection{Réduction}}
            \begin{indt}{\subsubsection{Introduction}}
                Pour montrer qu'un problème de décision $P$ est décidable ou indécidable, une technique courante consiste à lier ce problème à un problème dont la décidabilité ou l'indécidabilité est déjà connue.
                En effet, si $P'$ est décidable et si on peut ramener algorithmiquement la résolution de $P$ à celle de $P'$, alors $P$ est décidable.

                Inversement, si on peut ramener la résolution d'un problème $P'$ indécidable à celle de $P$, alors $P$ est indécidable.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Exemple}}
                On considère le problème de la trivialité : étant donné un algorithme $M$ à valeurs booléennes, $M$ renvoie-t-il \texttt{true} sur toute entrée ?

                On montre que ce problème est indécidable en le liant au problème de l'arrêt.

                On suppose donc l'existence d'un algorithme $M_T$ qui résout le problème de la trivialité et on construit l'algorithme suivant, d'entrées un algorithme $M$ et une entrée $e$ pour $M$ :

                \begin{algoBox}
                    \begin{algorithm}[H]
                        \KwInput{$M$, $e$}
                    
                        \BlankLine

                        Construire l'algorithme $M'$ d'entrée $e'$ et de code :

                        \setcounter{algocf}{3}
                        \begin{algorithm}[H]
                            \KwInput{$e'$}

                            \BlankLine

                            Simuler $M$ sur $e$\;
                            Renvoyer \texttt{true}\;

                            \caption{$M'$}
                        \end{algorithm}
                    
                        \BlankLine
                    
                        Simuler $M_T$ sur $M'$ et renvoyer son résultat\;

                        \setcounter{algocf}{2}
                        \caption{Réduction de \textsc{Arrêt} à \textsc{Trivialité}}
                    \end{algorithm}
                \end{algoBox}

                \setcounter{algocf}{4}

                Comme $M_T$ réalise une fonction totale, $M_T$ termine sur toute entrée, donc l'algorithme ci-dessus aussi.

                On montre que cet algorithme résout le problème de l'arrêt : sur l'entrée $(M, e)$, l'algorithme renvoie \texttt{true}
                $\ssi$ si $M_T$ renvoie \texttt{true} sur l'entrée $M'$
                $\ssi$ $M'$ renvoie \texttt{true} sur toute entrée,
                $\ssi$ $M$ termine sur $e$.

                On a donc un algorithme qui résout le problème de l'arrêt, ce qui est absurde d'après \ref{1.2.4} (page \pageref{1.2.4}).
                Donc le problème de la trivialité est indécidable.

                \vspace{12pt}
                
                Remarque : on a écrit un algorithme qui transforme toute instance du problème de l'arrêt en une instance "équivalente" du problème de la trivialité.
                On dit donc que l'on a \emph{réduit} le problème de l'arrêt au problème de la trivialité.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Réduction calculatoire}}
                \label{1.3.3}

                $\bullet$ Définition :
                soient deux prédicats $P_1 : E_1 \longrightarrow \mathtt{bool}$ et $P_2 : E_2 \longrightarrow \mathtt{bool}$.

                On dit que le problème de décision associé à $P_1$ se \emph{réduit calculatoirement} à celui associé à $P_2$ s'il existe une fonction $f : E_1 \longrightarrow E_2$ calculable telle que $\forall e \in E_1,\ P_1(e) \leftrightarrow P_2(f(e))$.

                On note alors $P_1 \le_m P_2$ et on dit que $f$ est une \emph{réduction} de $P_1$ à $P_2$.

                \vspace{12pt}
                
                $\bullet$ Remarques :

                $-$ On utiliser un symbole lié aux relations d'ordre car les réductions permettent "d'ordonner" les problèmes selon leur difficulté : si $P_1 \le_m P_2$, alors $P_2$ est plus difficile à résoudre que $P_1$ car si l'on dispose des moyens nécessaires à la résolution de $P_2$, on sait également résoudre $P_1$ \textit{via} la réduction.

                $-$ Le $m$ du symbole $\le_m$ vient du mot anglais de cette notion de réduction : on parle de \emph{mapping reducibility}, ou de \emph{many-to-one / many-one reducibility} (car $f$ n'est pas forcément injective).

                On parle aussi parfois de \emph{computational reducibility}.

                \vspace{12pt}
                
                $\bullet$ Proposition :
                \begin{emphBox}
                    Soient $P_1, P_2$ deux problèmes de décision tels que $P_1 \le_m P_2$.

                    Alors

                    (1) Si $P_2$ est décidable, alors $P_1$ aussi.

                    (2) Si $P_1$ est indécidable, alors $P_2$ aussi.
                \end{emphBox}

                \vspace{6pt}
                
                \begin{proof}
                    (2) est la contraposée de (1), donc on démontre seulement (1).

                    Il existe un algorithme $M_2$ qui résout $P_2$.

                    Comme $P_1 \le_m P_2$, il existe un algorithme $M_f$ qui réalise une réduction de $P_1$ à $P_2$.

                    On construit l'algorithme $M_1$ d'entrée un instance $e$ de $P_1$ :

                    \begin{indalgo}{$M_1$}
                        Simuler $M_f$ sur $e$ et noter $e'$ son résultat\;

                        Simuler $M_2$ sur $e'$ et renvoyer son résultat\;
                    \end{indalgo}

                    $M_1$ termine sur toute entrée car c'est le cas pour $M_f$ et $M_2$.

                    Pour une instance $e$ de $P_1$, $M_1$ renvoie vrai
                    \[
                        \begin{array}{cl}
                            \ssi & M_2\ \text{renvoie vrai sur l'instance $e'$ associée à $e$}
                            \\
                            \ssi & M_2\ \text{renvoie vrai sur}\ f(e)
                            \\
                            \ssi & P_2(f(e)) \ \text{est vrai}
                            \\
                            \ssi & P_1(e) \ \text{est vrai}
                        \end{array}
                    \]

                    Donc l'algorithme $M_1$ résout $P_1$.
                \end{proof}

                \vspace{12pt}
                
                $\bullet$ Attention à ne pas se tromper sur le sens de la réduction : 

                Exemple : on considère le problème de l'accessibilité dans un graphe : étant donné un graphe $G = (S, A)$ et $s, t \in S$, existe-t-il un chemin de $s$ à $t$ dans $G$ ?

                Ce problème est décidable : on lance un parcours de $G$ depuis $s$ et on revoie \texttt{true} si et seulement si $t$ est atteint.

                On montre que \textsc{Accessibilité} $\le_m$ \textsc{Arrêt}, ce qui n'apporte aucune information : le problème de l'arrêt est plus difficile que tout problème décidable puisqu'il est indécidable.

                Voici un réduction, d'entrée $G, s, t$ :

                \begin{algoBox}
                    \begin{algorithm}[H]
                        \KwInput{$G, s, t$}
                    
                        \BlankLine
                    
                        Définir l'algorithme $M_{G, s}$, d'entrée un sommet $u$ :
                        \begin{algorithm}[H]
                            \KwInput{$u$}
                    
                            \BlankLine
                    
                            \For{chaque $n \in \N$}{
                                \For{chaque séquence $s_0 \cdots s_n$ de sommets}{
                                    \If{$s_0 \cdots s_n$ est un chemin dans $G$ de $s$ à $u$}{
                                        \Return \texttt{true}\;
                                    }
                                }
                            }


                            \setcounter{algocf}{6}
                            \caption{$M_{G, s}$}
                        \end{algorithm}

                        \BlankLine
                    
                        \Return $(M_{G, s}, t)$\;

                        \setcounter{algocf}{5}
                        \caption{Réduction de \textsc{Accessibilité} à \textsc{Arrêt}}
                    \end{algorithm}
                \end{algoBox}

                \setcounter{algocf}{7}

                On remarque qu'il existe un chemin de $s$ à $t$ dans $G$ si et seulement si l'algorithme $M_{G, s}$ termine sur $t$.

                On a donc bien construit une réduction calculatoire du problème de l'accessibilité au problème de l'arrêt.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Réduction \textsc{Turing}}}
                $\bullet$ Remarque : la notion de réduction calculatoire est insuffisante pour capturer l'intuition de la notion de réduction. En effet, intuitivement, \textsc{Arrêt} et co(\textsc{Arrêt}) devraient être réductibles l'un à l'autre car si l'on sait résoudre l'un, on peut résoudre l'autre en inversant les réponses d'un algorithme de décision.
                Cependant, si on avait co(\textsc{Arrêt}) $\le_m$ \textsc{Arrêt}, alors co(\textsc{Arrêt}) serait semi-décidable \boxed{\rm Exo}, ce qui est absurde d'après \ref{1.2.5} (page \pageref{1.2.5}).

                Nous avons donc besoin d'une notion plus générale de réduction.

                \vspace{12pt}
                
                $\bullet$ Définition (\emph{réduction \textsc{Turing}}) :
                Soient $P_1 : E_1 \longrightarrow \mathtt{bool}$ et $P_2 : E_2 \longrightarrow \mathtt{bool}$ deux problèmes de décision.

                On dit que $P_1$ est \emph{\textsc{Turing}-réductible} à $P_2$ si, en supposant l'existence d'un algorithme qui résout $P_2$, il existe un algorithme qui résout $P_1$.

                On note alors $P_1 \le_T P_2$, et on dit que $P_1$ est décidable relativement à $P_2$.

                \vspace{12pt}
                
                $\bullet$ Remarque : cette notion est liée aux machines de \textsc{Turing} à oracle (H.P), qui sont des machines pouvant effectuer des requêtes à un oracle, \textit{i.e} à un outil qui peut "magiquement" résoudre le problème associé, même si ce problème est indécidable.

                \vspace{12pt}
                
                $\bullet$ Proposition :
                \begin{emphBox}
                    Soient $P_1, P_2$ deux problèmes de décision tels que $P_1 \le_T P_2$.

                    Alors :

                    (1) Si $P_2$ est décidable, alors $P_1$ aussi.

                    (2) Si $P_1$ est indécidable, alors $P_2$ aussi.
                \end{emphBox}

                \vspace{12pt}
                
                \begin{proof}
                    Comme en \ref{1.3.3} (page \pageref{1.3.3}), il suffit de montrer (1).

                    Il existe un algorithme $M_2$ qui résout $P_2$.

                    Par définition de $P_1 \le_T P_2$, il existe donc un algorithme $M_1$ qui résout $P_1$.

                    En pratique, cet algorithme est construit ainsi : on utilise la machine à oracle qui résout $P_1$ à l'aide d'un oracle pour $P_2$ et on remplace cet oracle par l'algorithme $M_2$, ce qui donne un algorithme sans oracle qui résout $P_1$.
                \end{proof}

                \vspace{12pt}
                
                $\bullet$ Exemple : co(\textsc{Arrêt}) $\le_T$ \textsc{Arrêt}.

                On suppose qu'il existe un algorithme $M_H$ qui résout le problème de l'arrêt.

                On construit alors l'algorithme $M_{\neg H}$, d'entrée un algorithme $M$ et une entrée $e$ pour $M$ :

                \begin{indalgo}{}
                    Simuler $M_H$ sur $(M, e)$ et noter $b$ son résultat\;

                    Renvoyer $\neg b$\;
                \end{indalgo}

                Cet algorithme termine sur toute entrée car c'est le cas pour $M_H$.

                Sur l'entrée $(M, e)$, $M_{\neg H}$ renvoie \texttt{true} $\ssi$ $M_H$ renvoie \texttt{false} sur $(M, e)$ $\ssi$ $M$ ne termine pas sur $e$.

                Donc $M_{\neg H}$ résout co(\textsc{Arrêt}) et co(\textsc{Arrêt}) $\le_T$ \textsc{Arrêt}.

                \vspace{12pt}
                
                $\bullet$ Remarque : cette réduction ne pose aucun problème du point de vue de la semi-décidabilité : une machine à oracle pour \textsc{Arrêt} faisant appel à l'algorithme de semi-décision pour \textsc{Arrêt} sur une instance sur laquelle il ne termine pas (donc une entrée $(M, e)$ telle que $M$ ne termine pas sur $e$), alors la machine ne peut s'arrêter pour renvoyer la réponse "vrai" pour co(\textsc{Arrêt}), ce qui empêche d'avoir un algorithme de semi-décision pour co(\textsc{Arrêt}).

                La différence entre réduction calculatoire et réduction \textsc{Turing} est la suivante : dans le cas d'une réduction calculatoire, in ne peut faire qu'un appel à l'oracle et on doit renvoyer directement son résultat alors que dans le cas d'une réduction \textsc{Turing} on peut effectuer des calculs supplémentaires qui dépendent de la réponse de l'oracle.

                Autrement dit, si $P_1 \le_m P_2$, alors $P_1 \le_T P_2$, mais la réciproque est fausse.
            \end{indt}
        \end{indt}
    \end{indt}

    \vspace{12pt}
    
    \begin{indt}{\section{Classes de complexité}}
        \begin{indt}{\subsection{Introduction}}
            \begin{indt}{\subsubsection{Motivation}}
                Jusqu'ici, nous n'avons évoqué la que la complexité d'un algorithme donné.
                Un problème de décision donné peut être résolu par plusieurs algorithme : comment définir la complexité d'un problème de décision ?

                Idée : on pourrait considérer la complexité du meilleur algorithme qui résout le problème.
                Pas clair : existe-il un algorithme de complexité meilleure que celle de tous les autres ?

                On va donc inverser le point de vue : au lieu d'associer une complexité à un problème, on associe un ensemble de problème à chaque complexité.
                Un problème de décision appartient à une classe de complexité s'il peut être résolu avec un algorithme de la complexité associé à la classe.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Complexité}}
                On rappelle que le modèle de calcul est celui d'un programme C ou OCaml s'exécutant sur une machine à mémoire infinie.

                \vspace{12pt}
                
                $\bullet$ Définition (\textit{opération élémentaire}) :
                On appelle \emph{valeur atomique} toute valeur qui s'écrit avec un nombre fini fixé à l'avance de bits (par exemple : un mot machine).

                \begin{indt}{Les opérations élémentaires sont :}
                    $-$ Les opérations arithmétiques sur les valeurs atomiques ;

                    $-$ Les comparaisons de valeurs atomiques ;

                    $-$ Les lectures et écritures en mémoire de valeurs atomiques.
                \end{indt}

                \vspace{12pt}
                
                $\bullet$ Définition (\textit{complexité d'un algorithme}) :
                Soit $M$ un algorithme.

                On appelle \emph{complexité} (temporelle dans le pire cas) de $M$ la fonction de $\N \longrightarrow \N$ qui à tout $n \in \N$ associe le maximum du nombre d'opérations élémentaires exécutées par $M$ sur une entrée de taille $n$, où la taille d'une entrée est le nombre de valeurs atomiques nécessaires à sa description.

                \vspace{12pt}
                
                $\bullet$ Remarque : plutôt que d'exprimer la complexité d'un algorithme $M$, on a l'habitude d'en donner l'ordre de grandeur (symbole $\Theta$) ou un majorant (symbole $\mathcal O$).
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Classes de complexité}}
                \label{2.1.3}

                On se limite aux classes de complexité temporelles (les classes de complexité spatiales sont H.P).

                \vspace{12pt}
                
                $\bullet$ Définition :
                Soit $t : \N \longrightarrow \N$.

                On note $\mathrm{DTIME}(t(n))$ l'ensemble des problèmes de décision résolubles avec un algorithme de complexité $\mathcal O(t(n))$.

                \vspace{12pt}
                
                $\bullet$ Remarque : le D de DTIME signifie \emph{déterministe} : le modèle de calcul est celui des algorithmes déterministes : pas d'algorithmes randomisés / probabilistes (\textit{cf} chapitre 17).

                \vspace{12pt}
                
                $\bullet$ Exemple : On considère le problème $P_{\rm sort}$ : étant donné deux tableaux de taille $t_1$ et $t_2$, $t_2$ est-il une version tirée de $t_1$ ?

                En testant l'égalité entre $t_2$ et toutes les permutations de $t_1$, on montre que $P_{\rm sort} \in \mathrm{DTIME}(n! \cdot n)$.

                En triant $t_1$ et en comparant avec $t_2$, on montre que $P_{\rm sort} \in \mathrm{DTIME}(n \log n)$.

                \vspace{12pt}
                
                $\bullet$ Proposition :
                \begin{emphBox}
                    Soient $f, g \in \N^\N\ |\ f(n) = \mathcal O(g(n))$.

                    Alors
                    \[
                        \mathrm{DTIME}(f(n)) \subseteq \mathrm{DTIME}(g(n))
                    \]
                \end{emphBox}

                \vspace{6pt}
                
                \begin{proof}
                    $f(n) = \mathcal O(g(n))$, donc
                    \[
                        \exists C > 0,\ \exists N \in \N\ |\
                        \forall n \ge N,\
                        f(n) \le C g(n)
                    \]

                    Soit $P \in \mathrm{DTIME}(f(n))$.

                    Il existe $M$ qui résout $P$ avec une complexité $\mathcal O(f(n))$, \textit{i.e}
                    $
                        \exists C' > 0,\ \exists N' \in \N\ |\
                        \forall n \ge N',\
                        \forall e\ \text{entrée de taille}\ n
                    $,
                    l'exécution de $M$ sur $e$ effectue $\le C'C g(n)$ opérations élémentaires

                    Donc $M$ est de complexité $\mathcal O(g(n))$.

                    Donc $P \in \mathrm{DTIME}(g(n))$.
                \end{proof}
            \end{indt}
        \end{indt}

        \vspace{12pt}
        
        \begin{indt}{\subsection{Les classes $\mathbf P$ et $\mathbf{NP}$}}
            \begin{indt}{\subsubsection{La classe $\mathbf P$}}
                $\bullet$ Définition : la classe $\mathbf P$ est
                \[
                    \bigcup_{k \in \N} \mathrm{DTIME}\!\lr{n^k}
                \]

                \textit{i.e} la classe des problèmes de décision résoluble en temps polynomial.

                \vspace{12pt}
                
                $\bullet$ Exemples :

                $-$ Le problème de l'accessibilité (\textit{cf} \ref{1.3.3}, page \pageref{1.3.3}) appartient à $\mathbf P$ : on le résout à l'aide d'un parcours du graphe, donc en temps linéaire en la taille du graphe.

                $-$ Le meilleurs algorithme de tri par comparaison est de complexité $\mathcal O(n \log n) = \mathcal O(n^2)$, donc polynomiale, mais le problème \simplecit{trier un tableau donné} n'est pas un problème de décision.

                En revanche, le problème $P_{\rm sort}$ vu en \ref{2.1.3} (page \pageref{2.1.3}) appartient à $\mathbf P$.

                $-$ Le problème suivant : \simplecit{étant donné une grammaire algébrique sous forme normale de \textsc{Chomsky} $G$ et un mot $u$, a-t-on $u \in \mathcal L(G)$ ?} appartient à $\mathbf P$ (\textit{cf} TP$_{22}$)
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Vérification}}
                \label{2.2.2}

                $\bullet$ Exemple : on considère le problème \textsc{Chemin\_Hamiltonien} : \simplecit{étant donné un graphe $G$ et deux sommets $s$ et $t$, existe-il dans $G$ un chemin hamiltonien de $s$ à $t$ ?}

                (un chemin hamiltonien est un chemin passant exactement une fois par chaque sommet).

                On peut résoudre ce problème en temps $\mathcal O(n!)$ : il suffit de tester toutes les permutations de l'ensemble des sommets qui commencent par $s$ et finissent par $t$.

                On ne sait pas si \textsc{Chemin\_Hamiltonien} $\in \mathbf P$, en revanche on peut facilement vérifier si une solution à ce problème est correcte : étant donné un chemin, on vérifie en temps linéaire si c'est un chemin hamiltonien de $s$ à $t$.
                On dit que le chemin à vérifier est un certificat pour ce problème.

                \vspace{12pt}
                
                $\bullet$ Définition (\emph{vérificateur}) :
                Soit $P$ un problème de décision sur un domaine $E$.

                Un \emph{vérificateur} pour $P$ est un algorithme $V$ d'entrées une instance e $e \in E$ de $P$ et une valeur $c$ appelée \emph{certificat} et à valeur dans les booléens tel que
                \[
                    \set{e \in E |\ P(e)}
                    = \set{e \in E \ |\ V\ \text{termine et renvoie vrai sur l'entrée}\ (e, c)}
                \]

                \vspace{12pt}
                
                $\bullet$ Exemple : pour le problème de coloration de graphe vu en \ref{1.2.2}, on écrit le vérificateur suivant, d'entrées une instance $(G, k)$, où $G$ est un graphe, et $k$ un entier, et $c$ une coloration :

                \begin{indalgo}{Vérificateur du problème de coloration}
                    \KwInput{$(G, k), c$}

                    \BlankLine

                    Parcourir $S$ en comptant le nombre de couleurs distinctes\;

                    \If{ce nombre est $> k$}{
                        \Return \texttt{false}\;
                    }

                    \For{tout $\set{s, s'} \in A$}{
                        \If{$c(s) = c(s')$}{
                            \Return \texttt{false}\;
                        }
                    }

                    \Return \texttt{true}\;
                \end{indalgo}

                Ce vérificateur est de complexité $\mathcal O\!\lr{\abs S ^2}$ (si on l'implémente naïvement).

                \vspace{12pt}
                
                $\bullet$ Remarque : en général, on exprime la complexité d'un vérificateur uniquement  en fonction de la taille de l'instance.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{La classe $\mathbf{NP}$}}
                \label{2.2.3}

                $\bullet$ Définition : La classe $\mathbf{NP}$ est celle des problèmes de décision admettant un vérificateur de complexité polynomiale en la taille de l'instance.

                \vspace{12pt}
                
                $\bullet$ La contrainte de complexité justifie le fait d'ignorer la taille du certificat : un certificat trop grand ne pourra de toute façon pas être lu dans son intégralité par un algorithme de complexité polynomiale en la taille de l'instance.

                On pourrait imposer au certificat d'être de taille polynomiale en celle de l'instance et considérer des vérificateurs de complexité polynomiale en la taille de leurs deux entrées.

                Le $N$ de $\mathbf{NP}$ signifie \emph{non déterministe}, en raison du modèle H.P des machines de \textsc{Turing} non déterministes qui généralisent les machines de \textsc{Turing} déterministes de la même façon que les AFND généralisent les AFD.
                Un problème appartient à $\mathbf{NP}$ s'il existe une machine de \textsc{Turing} non déterministe qui le résout en temps polynomial.

                \vspace{12pt}
                
                $\bullet$ Théorème :
                \begin{emphBox}
                    \[
                        \mathbf P \subset \mathbf{NP}
                    \]
                \end{emphBox}

                \vspace{6pt}
                
                \begin{proof}
                    Soit $D$ un problème de décision qui appartient à $\mathbf P$.

                    Il existe donc un algorithme $M$ qui résout $D$ en temps polynomial.

                    On construit le vérificateur $V$ d'entrée une instance $e$ de $D$ et un certificat que l'on ignore (chaîne de caractères quelconque), et dont le code est :

                    \begin{indalgo}{$V$}
                        \KwInput{$e, c$}

                        \BlankLine

                        Simuler $M$ sur $e$\;

                        \Return le résultat de $M$\;
                    \end{indalgo}

                    $V$ est de complexité polynomiale en la taille de $e$ car c'est le cas pour $M$.

                    \[
                        \begin{array}{rcl}
                            \exists c\ |\ V(e, c)\ \text{renvoie \texttt{true}}
                            &\ssi&
                            \forall c,\ V(e, c)\ \text{renvoie \texttt{true}}
                            \\
                            &\ssi& M(e) \text{renvoie \texttt{true}}
                            \\
                            &\ssi& D(e)
                        \end{array}
                    \]

                    Donc $V$ est un vérificateur pour $D$ de complexité polynomiale, donc $D \in \mathbf{NP}$.
                \end{proof}

                \vspace{12pt}
                
                $\bullet$ Exemples :

                $-$ Les vérificateurs en \ref{2.2.2} (page \pageref{2.2.2}) montrent que le problème de coloration et \textsc{Chemin\_Hamiltonien} appartiennent à $\mathbf{NP}$.

                $-$ \textsc{Clique} : étant donné un graphe $G = (S, A)$ et un entier $k \in \N$, existe-t-il une clique de taille $k$ dans $G$, \textit{i.e} un ensemble $S' \subseteq S$ de taille $k$ telle que $G_{S'}$ est un graphe complet.

                On montre que \textsc{Clique} $\in \mathbf{NP}$ grâce au vérificateur suivant :

                \begin{indalgo}{Vérificateur de \textsc{Clique}}
                    \KwInput{$G = (S, A), k, S'$}

                    \BlankLine

                    \If{$\abs{S'} \neq k$}{
                        \Return \texttt{false}\;
                    }

                    \For{chaque $s \in S'$}{
                        \For{chaque $s' \in S' \setminus \set s$}{
                            \If{$\set{s, s'} \notin A$}{
                                \Return \texttt{false}\;
                            }
                        }
                    }

                    \Return \texttt{true}\;
                \end{indalgo}

                Ce vérificateur est de complexité $\mathcal O\!\lr{\abs{S'}^2} = \mathcal O\!\lr{\abs{S}^2}$ donc polynomiale en la taille de $(G, k)$.

                Attention, la taille de $k$ est $\mathcal O(\log k)$.

                \boxed{\rm Exo} Montrer que le problème suivant appartient à $\mathbf{NP}$ :

                \textsc{Subset\_Sum} : étant donné un ensemble (multi-ensemble : les répétitions sont autorisées) fini et un entier $S$, existe-t-il
                \[
                    E' \subseteq E\ |\
                    \sum_{n \in E'} n = S
                \]
                ?
            \end{indt}
        \end{indt}

        \vspace{12pt}
        
        \begin{indt}{\subsection{Réductions et complétude}}
            \begin{indt}{\subsubsection{Réduction polynomiale}}
                \label{2.3.1}

                $\bullet$ Définition : Soient $P_1, P_2$ des problèmes de décision.

                On dit que $P_1$ se réduit en temps polynomial à $P_2$ si et seulement si il existe un réduction de $P_1$ à $P_2$ calculable en temps polynomial, \textit{i.e} s'il existe une fonction $f$ du domaine de $P_1$ vers celui de $P_2$ telle que $\forall e\ \text{instance de}\ P_1,\ P_1(e) \ssi P_2(f(e))$ et un algorithme $M$ réalisant $f$ et de complexité polynomiale.

                On note alors $P_1 \le_{\rm p} P_2$.

                \vspace{12pt}
                
                $\bullet$ Remarques :

                $-$ Si on sait résoudre $P_2$, alors il y a un surcoût polynomial pour résoudre $P_1$.

                $-$ On peut aussi généraliser aux réductions \textsc{Turing} la notion de réduction polynomiale.

                \vspace{12pt}
                
                $\bullet$ Exemple : on a vu que SAT $\le_{\rm p}$ 3-SAT \textit{via} la transformation de \textsc{Tseitin} (\textit{cf} chapitre 8, 3.3.5).

                Rappel : Si $\varphi$ est une formule propositionnelle, on ajoute des variables propositionnelles $p_\psi$, $\forall \psi \in SF(\varphi)$ et on construit des 3-FNC $f_\psi$ qui représentent l'équivalence $\psi \leftrightarrow p_\psi$ :
                \[
                    \begin{array}{rcl}
                        f_x &=& (\neg x \vee p_x) \wedge (\neg p_x \vee x)
                        \\
                        f_{\neg \psi} &=& (\neg p_{\neg \psi} \vee \neg p_\psi) \wedge (p_\psi \vee p_{\neg \psi})
                        \\
                        f_{\psi_1 \vee \psi_2} &=& (\neg p_{\psi_1 \vee \psi_2} \vee p_{\psi_1} \vee p_{\psi_2}) \wedge (\neg p_{\psi_1} \vee p_{\psi_1 \vee \psi_2}) \wedge (\neg p_{\psi_2} \vee p_{\psi_2 \vee p_{\psi_1 \vee \psi_2}})
                        \\
                        f_{\psi_1 \wedge \psi_2} &=& (\neg p_{\psi_1 \wedge \psi_2} \vee p_{\psi_1}) \wedge (\neg p_{\psi_1 \wedge \psi_2} \vee p_{\psi_2}) \wedge (\neg p_{\psi_1} \vee \neg p_{\psi_2} \vee p_{\psi_1 \wedge \psi_2})
                    \end{array}
                \]

                On réécrit les sous-formules de la forme $\psi_1 \rightarrow \psi_2$ en $\neg \psi_1 \vee \psi_2$, ce qui ne fait que doubler la taille de la formule dans le pire cas.

                On considère alors la 3-FNC
                \[
                    p_\varphi \wedge \bigwedge_{\psi \in SF(\varphi)} f_\psi
                \]

                Cette formule est équisatisfiable à $\varphi$ \boxed{\rm Exo}, et calculable en temps linéaire en la taille de $\varphi$.

                Donc SAT $\le_{\rm p}$ 3-SAT.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{$\mathbf{NP}$-complétude}}
                $\bullet$ Introduction : L'idée de la complétude est d'exploiter la notion de réduction afin de se focaliser sur des problèmes qui sont plus difficiles que tous les problèmes de leur classe de complexité.

                En effet, si la complexité associée est super-polynomiale (polynomiale ou plus), alors le coût de la réduction est absorbé, donc on a un algorithme de même complexité pour chaque problème de la classe concernée, \textit{i.e} la classe de complexité est stable par réduction polynomiale.

                \vspace{12pt}
                
                $\bullet$ Proposition :
                Soient $P_1, P_2$ des problèmes de décision tels que $P_1 \le_{\rm p} P_2$.

                Si $P_2 \in \mathbf{P}$ (resp. $P_2 \in \mathbf{NP}$), alors $P_1 \in \mathbf P$ (resp. $P_1 \in \mathbf{NP}$).

                \vspace{6pt}
                
                \begin{proof}
                    Il existe une réduction $f$ de $P_1$ à $P_2$ et un algorithme $M_f$ réalisant $f$ et de complexité $\mathcal O(p_f(\abs e))$ où $p_f$ est un polynôme et $e$ une instance de $P_1$.

                    $-$ On suppose $P_2 \in \mathbf P$. Il existe donc un algorithme $M_2$ résolvant $P_2$, de complexité $\mathcal O(p_2(\abs{e_2}))$, où $p_2$ est un polynôme, et $e_2$ une instance de $P_2$.

                    On construit l'algorithme $M_1$, d'entrée une instance $e$ de $P_1$  et de code :
                    \begin{indalgo}{$M_1$}
                        \KwInput{$e$}

                        \BlankLine

                        Simuler $M_f$ sur $e$ pour obtenir $f(e)$\;
                        Simuler $M_2$ sur $f(e)$ et renvoyer son résultat\;
                    \end{indalgo}

                    $M_1$ résout $P_1$ et est de complexité $\mathcal O(p_f(\abs e) + p_2(\abs{f(e)}))$.

                    Or $\abs{f(e)} = \mathcal O(p_f(\abs e))$, donc $M_1$ est de complexité $\mathcal O((\underbrace{p_f + p_2 \circ p_f}_{\text{polynôme}})(\abs e))$.

                    Donc $P_1 \in \mathbf P$.

                    \vspace{6pt}
                    
                    $-$ On suppose $P_2 \in \mathbf{NP}$. Il existe donc un vérificateur $V_2$ pour $P_2$, de complexité polynomiale en la taille de l'instance de $P_2$ passé en entrée.

                    On montre de même que $P_1 \in \mathbf{NP}$ grâce au vérificateur $V_1$, d'entrées une instance $e$ de $P_1$ et un certificat $c$ (pour $P_2$), et de code :
                    \begin{indalgo}{$V_1$}
                        \KwInput{$e, c$}

                        \BlankLine

                        Simuler $M_f$ sur $e$ pour obtenir $f(e)$\;

                        Simuler $V_2$ sur l'entrée $(f(e), c)$ et renvoyer son résultat\;
                    \end{indalgo}
                \end{proof}

                \vspace{12pt}
                
                $\bullet$ Définition (\textit{\textbf{NP}-complétude}) :
                Soit $P_0$ un problème de décision.

                $-$ On dit que $P_0$ est \emph{\textbf{NP}-difficile} si et seulement si
                \[
                    \forall P_1 \in \mathbf{NP},\ P_1 \le{\rm p} P_0
                \]

                $-$ On dit que $P_0$ est \emph{\textbf{NP}-complet} si et seulement si
                \[
                    \begin{cases}
                        P_0 \in \mathbf{NP}
                        \\
                        P_0\ \text{est \textbf{NP}-difficile}
                    \end{cases}
                \]

                \vspace{12pt}
                
                $\bullet$ Proposition :
                Soit $P_0$ un problème \textbf{NP}-complet.

                Si $P_0 \in \mathbf P$, alors $\mathbf P = \mathbf{NP}$.

                \vspace{6pt}
                
                \begin{proof}
                    On sait déjà que $\mathbf P \subseteq \mathbf{NP}$ (\textit{i.e} \ref{2.2.3}, page \pageref{2.2.3}).

                    Soit $P_1 \in \mathbf{NP}$.

                    Comme $P_0$ est $\mathbf{NP}$-difficile, $P_1 \le_{\rm p} P_0$, donc par la proposition précédente, comme $P_0 \in \mathbf P,\ P_1 \in \mathbf P$, donc $\mathbf{NP} \subseteq \mathbf P$ et $\mathbf P = \mathbf{NP}$.
                \end{proof}

                \vspace{12pt}
                
                $\bullet$ Théorème (\textsc{Cook-Levin}) : SAT est \textbf{NP}-complet.

                \vspace{6pt}
                
                \begin{proof}
                    (démonstration informelle, H.P).

                    $-$ SAT $\in \mathbf{NP}$ : on considère comme certificat une valuation des variables de l'instance (donc de taille linéaire en la taille de l'instance) et on évalue la formule avec cette valuation (en temps linéaire) puis on vérifie que le résultat vaut $V$.

                    \vspace{6pt}
                    
                    $-$ SAT est \textbf{NP}-difficile : on considère $P_0 \in \mathbf{NP}$ et un vérificateur $V$ pour $P_0$.

                    On veut montrer que $P_0 \le_{\rm p}$ SAT. On voit une exécution de $V$ comme une suite de configurations (plus facile avec les machines de \textsc{Turing}) et on construit une FNC exprimant que l'enchaînement des configurations est valide et dépendent de variables représentant la valeur du certificat. La formule sera satisfiable si et seulement si il existe un valeur du certificat menant à une exécution valide et acceptante de $V$.

                    On peut borner la taille du certificat et le nombre de configuration à enchaîner grâce à un polynôme qui borne la complexité de $V$, d'où une réduction polynômiale.
                \end{proof}
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Preuves de \textbf{NP}-complétude}}
                \label{2.3.3}

                $\bullet$ Remarques : comme pour la décidabilité, l'usage de réductions (polynomiales) est un outil important.

                \vspace{12pt}
                
                $\bullet$ Prop : Soit $P_0$ un problème de décision.

                Alors
                \[
                    P_0\ \text{est \textbf{NP}-complet}
                    \ssi
                    \begin{cases}
                        P_0 \in \mathbf{NP}
                        \\
                        \exists P_1 \ \text{\textbf{NP}-complet}\ |\ P_1 \le_{\rm p} P_0
                    \end{cases}
                \]

                \begin{proof}
                    \boxed{\Rightarrow} $P_0 \in \mathbf{NP}$ par définition.

                    Par le théorème de \textsc{Cook-Levin}, SAT est \textbf{NP}-complet, donc comme $P_0$ est $\mathbf{NP}$- difficile, SAT $\le_{\rm p} P_0$.

                    \vspace{6pt}
                    
                    \boxed{\Leftarrow} $P_0 \in \mathbf{NP}$ par hypothèse.

                    $P_0$ est \textbf{NP}-difficile : si $P_2 \in \mathbf{NP}$, alors comme $P_1$ est \textbf{NP}-complet, on a $P_2 \le_{\rm p} P_1 \le_{\rm p} P_0$.

                    Donc, comme $\le_{\rm p}$ est transitive (car la composition de polynômes est un polynôme),
                    \[
                        P_2 \le_{\rm p} P_0
                    \]
                \end{proof}

                \vspace{12pt}
                
                $\bullet$ Exemple : 3-SAT est \textbf{NP}-complet.

                $-$ 3-SAT $\in \mathbf{NP}$ : on utilise le même vérificateur que celui vu pour SAT en \ref{2.3.3} (page \pageref{2.3.3}).

                $-$ SAT est \textbf{NP}-complet (\textit{cf} \ref{2.3.3}, page \pageref{2.3.3}) et SAT $\le_{\rm p}$ 3-SAT (\textit{cf} \ref{2.3.1}, page \pageref{2.3.1}).

                \vspace{6pt}
                
                De même, $\forall k \ge 3$, $k$-SAT est $\mathbf{NP}$-complet :

                $-$ $k$-SAT $\in \mathbf{NP}$ pour la même raison que $3$-SAT ;

                $-$ $3$-SAT est \textbf{NP}-complet et la fonction identité est une réduction polynomiale de $3$-SAT à $k$-SAT car $k \ge 3$.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{\textsc{Clique}}}
                $\bullet$ Définition :
                Soit $G = (S, A)$ un GNO.

                Une clique dans $G$ est une ensemble $S' \subseteq S\ |\ \forall s \neq s' \in S',\ \set{s, s'} \in A$.

                On dit que $\abs{S'}$ est la taille de la clique.

                \vspace{6pt}
                
                On s'intéresse au problème \textsc{Clique} suivant : étant donné un GNO $G$ et un entier $k$, existe-t-il une clique de taille $k$ dans $G$ ?

                \vspace{12pt}
                
                $\bullet$ Proposition :
                \begin{emphBox}
                    \textsc{Clique} est \textbf{NP}-complet.
                \end{emphBox}

                \vspace{6pt}
                
                \begin{proof}
                    $-$ \textsc{Clique} $\in \mathbf{NP}$ : on utilise $S'$ come certificat : on vérifie en $\mathcal O(\abs{S'}) = \mathcal O(\abs S)$ que $S' \subseteq S$ et $\abs{S'} = k$.

                    On vérifie en $\mathcal O\!\lr{\abs{S'}^2} = \mathcal O\!\lr{\abs S ^2}$ que $\forall s \neq s' \in S',\ \set{s, s'} \in A$.

                    Donc on a bien un vérificateur de complexité $\mathcal O\!\lr{\abs S ^2}$, donc polynomiale en la taille de $(G, k)$.

                    \vspace{6pt}
                    
                    $-$ On montre que $3$-SAT $\le_{\rm p}$ \textsc{Clique} :

                    Soit $\varphi$ une instance de 3-SAT. On veut construire une instance $(G, k)$ de \textsc{Clique} en temps polynomial en $\abs \varphi$ telle que $G$ contient une clique de taille $k$ si et seulement si $\varphi$ est satisfiable.

                    $G = (S, A)$ est construit ainsi :

                    $+$ $S$ contient chaque littéral de $\varphi$ avec multiplicité ;

                    $+$ Deux littéraux $l, l'$ sont liés dans $A$ si et seulement si $l$ et $l'$ ne sont pas la négation l'un de l'autre et $l, l'$ appartiennent à des clauses différentes.

                    $k$ est le nombre de clauses de $\varphi$.

                    $(G, k)$ est calculable en temps quadratique (donc polynomial) en $\abs \varphi$.

                    \vspace{6pt}
                    
                    Il reste à montrer que $\varphi$ est satisfiable si et seulement si $G$ contient une clique de taille $k$ :

                    \boxed{\Rightarrow} Il existe une valuation $v$ telle que $\lrbb \varphi _v = V$, donc chaque clause de $\varphi$ (numérotées de 1 à $k$), il existe un littéral $l_i$ de la clause tel que $\lrbb{l_i}_v = V$.

                    On note alors $S' = \set{l_i\ |\ i \in \nset 1 k}$ et on montre que $S'$ est une clique de taille $k$ dans $G$.

                    $S' \subseteq S$, $\abs{S'} = k$ et $\forall i \neq i \in \nset 1 k,\ l_i$ et $k_j$ appartiennent à des clauses différentes et $l_i, l_j$ ne peuvent être négation l'un de l'autre car  $\lrbb{l_i}_v = V = \lrbb{l_j}_v$.

                    Donc $S'$ est une clique de taille $k$ dans $G$.

                    \vspace{6pt}
                    
                    \boxed{\Leftarrow}
                    Par définition de $A$, les littéraux de $S'$ proviennent tous de clauses différentes donc on a exactement un littéral par clause.

                    Par définition de $A$, les littéraux de $S'$ ne se contredisent pas, donc on peut construire une valuation qui rend vrai chaque littéral de $S'$ et prolonger de manière quelconque cette valuation aux variables de $\varphi$ qui n'apparaissent pas dans les littéraux de $S'$.

                    Par ce qui précède, cette valuation rend vrai un littéral de chaque clause de $\varphi$, donc c'est un modèle de $\varphi$.
                \end{proof}
            \end{indt}
        \end{indt}
    \end{indt}
    
\end{document}
%--------------------------------------------End
