\documentclass[a4paper, 12pt, twoside]{article}


%------------------------------------------------------------------------
%
% Author                :   Lasercata
% Last modification     :   2022.09.29
%
%------------------------------------------------------------------------


%------ini
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
%\usepackage[english]{babel}


%------geometry
\usepackage[textheight=700pt, textwidth=500pt]{geometry}


%------color
\usepackage{xcolor}
\definecolor{ff4500}{HTML}{ff4500}
\definecolor{00f}{HTML}{0000ff}
\definecolor{0ff}{HTML}{00ffff}
\definecolor{656565}{HTML}{656565}

%\renewcommand{\emph}{\textcolor{ff4500}}
%\renewcommand{\em}{\color{ff4500}}

\newcommand{\Emph}{\textcolor{ff4500}}

\newcommand{\strong}[1]{\textcolor{ff4500}{\bf #1}}
\newcommand{\st}{\color{ff4500}\bf}


%------Code highlighting
%---listings
\usepackage{listings}

\definecolor{cbg}{HTML}{272822}
\definecolor{cfg}{HTML}{ececec}
\definecolor{ccomment}{HTML}{686c58}
\definecolor{ckw}{HTML}{f92672}
\definecolor{cstring}{HTML}{e6db72}
\definecolor{cstringlight}{HTML}{98980f}
\definecolor{lightwhite}{HTML}{fafafa}

\lstdefinestyle{DarkCodeStyle}{
    backgroundcolor=\color{cbg},
    commentstyle=\itshape\color{ccomment},
    keywordstyle=\color{ckw},
    numberstyle=\tiny\color{cbg},
    stringstyle=\color{cstring},
    basicstyle=\ttfamily\footnotesize\color{cfg},
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=4,
    xleftmargin=\leftskip
}

\lstdefinestyle{LightCodeStyle}{
    backgroundcolor=\color{lightwhite},
    commentstyle=\itshape\color{ccomment},
    keywordstyle=\color{ckw},
    numberstyle=\tiny\color{cbg},
    stringstyle=\color{cstringlight},
    basicstyle=\ttfamily\footnotesize\color{cbg},
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=10pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=4,
    frame=L,
    xleftmargin=\leftskip
}

%\lstset{style=DarkCodeStyle}
\lstset{style=LightCodeStyle}
%Usage : \begin{lstlisting}[language=Caml, xleftmargin=xpt] ... \end{lstlisting}


%---Algorithm
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\SetKwInput{KwInput}{Input}
\SetKwInput{KwOutput}{Output}

\SetKwProg{Fn}{Function}{:}{}
\SetKw{KwPrint}{Print}

\newcommand\commfont[1]{\textsl{\textcolor{656565}{#1}}}
\SetCommentSty{commfont}
\SetProgSty{texttt}
\SetArgSty{textnormal}
\SetFuncArgSty{textnormal}
%\SetProgArgSty{texttt}

\newenvironment{indalgo}[2][H]{
    \begin{minipage}{\linewidth-\leftskip-5pt}
        \begin{algorithm}[#1]
            \caption{#2}
}
{
        \end{algorithm}
    \end{minipage}
}


%---tcolorbox
\usepackage[many]{tcolorbox}
\DeclareTColorBox{emphBox}{O{black}O{lightwhite}}{
    breakable,
    outer arc=0pt,
    arc=0pt,
    top=0pt,
    toprule=-.5pt,
    right=0pt,
    rightrule=-.5pt,
    bottom=0pt,
    bottomrule=-.5pt,
    colframe=#1,
    colback=#2,
    enlarge left by=10pt,
    width=\linewidth-\leftskip-10pt,
}


%-------make the table of content clickable
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}


%------pictures
\usepackage{graphicx}
%\usepackage{wrapfig}

\usepackage{tikz}
%\usetikzlibrary{babel}             %Uncomment this to use circuitikz
%\usetikzlibrary{shapes.geometric}  % To draw triangles in trees
%\usepackage{circuitikz}            %Electrical circuits drawing


%------tabular
%\usepackage{color}
%\usepackage{colortbl}
%\usepackage{multirow}


%------Physics
%---Packages
%\usepackage[version=4]{mhchem} %$\ce{NO4^2-}$

%---Commands
\newcommand{\link}[2]{\mathrm{#1} \! - \! \mathrm{#2}}
\newcommand{\pt}[1]{\cdot 10^{#1}} % Power of ten
\newcommand{\dt}[2][t]{\dfrac{\mathrm d #2}{\mathrm d #1}} % Derivative


%------math
%---Packages
%\usepackage{textcomp}
%\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools} % For abs
\usepackage{stmaryrd} %for \llbracket and \rrbracket
\usepackage{mathrsfs} %for \mathscr{x} (different from \mathcal{x})

%---Commands
%-Sets
\newcommand{\N}{\mathbb{N}} %set N
\newcommand{\Z}{\mathbb{Z}} %set Z
\newcommand{\Q}{\mathbb{Q}} %set Q
\newcommand{\R}{\mathbb{R}} %set R
\newcommand{\C}{\mathbb{C}} %set C
\newcommand{\U}{\mathbb{U}} %set U
\newcommand{\seg}[2]{\left[ #1\ ;\ #2 \right]}
\newcommand{\nset}[2]{\left\llbracket #1\ ;\ #2 \right\rrbracket}

%-Exponantial / complexs
\newcommand{\e}{\mathrm{e}}
\newcommand{\cj}[1]{\overline{#1}} %overline for the conjugate.

%-Vectors
\newcommand{\vect}{\overrightarrow}
\newcommand{\veco}[3]{\displaystyle \vect{#1}\binom{#2}{#3}} %vector + coord

%-Limits
\newcommand{\lm}[2][{}]{\lim\limits_{\substack{#2 \\ #1}}} %$\lm{x \to a} f$ or $\lm[x < a]{x \to a} f$
\newcommand{\Lm}[3][{}]{\lm[#1]{#2} \left( #3 \right)} %$\Lm{x \to a}{f}$ or $\Lm[x < a]{x \to a}{f}$
\newcommand{\tendsto}[1]{\xrightarrow[#1]{}}

%-Integral
\newcommand{\dint}[4][x]{\displaystyle \int_{#2}^{#3} #4 \mathrm{d} #1} %$\dint{a}{b}{f(x)}$ or $\dint[t]{a}{b}{f(t)}$

%-left right
\newcommand{\lr}[1]{\left( #1 \right)}
\newcommand{\lrb}[1]{\left[ #1 \right]}
\newcommand{\lrbb}[1]{\left\llbracket #1 \right\rrbracket}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\lrangle}[1]{\left\langle #1 \right\rangle}

%-Others
\newcommand{\para}{\ /\!/\ } %//
\newcommand{\ssi}{\ \Leftrightarrow \ }
\newcommand{\eqsys}[2]{\begin{cases} #1 \\ #2 \end{cases}}

\newcommand{\med}[2]{\mathrm{med} \left[ #1\ ;\ #2 \right]}  %$\med{A}{B} -> med[A ; B]$
\newcommand{\Circ}[2]{\mathscr{C}_{#1, #2}}

\renewcommand{\le}{\leqslant}
\renewcommand{\ge}{\geqslant}

\newcommand{\oboxed}[1]{\textcolor{ff4500}{\boxed{\textcolor{black}{#1}}}} %orange boxed


%------commands
%---to quote
\newcommand{\simplecit}[1]{\guillemotleft$\;$#1$\;$\guillemotright}
\newcommand{\cit}[1]{\simplecit{\textcolor{656565}{#1}}}
\newcommand{\quo}[1]{\cit{\it #1}}

%---to indent
\newcommand{\ind}[1][20pt]{\advance\leftskip + #1}
\newcommand{\deind}[1][20pt]{\advance\leftskip - #1}

%---to indent a text
\newcommand{\indented}[2][20pt]{\par \ind[#1] #2 \par \deind[#1]}
\newenvironment{indt}[2][20pt]{#2 \par \ind[#1]}{\par \deind} %Titled indented env

%---title
\newcommand{\thetitle}[2]{\begin{center}\textbf{{\LARGE \underline{\Emph{#1} :}} {\Large #2}}\end{center}}

%---Maths environments
%-Proofs
\newenvironment{proof}[1][{}]{\begin{indt}{$\square$ #1}}{$\blacksquare$ \end{indt}}

%-Maths parts (proposition, definition, ...)
\newenvironment{mathpart}[1]{\begin{indt}{\boxed{\text{\textbf{#1}}}}}{\end{indt}}
\newenvironment{mathbox}[1]{\boxed{\text{\textbf{#1}}}\begin{emphBox}}{\end{emphBox}}
\newenvironment{mathul}[1]{\begin{indt}{\underline{\textbf{#1}}}}{\end{indt}}

\newenvironment{theo}{\begin{mathpart}{Théorème}}{\end{mathpart}}
\newenvironment{Theo}{\begin{mathbox}{Théorème}}{\end{mathbox}}

\newenvironment{prop}{\begin{mathpart}{Proposition}}{\end{mathpart}}
\newenvironment{Prop}{\begin{mathbox}{Proposition}}{\end{mathbox}}
\newenvironment{props}{\begin{mathpart}{Propriétés}}{\end{mathpart}}

\newenvironment{defi}{\begin{mathpart}{Définition}}{\end{mathpart}}
\newenvironment{meth}{\begin{mathpart}{Méthode}}{\end{mathpart}}

\newenvironment{Rq}{\begin{mathul}{Remarque :}}{\end{mathul}}
\newenvironment{Rqs}{\begin{mathul}{Remarques :}}{\end{mathul}}

\newenvironment{Ex}{\begin{mathul}{Exemple :}}{\end{mathul}}
\newenvironment{Exs}{\begin{mathul}{Exemples :}}{\end{mathul}}


%------Sections
% To change section numbering :
% \renewcommand\thesection{\Roman{section}}
% \renewcommand\thesubsection{\arabic{subsection})}
% \renewcommand\thesubsubsection{\textit \alph{subsubsection})}

% To start numbering from 0
% \setcounter{section}{-1}


%------page style
\usepackage{fancyhdr}
\usepackage{lastpage}

\setlength{\headheight}{18pt}
\setlength{\footskip}{50pt}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE, RO]{\textit{\textcolor{black}{\today}}}
\fancyhead[RE, LO]{\large{\textsl{\Emph{\texttt{\jobname}}}}}

\fancyfoot[RO, LE]{\textit{\texttt{\textcolor{black}{Page \thepage /}\pageref{LastPage}}}}
\fancyfoot[LO, RE]{\includegraphics[scale=0.12]{/home/lasercata/Pictures/1.images_profil/logo/mieux/lasercata_logo_fly_fond_blanc.png}}


%------init lengths
\setlength{\parindent}{0pt} %To avoid using \noindent everywhere.
\setlength{\parskip}{3pt}


%---------------------------------Begin Document
\begin{document}
    
    %For dark mode :
    % \pagecolor{black}
    % \color{white}
    
    \thetitle{Chapitre 13}{Concurrence et synchronisation}
    
    \tableofcontents
    \newpage
    
    
    \begin{indt}{\section{Introduction}}
        \begin{indt}{\subsection{Motivation}}
            \begin{indt}{\subsubsection{Rappel (chap.2, 1.1.1)}}
                Un programme en cours d'exécution dispose d'un espace mémoire dédié organisé comme suit :

                \begin{center}
                    \begin{tabular}{|c|}
                        \hline
                        code
                        \\
                        \hline
                        données
                        \\
                        \hline
                        tas
                        \\
                        $\downarrow$
                        \\
                        \hline
                        $\uparrow$
                        \\
                        stack
                        \\
                        \hline
                    \end{tabular}
                \end{center}

                Le tas (\textit{heap}) est la zone mémoire qui contient les données allouées dynamiquement.

                La pile (\textit{stack}) contient toutes les données liées à la gestion des appels de fonction.

                Dans ce chapitre, un programme en cours d'exécution sera appelé \textit{processus} et le terme \textit{programme} fera référence au code.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Concurrence}}
                En pratique dans un ordinateur, il y a plusieurs processus actifs simultanément, qui doivent se partager les ressources de la machine (mémoire, entrées/sorties, unité de calcul).

                Le programme de MPI se limite à l'étude de machines ayant une unique unité de calcul.
                En particulier, cela signifie qu'il ne peut pas y avoir plusieurs processus actifs en même temps.

                Pour contourner ce problème, le système met es place une alternance de processus : on exécute quelques instructions d'un processus avant de changer de contexte pour exécuter un autre processus. Si les changements de contexte sont assez rapides, l'utilisateur a l'impression d'une vraie exécution parallèle.

                Problème : les changements de contexte sont lents.
                De plus, deux processus ne sont pas forcément indépendants.

                Exemple : Louis tape ses cours en \LaTeX{}, et doit exécuter un compilateur pour obtenir un document PDF. Il peut alors le visionner à l'aide d'un autre programme qui lit dans la même zone mémoire que celle où le compilateur écrit.
                À chaque mise à jour, le programme de lecture doit rafraîchir l'affichage.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Non déterminisme et synchronisation}}
                \label{1.1.3}

                L'exécution de processus concurrents est non déterministe car on ne peut pas faire d'hypothèse sur l'ordre d'exécution des instructions et des changements de contextes.
                En effet, le système d'exploitation, \textit{via} un programme appelé \textit{ordonnanceur}, décide des changements de contexte selon des critères variés (horloge, événement provoqués par l'utilisateur, attente de données qui proviennent de la mémoire, \dots)

                Ce non-déterminisme implique la nécessité de synchroniser certains processus.

                \vspace{6pt}
                
                Par exemple, on considère deux processus concurrents qui exécutent le même programme.

                Le code est le suivant :

                \begin{emphBox}
                    \begin{indt}{Répéter 100 fois :}
                        Lire l'entier $n$ dans le fichier ``\texttt{toto.txt}"

                        Écraser le fichier ``\texttt{toto.txt}" en y écrivant $n + 1$
                    \end{indt}
                \end{emphBox}

                On suppose qu'initialement, le fichier contient l'entier $0$.
                Quel est le résultat final ?

                C'est une valeur de $\nset{100}{200}$ car un processus peut être interrompu juste après une lecture et l'écriture qui suivra la reprise de son exécution écrasera tous les changements faits par le second processus.
            \end{indt}
        \end{indt}

        \vspace{12pt}
        
        \begin{indt}{\subsection{Définition et objectifs}}
            \begin{indt}{\subsubsection{Fil d'exécution (\textit{thread})}}
                Dans certains cas, un processus peut être amené à effectuer plusieurs tâches, que l'on pourrait vouloir répartir sur plusieurs processus.
                Si les tâches ne sont pas indépendantes, on peut être amené à faire de nombreux changements de contexte qui peuvent être coûteux.

                Il faut de plus un moyen de communication entre ces processus, qui peut être une interruption système (le système d'exploitation sert de messager) ou un partage de mémoire.

                En réalité, un processus peut contenir plusieurs \textit{fils d'exécution} ou \textit{processus légers} qui partagent une partie de la mémoire du processus.
                Ces fils d'exécution ont un programme commun mais l'exécutent en des points différents.

                La structure de la mémoire d'un processus devient la suivante :

                \begin{center}
                    \begin{tikzpicture}
                        \node (c) at (0, 0) {code};
                        \node (d) at (0, -1) {données};
                        \node (t) at (0, -2) {tas};

                        \draw[->] (t) to (0, -3);

                        \node (p1) at (-2, -5) {pile};
                        \draw[->] (p1) to (-2, -4);

                        \node (p2) at (0, -5) {pile};
                        \draw[->] (p2) to (0, -4);

                        \node (p3) at (2, -5) {pile};
                        \draw[->] (p3) to (2, -4);

                        \node at (-2, -6) {registres};
                        \node at (0, -6) {registres};
                        \node at (1.8, -5.8) {registres};

                        \draw (-3, .3) rectangle (3, -6.5);
                        \draw (-3, -.5) -- (3, -.5);
                        \draw (-3, -1.5) -- (3, -1.5);
                        \draw (-3, -3.5) -- (3, -3.5);
                        \draw (-3, -5.5) -- (3, -5.5);

                        \draw (-1, -3.5) -- (-1, -6.5);
                        \draw (1, -3.5) -- (1, -6.5);

                        \node (f) at (0, -8) {3 fils};

                        \draw[->] (f) to (-2, -6.7);
                        \draw[->] (f) to (0, -6.7);
                        \draw[->] (f) to (2, -6.7);

                        \node (i) at (2.6, -6.2) [rectangle, draw] {$_{\text{\tiny{IP}}}$};

                        \draw[-latex] (i) to [out=45, in=-45] (3, 0);

                        \node at (6, -6) {IP : instruction pointer};
                    \end{tikzpicture}
                \end{center}

                \vspace{12pt}
                
                Limitations du programme :

                $\bullet$ On étudie les fils d'exécution d'un unique processus ;

                $\bullet$ On se limite uniquement à la norme POSIX ;

                \begin{indt}{$\bullet$ On s'autorise uniquement deux primitives sur les fils d'exécutions :}
                    $-$ \texttt{create} : prend une fonction et des paramètres pour cette fonction et crée un nouveau fil d'exécution pour le processus courant, chargé d'évaluer la fonction sur les paramètres ;

                    $-$ \texttt{join} : prend l'identifiant d'un fil d'exécution en paramètre et interrompt le fil courant jusqu'à terminaison du fil passé en argument.
                \end{indt}
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Situation de compétition et atomicité}}
                Un \textit{situation de compétition} (\textit{race condition}) a lieu quand le résultat d'un processus varie selon l'ordre d'exécution de ses fils. L'exemple vu en \ref{1.1.3} (page \pageref{1.1.3}) est une situation de compétition que l'on peut reproduire avec les fils d'un unique processus partageant une variable globale.
                Un fil principal est chargé de créer deux fils secondaires qui exécutent la boucle.
                Il doit attendre la terminaison des fils secondaires (opération \texttt{join}) avant de s'arrêter pour éviter une interruption prématurée du programme.

                Dans un cas comme celui-ci, on peut résoudre le problème en imposant \textit{l'atomicité} du corps de la boucle. Un ensemble d'instructions est \textit{atomique} si le système ne peut pas interrompre leur exécution. Ici, on ne voit pas d'interruption entre la lecture et l'écriture.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Section critique}}
                Dans l'exemple précédent, l'atomicité est une condition trop forte : on peut interrompre un fil entre la lecture et l'écriture tant que l'autre fil ne lit et n'écrit pas dans la variable.

                On dit que le corps de la boucle est une \textit{\em section critique} du programme.

                On veut garantir l'\emph{\it exclusion mutuelle} pour les secteurs critiques, \textit{i.e} il ne peut y avoir qu'un seul fil qui exécute une section critique à chaque instant.

                Une solution de synchronisation doit aussi garantir le \emph{\it progrès de l'exécution} : si un fil souhaite entrer en section critique et si celle-ci est libre, le choix d'un fil entrant en section critique ne doit pas pouvoir être retardé indéfiniment.

                On veut aussi assurer un \emph{\it temps d'attente borné} : il doit y avoir une borne sur le nombre de fois que d'autres fils d'exécution entrent en section critique entre le moment où un fil signale qu'il souhaite entrer en section critique et son entrée effective.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Interblocage (\textit{deadlock}) et famine}}
                \label{1.2.4}

                Si la synchronisation des fils d'exécution n'est pas effectuée correctement, il peut y avoir plusieurs problèmes, dont :

                \vspace{12pt}
                
                $\bullet$ l'interblocage : on dit qu'il y a \textit{interblocage} lorsque plusieurs fils attendent un événement qui ne peut être provoqué que par l'un des fils en attente.

                Exemple classique : le dîner des philosophes.

                Des philosophes sont réunis autour d'une table ronde, et on deux activités : manger et penser.
                Pour manger, un philosophe doit disposer de deux baguettes.
                Les baguettes sont réparties comme suit : il y en a une entre chaque couple de philosophe voisins.

                Si les philosophes exécutent le programme suivant :

                \begin{emphBox}
                    Prendre la baguette à gauche

                    Prendre la baguette à droite

                    Manger

                    Poser les baguettes

                    Penser
                \end{emphBox}

                Il peut y avoir unterblocage si chaque philosophe a pris la baguette à sa gauche et attend que son voisin de droite libère l'autre.

                \vspace{6pt}
                
                $\bullet$ La \textit{famine} a lieu lorsqu'un fil d'exécution attend indéfiniment l'accès à une ressource.

                Exemple classique : le problème des producteurs-consommateurs.

                Des producteurs remplissent un buffer que les consommateurs vident.

                Règles : une donnée ne peut être lue qu'une fois, on ne peut pas écraser une donnée qui n'a pas été lue, et une case vide ne peut pas être lue.

                Si l'accès au buffer n'est pas équitable (par exemple une priorité selon les identifiants des fils d'exécution), un fil peut être amené à attendre indéfiniment.

                Par exemple : un producteur très lent, deux consommateurs très rapides : chaque fois que le producteur écrit dans le buffer, le fil consommateur n°1 récupère la donnée et reprend son attente, le fil n°2 n'accède jamais aux données.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Remarque}}
                Nous allons voir plusieurs outils de synchronisation permettant l'établissement de sections critiques.
                \begin{indt}{Ces outils peuvent être de plusieurs natures :}
                    $\bullet$ Algorithmique : nous verrons deux algorithmes permettant de travailler avec deux fils d'exécution (algorithme de \textsc{Petersen}) ou plus (algorithme de la boulangerie de \textsc{Lamport})

                    Ces algorithmes nécessitent une attente active des fils d'exécution : ils bouclent en ne faisant rien en attendant la réalisation d'une condition.

                    $\bullet$ Des primitives de programmation directement fournies par le système (mutex et sémaphore) qui permettent l'interruption d'un fil en attendant la réalisation d'une condition plutôt qu'une attente active.
                \end{indt}
            \end{indt}
        \end{indt}

        \vspace{12pt}
        
        \begin{indt}{\subsection{Syntaxe de la manipulation des fils d'exécution}}
            \begin{indt}{\subsubsection{En OCaml}}
                On utilise le module \texttt{Thread}, qui propose les objets suivants :

                $\bullet$ le type \texttt{Thread.t} qui représente les fils d'exécution ;

                $\bullet$ la fonction \texttt{Thread.create : ('a -> 'b) -> 'a -> Thread.t} qui, étant donné une fonction \texttt{f : 'a -> 'b} et un argument \texttt{x : 'a}, crée et renvoie un fil d'exécution pour le processus courant, chargé d'évaluer \texttt{f x}.
                Le résultat de la fonction est ignoré, et en pratique, on utilise des fonctions de type \texttt{'a -> unit} qui font des effets de bord ;

                $\bullet$ la fonction \texttt{Thread.join : Thread.t -> unit} qui prend un fil \texttt p en argument et qui interrompt le fil courant jusqu'à terminaison de \texttt p.

                \vspace{12pt}
                
                Pour compiler un programme utilisant ce module, on exécute une ligne de la forme
                \begin{center}
                    \texttt{ocamlc -I +threads unix.cma threads.cma fichier.ml -o programme}
                \end{center}
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{En C}}
                On inclut l'en-tête \texttt{pthread.h}.

                Cela donne accès à :

                $\bullet$  un type \texttt{pthread\_t} qui représente les fils d'exécution ;

                $\bullet$ une fonction de prototype

                \begin{lstlisting}[language=C, xleftmargin=80pt]
int pthread_create(pthread_t* p, const pthread_attr_t* attr, void* (*f)(void*), void* args)\end{lstlisting}

                \begin{indt}{où}
                    $-$ \texttt p est un pointeur permettant de stocker le fil créé ;

                    $-$ \texttt{attr} est H.P et sera toujours \texttt{NULL} ;

                    $-$ \texttt f et \texttt{args} représentent la fonction que le nouveau fil doit exécuter et ses arguments.
                \end{indt}

                \vspace{12pt}
                
                Pourquoi \texttt{void*} ?

                Pas de fonction d'ordre supérieur et pas de polymorphisme mais il est possible d'effectuer du transtypage vers et depuis \texttt{void*}.

                On pourra se contenter de définir une fonction de type \texttt{void* f(void*)} et de la passer directement en argument.
                Si \texttt f n'a aucun argument, \texttt{args} sera \texttt{NULL}.

                L'entier renvoyé est un code d'erreur qui vaut 0 si tout s'est bien passé. On adoptera un style défensif et on vérifiera la valeur de cet entier.

                \vspace{12pt}
                
                $\bullet$ La fonction de prototype

                \begin{lstlisting}[language=C, xleftmargin=80pt]
int pthread_join(pthread_t p, void** res)\end{lstlisting}

                où \texttt p est le fil d'exécution dont le fil courant doit attendre la terminaison, et \texttt{res} est H.P et sera toujours \texttt{NULL} (permet de récupérer le résultat de la fonction \texttt f).

                L'entier en retour a la même signification que dans la fonction \texttt{pthread\_create}.

                \vspace{12pt}
                
                La compilation d'un programme utilisant cette bibliothèque est de la forme :

                \begin{center}
                    \texttt{gcc -lpthread file.c - o prog}
                \end{center}

                ou
                \begin{center}
                    \texttt{gcc -pthread file.c - o prog}
                \end{center}
            \end{indt}
        \end{indt}
    \end{indt}

    \vspace{12pt}
    
    \begin{indt}{\section{Outils algorithmiques de synchronisation}}
        \begin{indt}{\subsection{Algorithme de \textsc{Petersen}}}
            \begin{indt}{\subsubsection{Introduction}}
                Conçut en 1981, cet algorithme permet l'établissement d'une section critique garantissant l'exclusion mutuelle, l'absence de famine et l'absence d'interblocage.

                Cependant, il nécessite une attente active de la part des fils d'exécution et est limité à deux fils concurrents, ce qui en fait un algorithme peu utilisé en pratique.

                Avant de l'étudier, nous allons voir des versions plus simples, mais qui échouent.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Première tentative}}
                On utilise un booléen associé à chaque fil d'exécution indiquant s'il est en section critique.
                Un fil souhaitant entrer en section critique attend que l'autre n'y soit plus puis met son booléen à jour.
                En sortie de section critique, un fil doit mettre son booléen à jour.

                \textit{cf} \texttt{petersen\_0.c}.

                \vspace{6pt}
                
                Problème : si un fil est interrompu entre la fin de son attente active et la mise à jour de son booléen, il n'y a plus forcément exclusion mutuelle.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Deuxième tentative}}
                Le problème de la première version vient du fait que la mise à jour du booléen est trop tardive. On pourrait plutôt signaler la volonté d'entrer en section critique : le booléen est mis à jour avant l'attente et un fil souhaitant entrer en section critique attend que l'autre fil ne veuille plus y être.

                \textit{cf} \texttt{petersen\_1.c}

                \vspace{6pt}
                
                Problème : si un fil est interrompu entre la mise à jour de son booléen et le début de son attente, on peut atteindre une situation de blocage où les deux booléens valent \texttt{true}.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Troisième tentative}}
                On utilise plutôt une variable indiquant quel fil d'exécution peut entrer en section critique.
                Lorsqu'un fil quitte la section critique, il indique que c'est au tour de l'autre fil.

                \textit{cf} \texttt{petersen\_2.c}.

                \vspace{6pt}
                
                Problème : si un fil termine son exécution avant l'autre, lorsque le second fil indique que c'est au tour du fil qui s'est arrêté, son tour ne reviendra jamais, il est donc en situation de famine.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Algorithme de \textsc{Petersen}}}
                On combine les deux dernières tentatives : un fil peut entrer en section critique si c'est à son tour ou si l'autre fil ne souhaite pas entrer en section critique.

                \textit{cf} \texttt{petersen\_final.c}

                Pseudo code :

%                 \begin{emphBox}
%                     \texttt{turn} $\leftarrow 0$
% 
%                     \texttt{want} $\leftarrow$ \texttt{[false, false]}
% 
%                     \vspace{6pt}
%                     
%                     \begin{indt}{Thread $i$ :}
%                         \texttt{want[$i$]} $\leftarrow$ \texttt{true}
% 
%                         \texttt{turn} $\leftarrow 1 - i$
% 
%                         \vspace{6pt}
%                         
%                         \begin{indt}{while \texttt{want[$1 - i$] \&\& turn = $1 - i$} :}
%                             wait
%                         \end{indt}
% 
%                         \vspace{6pt}
%                         
%                         \textit{\textcolor{656565}{//Critical section}}
% 
%                         \vspace{6pt}
%                         
%                         \texttt{want[$i$]} $\leftarrow$ \texttt{false}
%                     \end{indt}
%                 \end{emphBox}
    
                \begin{indalgo}{\textsc{Petersen}}
                    \texttt{turn} $\gets 0$\;
                    \texttt{want} $\gets$ \texttt{[false, false]}\;

                    \SetKwProg{Thread}{Thread}{:}{}

                    \Thread{$i$}{
                        \texttt{want[$i$] $\gets$ true}\;
                        \texttt{turn $\gets 1 - i$}\;
                        
                        \BlankLine

                        \While{\texttt{want[$1 - i$] \&\& turn = $1 - i$}}{
                            Wait
                        }

                        \tcp{Critical section}

                        \texttt{want[$i$] $\gets$ false}\;
                    }
                \end{indalgo}

                \vspace{12pt}
                
                $\bullet$ Proposition : l'algorithme de \textsc{Petersen} garantit l'exclusion mutuelle.

                \begin{proof}
                    Par l'absurde, supposons que les fils 0 et 1 sont en section critique.

                    Sans perte de généralité, on suppose que le fil 0 est entré en section critique en premier.

                    Au moment de l'entrée en section critique du fil 1, on sait que \texttt{want[0]} vaut toujours \texttt{true} donc que \texttt{turn} vaut 1.

                    Ainsi, le fil 1 a du être interrompu entre l'affectation \texttt{turn} $\leftarrow 0$ et la boucle d'attente pour permettre l'entrée en section critique du fil 0 (s'il avait été interrompu avant, l'affectation \texttt{turn} $\leftarrow 0$ empêcherait son entrée en section critique).

                    Lorsque le fil 0 effectue l'affectation \texttt{turn} $\leftarrow 1$, il ne peut plus entrer en section critique car \texttt{want[1]} vaut \texttt{true} : absurde
                \end{proof}

                \vspace{12pt}
                
                $\bullet$ Proposition : l'algorithme de \textsc{Petersen} garantit le progrès de l'exécution et le temps d'attente borné pour les fils d'exécution.

                \begin{proof}
                    Supposons que le fil 0 veuille entrer en section critique.

                    Si le fil 0 est en attente, c'est que \texttt{want[1]} vaut \texttt{true}, et \texttt{turn} vaut 1.

                    Dans ce contexte, le fil 1 peut être dans plusieurs états :

                    $-$ le fil 1 se situe juste après l'affectation \texttt{want[1]} $\leftarrow$ \texttt{true}. Dans ce cas, on a l'affectation \texttt{turn} $\leftarrow 0$, le fil 1 se met en attente (on a aussi \texttt{want[0]} qui vaut \texttt{true}) et le fil 0 peut entrer en section critique ;

                    $-$ le fil 1 se situe à la boucle d'attente entre le moment où le fil 0 effectue l'affectation \texttt{want[0]} $\leftarrow$ \texttt{true} et l'affectation \texttt{turn} $\leftarrow 1$.

                    Dans ce cas, lorsqu'il reprend son exécution, le fil 1 entre en section critique.
                    \begin{indt}{Lorsqu'il sort de section critique, on a \texttt{want[1] = false} et il y a deux possibilités :}
                        (1) le fil 0 reprend son exécution et entre en section critique ;

                        (2) le fil 1 poursuit son exécution et tente à nouveau d'entrer en section critique.

                        \texttt{want[1]} redevient \texttt{true}, mais le fil 1 finira par exécuter l'affectation \texttt{turn} $\leftarrow 0$ et le fil 1 se met en attente et le fil 0 entre en section critique
                    \end{indt}

                    $-$ le fil 1 se situe à la boucle d'attente avant l'affectation \texttt{want[0]} $\leftarrow$ \texttt{true}.

                    Le fil 1 est donc en section critique, et comme avant, ne fera qu'un passage en section critique avant de céder la place au fil 0.

                    Le même raisonnement s'applique au fil 1 par symétrie.

                    On en déduit que l'exécution progresse toujours et qu'un fil d'exécution souhaitant entrer en section critique attendra au plus un passage de l'autre fil en section critique.
                \end{proof}

                \vspace{12pt}
                
                $\bullet$ Remarque : la proposition précédente assure l'absence de famine, donc d'interblocage.
            \end{indt}
        \end{indt}

        \vspace{12pt}
        
        \begin{indt}{\subsection{Algorithme de la boulangerie de \textsc{Lamport}}}
            \begin{indt}{\subsubsection{Introduction}}
                Conçut en en 1974, cet algorithme permet également la mise en place d'une section critique avec les mêmes propriétés.

                Il est aussi basé sur l'attente active, mais permet l'utilisation de plus de 2 fils.

                Il existe des solutions plus efficaces que donc algorithme n'a qu'un intérêt théorique.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Principe de l'algorithme}}
                L'algorithme de la boulangerie de \textsc{Lamport} exploite le fonctionnement d'une file d'attente à ticket : un fil d'exécution souhaitant entrer en section critique doit prendre un ticket et attendre son tour.

                Différence majeure : ce sont les fils d'exécutions qui s'attribuent eux-mêmes leur ticket. Il doivent donc déterminer quel est le numéro de ticket maximal afin de s'attribuer un numéro qui lui est supérieur.

                Dans un cadre concurrent, les fils peuvent être amenés à s'attribuer le même numéro.
                Un fil d'exécution souhaitant entrer en section critique doit d'abord s'attribuer un numéro puis attendre d'avoir le numéro minimal, et en cas d'égalité, il faut pouvoir départager les fils.
                On utilise pour cela les identifiants des fils d'exécution, que l'on suppose totalement ordonnés : en cas d'égalité, le fil d'identifiant minimal a la priorité.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Première tentative}}
                On utilise un tableau \texttt{ticket} qui associe à chaque fil un numéro de ticket (on suppose ici que les identifiants correspondent aux indices du tableau).
                L'absence de ticket sera dénoté par la valeur 0.

                $\bullet$ Phase d'attribution du ticket pour le fil $i$ :

                \begin{emphBox}
                    $m \leftarrow \max(\mathtt{ticket})$

                    \texttt{ticket[$i$]} $\leftarrow m + 1$
                \end{emphBox}

                \vspace{6pt}
                
                $\bullet$ Phase d'attente active pour le fil $i$ :

                On parcourt séquentiellement le tableau \texttt{ticket} en attendant pour chaque fil prioritaire devant $i$ qu'il ait fini.

%                 \begin{emphBox}
%                     \begin{indt}{Pour $j$ de $0$ à $n - 1$ :}
%                         \begin{indt}{Tant que \texttt{ticket[$j$] != 0} et (\texttt{ticket[$j$] < ticket[$i$]} ou \texttt{ticket[$j$] = ticket[$i$]} et $j < i$) :}
%                             Attendre
%                         \end{indt}
%                     \end{indt}
% 
%                     \vspace{6pt}
%                     
%                     Sortie de section critique : on détruit le ticket :
% 
%                     \texttt{ticket[$i$]} $\leftarrow 0$
%                 \end{emphBox}
    
                \begin{indalgo}{Phase d'attente active pour le fil $i$}
                    \For{$j = 0$ \KwTo $n - 1$}{
                        \While{\texttt{ticket[$j$] != 0} \KwSty{et} (\texttt{ticket[$j$] $<$ ticket[$i$]} \KwSty{ou} (\texttt{ticket[$j$] = ticket[$i$]} \KwSty{et} $j < i$))}{
                            Attendre\;
                        }
                    }

                    \BlankLine

                    \tcp{Sortie de section critique : on détruit le ticket}

                    \texttt{ticket[$i$] $\gets 0$} \;
                \end{indalgo}

                \vspace{6pt}
                
                Problème : l'exclusion mutuelle n'est pas garantie.

                On suppose qu'il y a deux fils $i < j$ qui veulent entrer en section critique.
                \textit{Via} des interruptions, ces deux fils peuvent calculer la même valeur pour le maximum, donc s'attribuer le même numéro.
                On suppose que le fil $i$ est interrompu avant la mise à jour de son numéro et que le fil $j$ poursuit son exécution.

                Dans la phase d'attente active, le fil $j$ constatera que \texttt{ticket[$i$] = 0}, donc poursuivra l'exécution et entrera en section critique.

                Si le fil $i$ reprend son exécution, dans la phase d'attente active il constate que le fil $j$ a le même numéro mais n'est pas prioritaire car $i < j$, donc il poursuivra l'exécution et arrivera en section critique.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Algorithme de boulangerie}}
                Le problème de la tentative précédente est qu'un fil peut être interrompu pendant la phase d'attribution, ce qui permet à des fils non prioritaires de passer devant.
                L'idée de \textsc{Lamport} est d'ajouter une phase d'attente supplémentaire : un fil ne peut comparer un ticket avec celui d'un autre fil que si ce dernier n'est pas en cours d'attribution.

                \vspace{6pt}
                
                On utilise un tableau de booléens indiquant pour chaque fil s'il est dans la phase d'attribution.

                $\bullet$ Initialisation :

                \begin{emphBox}
                    \texttt{ticket} $\leftarrow$ tableau de taille $n$ contenant des 0

                    \texttt{attribution} $\leftarrow$ tableau de taille $n$ contenant \texttt{false}
                \end{emphBox}

                \vspace{6pt}
                
                $\bullet$ Phase d'attribution pour le fil $i$ :

                \begin{emphBox}
                    \texttt{attribution[$i$]} $\leftarrow$ \texttt{true}

                    $m \leftarrow \max(\mathtt{ticket})$

                    \texttt{ticket[$i$]} $\leftarrow m + 1$

                    \texttt{attribution[$i$]} $\leftarrow$ \texttt{false}
                \end{emphBox}

                \vspace{6pt}
                
                $\bullet$ Phase d'attente active pour le fil $i$ :

                \begin{emphBox}
                    \begin{indt}{Pour $i$ de 0 à $n - 1$ :}
                        \begin{indt}{Tant que \texttt{attribution[$j$]} est vrai :}
                            Attendre
                        \end{indt}

                        \vspace{6pt}
                        
                        \begin{indt}{Tant que \texttt{ticket[$j$] != 0} et (\texttt{ticket[$j$]}, $j$) $<$ (\texttt{ticket[$i$]}, $i$)}
                            Attendre
                        \end{indt}
                    \end{indt}
                \end{emphBox}

                \vspace{6pt}
                
                Sortie de section critique pour le fil $i$ :

                \begin{emphBox}
                    \texttt{ticket[$i$]} $\leftarrow 0$
                \end{emphBox}
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Correction de l'algorithme de la boulangerie de \textsc{Lamport}}}
                On dira qu'un fil d'exécution est dans la boulangerie entre le moment où il exécute la dernière instruction de la phase d'attribution et la fin de l'exécution de la sortie de section critique.

                $\bullet$ Lemme 1

                \begin{emphBox}
                    \textit{Lemme 1} : Si les fils $i$ et $j$ sont dans la boulangerie et si le fil $i$ y est entré avant que le fil $j$ exécute l'affectation \texttt{attribution[$j$] $\leftarrow$ true}, alors \texttt{ticket[$i$] < ticket[$j$]}.
                \end{emphBox}

                \begin{proof}
                    Lorsque le fil $j$ calcule $\max(\mathtt{ticket})$, \texttt{ticket[$i$]} contient déjà sa valeur courante (puisque $i$ est déjà dans la boulangerie).

                    Donc $\max(\mathtt{ticket}) \ge \mathtt{ticket}[i]$

                    et \texttt{ticket[$j$]} $\ge 1 + \mathtt{ticket[} i \mathtt ]$
                \end{proof}

                \vspace{12pt}
                
                $\bullet$ Lemme 2

                \begin{emphBox}
                    \textit{Lemme 2} :
                    Si le fil $i$ est en section critique et le fil $j$ est dans le boulangerie avec $i \neq j$, alors
                    \[
                        (\mathtt{ticket}[i], i) < (\mathtt{ticket}[j], j)
                    \]
                \end{emphBox}

                \begin{proof}
                    On note $t_{\rm read}$ l'instant où le fil $i$ lit pour la dernière fois \texttt{attribution[$j$]} dans la phase d'attente, et $t_{\rm wait}$ l'instant auquel il exécute son dernier tour dans la seconde boucle d'attente concernant le fil $j$.

                    On sait que $t_{\rm read} < t_{\rm wait}$.

                    On note :

                    $t_{\rm attr}$ l'instant auquel le fil $j$ exécute l'affectation \texttt{attribution[$j$] $\leftarrow$ true} ;

                    $t_{\rm write}$ l'instant auquel le fil $j$ a fini d'écrire la valeur de \texttt{ticket[$j$]} ;

                    $t_{\rm enter}$ l'instant auquel le fil $j$ entre dans le boulangerie.

                    \vspace{6pt}
                    
                    On sait que $t_{\rm attr} < t_{\rm write} < t_{\rm enter}$.

                    Par définition de $t_{\rm read}$, on sait que \texttt{attribution[$j$]} vaut \texttt{false} à l'instant $t_{\rm read}$.

                    Il y a deux possibilités :

                    $-$ Soit le fil $j$ n'est pas encore dans la phase d'attribution, \textit{i.e} $t_{\rm read} < t_{\rm attr}$.

                    Dans ce cas, comme $i$ et $j$ sont dans la boulangerie, et comme $i$ y est entré avant que $j$ commence la phase d'attribution, le lemme 1 assure que
                    \[
                        \mathtt{ticket}[i] < \mathtt{ticket}[j],
                    \]
                    donc que
                    \[
                        (\mathtt{ticket}[i], i) < (\mathtt{ticket}[j], j)
                    \]

                    $-$ Soit le fil $j$ a fini sa phase d'attribution à l'instant $t_{\rm read}$.

                    On a donc $t_{\rm write} < t_{\rm enter} < t_{\rm read} < t_{\rm wait}$

                    Donc à l'instant $t_{\rm wait}$, \texttt{ticket[$j$]} contient sa valeur courante et comme le fil $i$ a pu poursuivre son exécution, soit $\mathtt{ticket}[j] = 0$, soit $(\mathtt{ticket}[i], i) \le (\mathtt{ticket}[j], j)$.

                    Or $\mathtt{ticket}[j] \ge 1$ puisque l'attribution du ticket est déjà faite.

                    De plus, $(\mathtt{ticket}[i], i) \neq (\mathtt{ticket}[j], j)$, car $i \neq j$.

                    Donc
                    \[
                        (\mathtt{ticket}[i], i) < (\mathtt{ticket}[j], j)
                    \]
                \end{proof}

                \vspace{12pt}
                
                $\bullet$ Proposition

                \begin{emphBox}
                    \textit{Proposition} :
                    L'algorithme de la boulangerie garantit l'exclusion mutuelle.
                \end{emphBox}

                \vspace{6pt}
                
                \begin{proof}
                    Par l'absurde, on suppose que deux fils $i \neq j$ sont en section critique.

                    En particulier, il sont dans la boulangerie.

                    Par le lemme 2, on a donc :
                    \[
                        \begin{cases}
                            (\mathtt{ticket}[i], i) < (\mathtt{ticket}[j], j)
                            \\
                            (\mathtt{ticket}[j], j) < (\mathtt{ticket}[i], i)
                        \end{cases}
                    \]

                    Absurde.
                \end{proof}

                \vspace{12pt}
                
                $\bullet$ Proposition

                \begin{emphBox}
                    \textit{Proposition} :
                    L'algorithme de la boulangerie garantit le progrès de l'exécution.
                \end{emphBox}

                \vspace{12pt}
                
                \begin{proof}
                    Par l'absurde, on suppose qu'au moins un fil souhaite entrer en section critique, que la section critique est libre, et qu'on peut retarder indéfiniment l'entrée d'un fil en section critique.

                    Comme la phase d'attribution n'est pas bloquante, à un moment tous les fils seront soit dans la phase d'attente, soit ne souhaiterons pas entrer en section critique.

                    Il y a au moins un fil en phase d'attente, donc on peut considérer le fil $i$ en attente qui minimise $(\mathtt{ticket}[i], i)$ (car l'ordre lexicographique est bien fondé).

                    Pour chaque fil $j$ que le fil $i$ considère dans la phase d'attente, on sait que \texttt{attribution[$j$]} vaut \texttt{false} ($j$ est soit en phase d'attente, soit ne souhaite pas entrer en section critique), et si $\mathtt{ticket}[j] \neq 0$, alors $j$ est en phase d'attente.

                    Donc par définition de $i$, $(\mathtt{ticket}[i], i) \le (\mathtt{ticket}[j], j)$, donc $i$ ne peut pas être bloqué en phase d'attente : absurde.
                \end{proof}

                \vspace{12pt}
                
                $\bullet$ Proposition :

                \begin{emphBox}
                    \textit{Proposition} :
                    l'algorithme de la boulangerie garantit un temps d'attente borné.
                \end{emphBox}

                \vspace{6pt}
                
                \begin{proof}
                    Soit $i$ un fil souhaitant entrer en section critique. On considère ce fil après la phase d'attribution, \textit{i.e} $i$ est dans la boulangerie.

                    Soit $j$ un autre fil.

                    Si $j$ commence sa phase d'exécution après l'entrée de $i$ dans la boulangerie, le lemme 1 assure $\mathtt{ticket}[i] < \mathtt{ticket}[j]$, donc le fil $i$ passera avant $j$ en section critique.

                    Sinon deux possibilités : $i$ passe avant $j$ en section critique, soit $j$ passe avant $i$.

                    Dans ce dernier cas, si le fil $j$ souhaite revenir en section critique, il devra commencer une nouvelle phase d'attribution, et le lemme 1 garantit que $i$ entrera en section critique avant le second passage de $j$.

                    Donc dans le pire cas, un fil donné devra attendre un passage de chaque fil en section critique avant de pouvoir y entrer
                \end{proof}
            \end{indt}
        \end{indt}
    \end{indt}

    \vspace{12pt}
    
    \begin{indt}{\section{Outils techniques de synchronisation}}
        \begin{indt}{\subsection{Mutex}}
            \begin{indt}{\subsubsection{Introduction}}
                Un \textit{mutex} (pour \textit{mutual exclusion}) est une primitive de haut niveau pour l'exclusion qui se présente sous la forme d'un verrou : un fil d'exécution souhaitant entrer en section critique doit le verrouiller, puis le déverrouiller en sortie de section critique.
                Si le mutex est déjà verrouillé lorsqu'un fil tente de le verrouiller, il sera mis en attente.

                \vspace{12pt}
                
                Remarque : on ne dit rien sur l'implémentation des mutex, qui fonctionnent comme une boite noire pour le programmeur. Les algorithmes de \textsc{Petersen} et de \textsc{Lamport} sont des implémentations possibles de mutex, même s'il existe des solutions matérielles plus efficaces.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Mutex en OCaml}}
                \begin{indt}{Le module \texttt{Mutex} fournit les objets suivants :}
                    $\bullet$ Le type \texttt{Mutex.t} des mutex ;

                    $\bullet$ Une fonction \texttt{Mutex.create : unit -> Mutex.t} qui sert à créer un nouveau mutex ;

                    $\bullet$ Une fonction \texttt{Mutex.lock : Mutex.t -> unit} qui verrouille un mutex donné.
                    Si le mutex est déjà verrouillé, le fil appelant est interrompu ;

                    $\bullet$ Une fonction \texttt{Mutex.unlock : Mutex.t -> unit} qui déverrouille un mutex donné.
                    Important : le mutex doit être verrouillé, et c'est le fil appelant qui doit l'avoir verrouillé.
                    Les fils qui ont été interrompus parce qu'ils ont essayé de verrouiller ce mutex sont réveillés pour qu'ils tentent à nouveau de le verrouiller.
                \end{indt}

                \vspace{12pt}
                
                Exemple : on reprend la situation de compétition pour l'incrémentation d'une variable commune.
                Le fil d'exécution principal crée un mutex \texttt m, qu'il rend accessible aux fils secondaires.
                Le corps de la boucle des fils secondaires devient :

                \begin{lstlisting}[language=Caml, xleftmargin=80pt]
Mutex.lock m;
n := !n + 1;
Mutex.unlock m;\end{lstlisting}

                \textit{cf} les fichiers \texttt{no\_race\_mutex.ml} et \texttt{no\_race\_mutex\_more\_threads.ml}.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Mutex en C}}
                \begin{indt}{L'en-tête \texttt{pthread.h} donne accès aux objets suivants :}
                    $\bullet$ Le type \texttt{pthread\_mutex\_t} des mutex ;

                    \begin{indt}{$\bullet$ H.P (oubli du programme) : un mutex doit être initialisé. Il y a deux options :}
                        $-$ Au moment de la déclaration, on écrit une ligne de la forme
                        \begin{lstlisting}[language=C, xleftmargin=120pt]
pthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;\end{lstlisting}

                        $-$ Après la déclaration sans initialisation, on utilise la fonction de prototype
                        \begin{lstlisting}[language=C, xleftmargin=120pt]
int pthread_mutex_init(pthread_mutex_t* lock, const pthread_mutex_attr_t* attr);\end{lstlisting}

                        Le second paramètre est H.P, et la valeur \texttt{NULL} donne un comportement équivalent à l'initialisation directe.

                        L'entier renvoyé est un code d'erreur ;
                    \end{indt}

                    \vspace{6pt}
                    
                    $\bullet$ Les fonctions de prototypes
                    \begin{lstlisting}[language=C, xleftmargin=100pt]
int pthread_mutex_lock(pthread_mutex_t* lock);
int pthread_mutex_unlock(pthread_mutex_t* lock);\end{lstlisting}

                    qui fonctionnent comme \texttt{Mutex.lock} et \texttt{Mutex.unlock} en OCaml.

                    Les entiers renvoyés sont des codes d'erreur ;

                    \vspace{6pt}
                    
                    $\bullet$ La fonction de prototype
                    \begin{lstlisting}[language=C, xleftmargin=100pt]
int pthread_mutex_destroy(pthread_mutex_t* lock);\end{lstlisting}

                    qui sert à détruire le mutex, \textit{i.e} à le remettre dans un état non initialisé.

                    L'entier renvoyé est un code d'erreur.
                \end{indt}

                \vspace{12pt}
                
                Remarque : le module \texttt{Mutex} d'OCaml est implémenté en utilisant ces fonctions.

                Exemple : \textit{cf} \texttt{no\_race\_mutex.c} et \texttt{no\_race\_mutex\_more\_threads.c}.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Retour sur le problème du dîner des philosophes}}
                \label{3.1.4}

                On se propose d'essayer d'utiliser les mutex pour résoudre ce problème.

                \begin{indt}{$\bullet$  Première tentative : on pourrait utiliser un mutex global concernant l'activité \texttt{manger}.}
                    Code :

                    $-$ Déclaration globale :

                    \begin{lstlisting}[language=C, xleftmargin=100pt]
pthread_mutex_t diner = PTHREAD_MUTEX_INITIALIZER;\end{lstlisting}

                    $-$ Fonction exécutée par chaque philosophe :

                    \newpage

                    \begin{lstlisting}[language=C, xleftmargin=100pt]
void* philosopher(void* args) {
    int i = *((int*) args);
    printf("Philosopher %d is starting\n", i);

    while (true) {
        printf("Philosopher %d is thinking\n", i);
        pthread_mutex_lock(&diner);
        printf("Philosopher %d is eating\n", i);
        pthread_mutex_unlock(&diner);
    }
}\end{lstlisting}

                    On n'oublie pas la destruction du mutex par le fil principal avant la fin de son exécution.

                    \textit{cf} \texttt{philosopher\_0.c}
                \end{indt}

                \vspace{12pt}
                
                Problème : on n'exploite pas toutes les possibilités du modèle concurrent car on pourrait autoriser deux philosophes à manger en même temps.

                \vspace{12pt}
                
                \begin{indt}{$\bullet$ Deuxième tentative :}
                    Puisqu'on veut autoriser plusieurs philosophes à manger en même temps, il faut tenir compte de la disponibilité des baguettes.

                    On utilise un tableau de booléens \texttt{stick[5]}, et le philosophe $i$ doit prendre les baguettes $i$ et $i + 1 \mod 5$ pour pouvoir manger.

                    Pour éviter les situations de compétition, on protège les accès au tableau par un mutex.

                    Code :

                    $-$ Déclaration globale :

                    \begin{lstlisting}[language=C, xleftmargin=100pt]
bool stick[5] = {true};
pthread_mutex_t array = PTHREAD_MUTEX_INITIALIZER;\end{lstlisting}

                    $-$ Boucle du philosophe $i$ :

                    \begin{lstlisting}[language=C, xleftmargin=100pt]
while (true) {
    printf("Philosopher %d is thinking\n", i);

    pthread_mutex_lock(&array);

    if (stick[i] && stick[(i + 1) % 5]) {
        stick[i] = false;
        stick[(i + 1) % 5] = false;
        pthread_mutex_unlock(&array);

        printf("Philosopher %d is eating\n", i);

        //No race situation here even if access is not protected
        stick[i] = true; 
        stick[(i + 1) % 5] = true;
    }
    else
        pthread_mutex_unlock(&array);
}\end{lstlisting}

                    \textit{cf} \texttt{philosopher\_1.c}
                \end{indt}

                \vspace{12pt}
                
                Problème : on reproduit de l'attente active, et il peut y avoir famine si un philosophe n'a pas de chance avec les interruptions entre ses tests.

                \vspace{12pt}
                
                \begin{indt}{$\bullet$ Troisième tentative :}
                    Pour éviter l'attente active, on décide d'utiliser un mutex par baguette : un philosophe souhaitant manger doit verrouiller les deux mutex correspondant à ses baguettes.
                    L'attente active est remplacée par l'interruption jusqu'au déverrouillage du mutex.

                    $-$ Déclaration globale : on suppose déclaré et initialisé un tableau :

                    \begin{lstlisting}[language=C, xleftmargin=100pt]
pthread_mutex_t stick[5];\end{lstlisting}

                    $-$ Boucle du philosophe $i$ :

                    \begin{lstlisting}[language=C, xleftmargin=100pt]
while (true) {
    printf("Philosopher %d is thinking\n", i);

    pthread_mutex_lock(stick + i);
    pthread_mutex_lock(stick + ((i + 1) % 5));

    printf("Philosopher %d is eating", i);

    pthread_mutex_unlock(stick + i);
    pthread_mutex_unlock(stick + ((i + 1) % 5));
}\end{lstlisting}

                    \textit{cf} \texttt{philosopher\_2.c}
                \end{indt}

                \vspace{12pt}
                
                Problème : il peut y avoir interblocage si chaque philosophe détient une baguette (\textit{cf} \ref{1.2.4}, page \pageref{1.2.4}).

                \vspace{12pt}
                
                Solution simple : on impose aux philosophes d'identifiant impair de verrouiller d'abord le mutex $(i + 1) \mod 5$.

                Inconvénient : cela brise la symétrie entre les philosophes. On voudrait que chaque fil d'exécution exécute le même programme.

                \vspace{12pt}
                
                \begin{indt}{$\bullet$ Autre idée :}
                    Pour garder la symétrie, on pourrait limiter le nombre de philosophes autorisés à tenir une baguette simultanément.

                    Question : pourquoi une limite égale à quatre convient-t-elle ?

                    Il reste toujours un baguette libre pour l'un de ces quatre philosophes.

                    \begin{center}
                       \begin{tikzpicture}[scale=1.8]
                           \foreach \i in {0, 1, ..., 4} {
                               \node (\i) at (\i*72+90 : 1) [circle, draw] {\i};
                               \draw (\i*72+90+36 : .5) to (\i*72+90+36 : 1.5);
                           }

                           %\draw[dashed] (1) -- (126 : 1);

                           \foreach \i in {1, 2, 3, 4} {
                               \draw[dashed] (\i) -- (\i*72+90+36 : 1);
                           }

                           %\node at (0, 0) {$\cdot$};
                       \end{tikzpicture}
                    \end{center}

                    On a donc besoin d'un compteur sur le nombre de philosophes tenant une baguette, protégé par une section critique pour éviter les situations de compétition et qui soit bloquant pour un philosophe qui souhaite prendre une baguette alors que les quatre autres en tiennent une.
                    C'est impossible sans attente active avec les mutex (même problème que la deuxième tentative).

                    Une généralisation des mutex, appelée sémaphore, permet de gérer ce type de capteur sans attente active.
                \end{indt}
            \end{indt}
        \end{indt}

        \vspace{12pt}
        
        \begin{indt}{\subsection{Sémaphores}}
            \begin{indt}{\subsubsection{Introduction}}
                Conçus dans les années 1960 par \textsc{Dijkstra}, les sémaphores permettent de compter le nombre d'accès simultanés à une resource et de mettre en attente tout processus souhaitant accéder à la resource si le nombre maximal d'accès est atteint.

                Le \emph{sémaphore} est une primitive de synchronisation de haut niveau dont l'implémentation peut varier selon les systèmes.

                On distingue le sémaphore \emph{binaire}, qui ne permet qu'un accès à la resource et correspond donc au mutex, du sémaphore à \emph{compteur}, qui autorise plus d'accès simultanés.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Définition (\emph{sémaphore à compteur})}}
                \label{3.2.2}

                \begin{indt}{Un \emph{sémaphore à compteur} est une structure contenant :}
                    $\bullet$ un compteur initialisé par l'utilisateur avec une valeur positive ;

                    $\bullet$ une file d'attente pour les fils d'exécutions interrompus.
                \end{indt}

                \vspace{12pt}
                
                \begin{indt}{Cette structure doit venir avec des primitives de création, d'initialisation (parfois de destruction), et de manipulation du compteur :}
                    $\bullet$ Une opération nommée P : si le compteur est strictement positif, il est décrémenté et le fil poursuit son exécution. Sinon, le fil est placé dans la file d'attente ;

                    $\bullet$ Une opération nommée V : s'il existe un fil d'exécution dans la file d'attente, il est réveillé et poursuit son exécution (la ressource est devenue disponible pour ce fil).
                    Sinon, le compteur est incrémenté.
                \end{indt}

                \vspace{12pt}
                
                Attention : on ne dit rien sur le fonctionnement de la file d'attente, même si un comportement proche de celui d'une file (de priorité) est désirable pour éviter les famines.

                \vspace{12pt}
                
                Remarque : on explique souvent les noms P et V par les termes néerlandais \textit{proberen} (tester) et \textit{verhogen} (incrémenter), même s'il sont souvent remplacés par d'autres termes, comme \textit{wait} et \textit{signal} (\textit{cf} TD$_{36}$), ou \textit{pend} et \textit{post}.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Syntaxe de la manipulation  des sémaphores}}
                Même s'il existe un module \texttt{Semaphore} en OCaml, contenant deux sous-modules pour les sémaphores binaires et à compteur, le programme limite la programmation avec les sémaphores au language C.

                Le fichier d'en-tête \texttt{semaphore.h} donne accès aux primitives des sémaphores à compteur (qui généralisent les sémaphores binaires).

                \vspace{12pt}
                
                \begin{indt}{L'en-tête donne accès aux objets suivants :}
                    $\bullet$ Le type \texttt{sem\_t} des sémaphores ;

                    $\bullet$ Une fonction de prototype
                    \begin{lstlisting}[language=C, xleftmargin=100pt]
int sem_init(sem_t* sem, int pshared, unigned value);\end{lstlisting}

                    qui initialise le sémaphore \texttt{sem} avec la valeur ($\ge 0$) \texttt{value}.
                    Dans notre cas, l'entier \texttt{pshared} vaudra toujours 0 pour signaler que le sémaphore est partagé entre les fils du processus (une valeur non nulle signale que le sémaphore est partagé entre plusieurs processus, c'est donc H.P).

                    L'entier renvoyé est un code d'erreur ;

                    $\bullet$ Une fonction de prototype
                    \begin{lstlisting}[language=C, xleftmargin=100pt]
int sem_destroy(sem_t* sum);\end{lstlisting}
                    qui détruit un sémaphore dont la file d'attente est vide ;

                    $\bullet$ Une fonction implémentant l'opération P, de prototype
                    \begin{lstlisting}[language=C, xleftmargin=100pt]
int sem_wait(sem_t* sem);\end{lstlisting}
                    Différence avec \ref{3.2.2} : le compteur est toujours décrémenté, et le fil appelant est placé dans un fil d'attente si la nouvelle valeur du compteur est strictement négative ;

                    $\bullet$ Une fonction implémentant l'opération V, de prototype
                    \begin{lstlisting}[language=C, xleftmargin=100pt]
int sem_post(sem_t* sem);\end{lstlisting}
                    Différence avec \ref{3.2.2} : le compteur est toujours incrémenté, et il existe un fil en attente qui sera réveillé si et seulement si la nouvelle valeur du compteur est négative ou nulle.
                \end{indt}
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Application : le dîner des philosophes}}
                On revient à l'idée évoquée en \ref{3.1.4} (page \pageref{3.1.4}) : afin d'éviter les interblocages liés aux verrous pris simultanément sur les baguettes par tous les philosophes, on limite à l'aide d'un sémaphore le nombre de philosophes pouvant prendre un verrou à quatre.

                \vspace{12pt}
                
                $\bullet$ Initialisation :

                \begin{lstlisting}[language=C, xleftmargin=80pt]
sem_t pick_up;
sem_init(&pick_up, 0, 4);

pthread_mutex_t stick[5];
for (int k = 0 ; k < 5 ; k++) {
    pthread_mutex_init(&stick[i], NULL);
}\end{lstlisting}

                $\bullet$ Boucle du philosophe $i$ :

                \begin{lstlisting}[language=C, xleftmargin=80pt]
while (true) {
    printf("Philosopher %d is thinking\n", i);

    sem_wait(&pick_up);
    pthread_mutex_lock(stick + i);
    pthread_mutex_lock(stick + ((i + 1) %5));

    //Possible to put sem_post here

    printf("Philosopher %d is eating\n", i);

    pthread_mutex_unlock(stick + i);
    pthread_mutex_unlock(stick + ((i + 1) %5));

    sem_post(&pick_up);
}\end{lstlisting}

                Remarque : ce programme garantit l'absence d'interblocage, mais l'absence de famine dépend d'une gestion équitable de la file d'attente.

                \vspace{12pt}
                
                \textit{cf} \texttt{philosopher\_sem.c}
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Application : producteurs-consommateurs}}
                $\bullet$  Rappel : on a un buffer dans lequel les producteurs écrivent des données, et les consommateurs prennent ces données.

                \begin{indt}{$\bullet$ Besoins :}
                    $-$ Il faut garantir l'exclusion mutuelle pour l'accès au buffer ;

                    $-$ un consommateur souhaitant prendre une donnée dans un buffer vide doit être mis en attente ;

                    $-$ un producteur souhaitant écrire dans un buffer plein doit être mis en attente.
                \end{indt}

                \vspace{6pt}
                
                \begin{indt}{$\bullet$ Outils :}
                    $-$ l'accès au buffer est protégé par un mutex \texttt{access} ;

                    $-$ la mise en attente des consommateurs est assurée par un sémaphore \texttt{full} qui compte le nombre de cases occupées : u producteur souhaitant écrire une donnée dans le buffer incrémente ce sémaphore après écriture, et un consommateur souhaitant prendre une donnée décrémente ce sémaphore avant la lecture ;

                    $-$ la mise en attente des producteurs est assurée par un sémaphore \texttt{empty} qui compte le nombre de cases vides : un producteur souhaitant écrire dans le buffer décrémente ce sémaphore avant l'écriture, et un consommateur souhaitant prendre une donnée incrémente ce compteur après la lecture.
                \end{indt}

                \vspace{6pt}
                
                $\bullet$ Code :

                Boucle producteur $i$ :
                \begin{lstlisting}[language=C, xleftmargin=80pt]
sem_wait(&empty);
pthread_mutex_lock(&acces);
int k = rand() % 100;
pritnf("producer %d is writing %d\n", i, k);
add(k, buffer);
pthread_mutex_unlock(&access);
sem_post(&full);\end{lstlisting}

                Boucle consommateur $i$ :
                \begin{lstlisting}[language=C, xleftmargin=80pt]
sem_wait(&full);
pthread_mutex_lock(&access);
int k = take(buffer);
printf("consumer %d is reading %d\n", i, k);
pthread_mutex_unlock(&access);
sem_post(&empty);\end{lstlisting}

                Remarque : un buffer est une file que l'on peut implémenter grâce à un structure contenant une liste chaînée et un pointeur vers le dernier élément de la liste (on ajoute en fin de liste et on extrait la tête) + un compteur pour vérifier la taille du buffer, ou bien à l'aide d'un tableau et de deux indices indiquant le début et la fin des données.

                \begin{lstlisting}[language=C, xleftmargin=80pt]
typedef struct {
    int start;
    int end;
    int buffer[SIZE];
} le_buffer_de_Gaspard;\end{lstlisting}

                \textit{cf} \texttt{prod\_cons.c}
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Application : barrière de synchronisation}}
                Une \emph{barrière de synchronisation} pour $n$ fils d'exécution permet de bloquer les fils sur un point de rendez-vous tant que les $n$ fils n'y sont pas tous arrivés.
                Cela permet donc de resynchroniser des fils dont l'exécution ne progresse pas de la même façon.

                Idée : on utilise un sémaphore initialisé à 0 que les $n - 1$ premiers arrivés à la barrière décrémentent. Le dernier fil constate qu'il est dernier et incrémente $n - 1$ fois le sémaphore pour relancer l'exécution de tous les fils.

                Pour que le dernier fil sache qu'il est le dernier, on utilise un compteur de fil en attente protégé par un mutex.

                \vspace{12pt}
                
                $\bullet$ Initialisation :
                \begin{lstlisting}[language=C, xleftmargin=80pt]
sem_t barrier;
sem_init(&barrier, 0, 0);
int waiting = 0;
pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;\end{lstlisting}

                $\bullet$ Arrivée sur la barrière :
                \begin{lstlisting}[language=C, xleftmargin=80pt]
pthread_mutex_lock(&lock);

if (waiting < n - 1) {
    waiting++;
    pthread_mutex_unlock(&lock);
    sem_wait(&barrier);
}
else {
    for (int i = 0 ; i < n - 1 ; i++)
        sem_post(&barrier);

    waiting = 0;
    pthread_mutex_unlock(&lock);
}\end{lstlisting}

                \textit{cf} \texttt{barrier.c}
            \end{indt}
        \end{indt}
    \end{indt}
    
    
    
\end{document}
%--------------------------------------------End
