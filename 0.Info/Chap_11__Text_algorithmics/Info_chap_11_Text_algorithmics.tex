\documentclass[a4paper, 12pt, twoside]{article}


%------------------------------------------------------------------------
%
% Author                :   Lasercata
% Last modification     :   2022.06.27
%
%------------------------------------------------------------------------


%------ini
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
%\usepackage[english]{babel}


%------geometry
\usepackage[textheight=700pt, textwidth=500pt]{geometry}


%------color
\usepackage{xcolor}
\definecolor{ff4500}{HTML}{ff4500}
\definecolor{00f}{HTML}{0000ff}
\definecolor{0ff}{HTML}{00ffff}
\definecolor{656565}{HTML}{656565}

\renewcommand{\emph}{\textcolor{ff4500}}
\renewcommand{\em}{\color{ff4500}}

\newcommand{\strong}[1]{\textcolor{ff4500}{\bf #1}}
\newcommand{\st}{\color{ff4500}\bf}


%------Code highlighting
%---listings
\usepackage{listings}

\definecolor{cbg}{HTML}{272822}
\definecolor{cfg}{HTML}{ececec}
\definecolor{ccomment}{HTML}{686c58}
\definecolor{ckw}{HTML}{f92672}
\definecolor{cstring}{HTML}{e6db72}
\definecolor{cstringlight}{HTML}{98980f}
\definecolor{lightwhite}{HTML}{fafafa}

\lstdefinestyle{DarkCodeStyle}{
    backgroundcolor=\color{cbg},
    commentstyle=\itshape\color{ccomment},
    keywordstyle=\color{ckw},
    numberstyle=\tiny\color{cbg},
    stringstyle=\color{cstring},
    basicstyle=\ttfamily\footnotesize\color{cfg},
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=4,
    xleftmargin=\leftskip
}

\lstdefinestyle{LightCodeStyle}{
    backgroundcolor=\color{lightwhite},
    commentstyle=\itshape\color{ccomment},
    keywordstyle=\color{ckw},
    numberstyle=\tiny\color{cbg},
    stringstyle=\color{cstringlight},
    basicstyle=\ttfamily\footnotesize\color{cbg},
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=10pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=4,
    frame=L,
    xleftmargin=\leftskip
}

%\lstset{style=DarkCodeStyle}
\lstset{style=LightCodeStyle}
%Usage : \begin{lstlisting}[language=Caml] ... \end{lstlisting}

%---tcolorbox
\usepackage[many]{tcolorbox}
\DeclareTColorBox{pseudocode}{O{black}O{lightwhite}}{
    breakable,
    outer arc=0pt,
    arc=0pt,
    top=0pt,
    toprule=-.5pt,
    right=0pt,
    rightrule=-.5pt,
    bottom=0pt,
    bottomrule=-.5pt,
    colframe=#1,
    colback=#2,
    enlarge left by=10pt,
    width=\linewidth-\leftskip-10pt,
}


%-------make the table of content clickable
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}
%Uncomment this and comment above for dark mode
% \hypersetup{
%     colorlinks,
%     citecolor=white,
%     filecolor=white,
%     linkcolor=white,
%     urlcolor=white
% }


%------pictures
\usepackage{graphicx}
%\usepackage{wrapfig}

\usepackage{tikz}
%\usetikzlibrary{babel}             %Uncomment this to use circuitikz
%\usetikzlibrary{shapes.geometric}  % To draw triangles in trees
%\usepackage{circuitikz}            %Electrical circuits drawing
\usetikzlibrary{patterns, snakes}


%------tabular
%\usepackage{color}
%\usepackage{colortbl}
%\usepackage{multirow}


%------Physics
%---Packages
%\usepackage[version=4]{mhchem} %$\ce{NO4^2-}$

%---Commands
\newcommand{\link}[2]{\mathrm{#1} \! - \! \mathrm{#2}}
\newcommand{\pt}[1]{\cdot 10^{#1}} % Power of ten
\newcommand{\dt}[2][t]{\dfrac{\mathrm d #2}{\mathrm d #1}} % Derivative


%------math
%---Packages
%\usepackage{textcomp}
%\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools} % For abs
\usepackage{stmaryrd} %for \llbracket and \rrbracket
\usepackage{mathrsfs} %for \mathscr{x} (different from \mathcal{x})

%---Commands
%-Sets
\newcommand{\N}{\mathbb{N}} %set N
\newcommand{\Z}{\mathbb{Z}} %set Z
\newcommand{\Q}{\mathbb{Q}} %set Q
\newcommand{\R}{\mathbb{R}} %set R
\newcommand{\C}{\mathbb{C}} %set C
\newcommand{\U}{\mathbb{U}} %set U
\newcommand{\seg}[2]{\left[ #1\ ;\ #2 \right]}
\newcommand{\nset}[2]{\left\llbracket #1\ ;\ #2 \right\rrbracket}

%-Exponantial / complexs
\newcommand{\e}{\mathrm{e}}
\newcommand{\cj}[1]{\overline{#1}} %overline for the conjugate.

%-Vectors
\newcommand{\vect}{\overrightarrow}
\newcommand{\veco}[3]{\displaystyle \vect{#1}\binom{#2}{#3}} %vector + coord

%-Limits
\newcommand{\lm}[2][{}]{\lim\limits_{\substack{#2 \\ #1}}} %$\lm{x \to a} f$ or $\lm[x < a]{x \to a} f$
\newcommand{\Lm}[3][{}]{\lm[#1]{#2} \left( #3 \right)} %$\Lm{x \to a}{f}$ or $\Lm[x < a]{x \to a}{f}$
\newcommand{\tendsto}[1]{\xrightarrow[#1]{}}

%-Integral
\newcommand{\dint}[4][x]{\displaystyle \int_{#2}^{#3} #4 \mathrm{d} #1} %$\dint{a}{b}{f(x)}$ or $\dint[t]{a}{b}{f(t)}$

%-left right
\newcommand{\lr}[1]{\left( #1 \right)}
\newcommand{\lrb}[1]{\left[ #1 \right]}
\newcommand{\lrbb}[1]{\left\llbracket #1 \right\rrbracket}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}
\newcommand{\lrangle}[1]{\left\langle #1 \right\rangle}

%-Others
\newcommand{\para}{\ /\!/\ } %//
\newcommand{\ssi}{\ \Leftrightarrow \ }
\newcommand{\eqsys}[2]{\begin{cases} #1 \\ #2 \end{cases}}

\newcommand{\med}[2]{\mathrm{med} \left[ #1\ ;\ #2 \right]}  %$\med{A}{B} -> med[A ; B]$
\newcommand{\Circ}[2]{\mathscr{C}_{#1, #2}}

\renewcommand{\le}{\leqslant}
\renewcommand{\ge}{\geqslant}

\newcommand{\oboxed}[1]{\textcolor{ff4500}{\boxed{\textcolor{black}{#1}}}} %orange boxed


%------commands
%---to quote french text
\newcommand{\simplecit}[1]{\guillemotleft$\;$#1$\;$\guillemotright}
\newcommand{\cit}[1]{\simplecit{\textcolor{656565}{#1}}}
\newcommand{\quo}[1]{\cit{\it #1}}

%---to indent
\newcommand{\ind}[1][20pt]{\advance\leftskip + #1}
\newcommand{\deind}[1][20pt]{\advance\leftskip - #1}

%---to indent a text
\newcommand{\indented}[2][20pt]{\par \ind[#1] #2 \par \deind[#1]}
\newenvironment{indt}[2][20pt]{#2 \par \ind[#1]}{\par \deind} %Titled indented env

%---title
\newcommand{\thetitle}[2]{\begin{center}\textbf{{\LARGE \underline{\emph{#1} :}} {\Large #2}}\end{center}}


%------Sections
% To change section numbering :
% \renewcommand\thesection{\Roman{section}}
% \renewcommand\thesubsection{\arabic{subsection}}
% \renewcommand\thesubsubsection{\textit \alph{subsubsection}}

% To start numbering from 0
% \setcounter{section}{-1}


%------page style
\usepackage{fancyhdr}
\usepackage{lastpage}

\setlength{\headheight}{18pt}
\setlength{\footskip}{50pt}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LE, RO]{\textit{\textcolor{black}{\today}}}
\fancyhead[RE, LO]{\large{\textsl{\emph{\texttt{\jobname}}}}}

\fancyfoot[RO, LE]{\textit{\texttt{\textcolor{black}{Page \thepage /}\pageref{LastPage}}}} %Change 'black' to 'white' for dark mode
\fancyfoot[LO, RE]{\includegraphics[scale=0.12]{/home/lasercata/Pictures/1.images_profil/logo/mieux/lasercata_logo_fly_fond_blanc.png}}

% For dark mode :
%/home/lasercata/Pictures/1.images_profil/logo/mieux/lasercata_logo_fly.png


%------init lengths
\setlength{\parindent}{0pt} %To avoid using \noindent everywhere.
\setlength{\parskip}{3pt}


%---------------------------------Begin Document
\begin{document}
    
    %For dark mode :
    % \pagecolor{black}
    % \color{white}
    
    \thetitle{Chapitre 11}{Algorithmique du texte}
    
    \tableofcontents
    \newpage
    
    
    \begin{indt}{\section{Recherche dans un texte}}
        
        \begin{indt}{\subsection{Introduction}}
            \begin{indt}{\subsubsection{Problème}}
                \'Etant donné un texte (un fichier / une chaîne de caractères) $t$, et un motif (une chaîne de caractères) $x$, on veut trouver toutes les occurrences de $x$ dans $t$ (\textit{i.e} on veut les positions (indices)).
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Algorithme naïf}}
                On teste toutes les positions dans $t$ pour déterminer si ce sont des positions d'occurrences de $x$ :

                \begin{lstlisting}[language=Caml, xleftmargin=80pt]
let recherche_naive (x : string) (t : string) : int list =
    let l = ref []in
    let n = String.length t
    and m = String.length x in

    for i = 0 to n - m do
        let j = ref 0 in
        while !j < m && x.[!j] = t.[i + !j] do
            incr j
        done;

        if !j = m then l := i::!l
    done;
    !l\end{lstlisting}

                Complexité : dans le pire cas, la boucle \texttt{while} s'arrête au dernier indice dans $x$ (exemple : $t = a^n = \underbrace{a \cdots a}_{n\ \text{fois}\ a}$, et $x = a^{m - 1}b$) : $\mathcal O((n - m + 1)m) = \mathcal O(nm)$ si $m$ est petit devant $n$.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Remarque}}
                Cet algorithme fait partie d'une famille d'algorithmes, dits de \textit{fenêtre glissante} : on fait glisser une fenêtre sur le texte en notant toutes les positions auxquelles la fenêtre contient le motif.

                \begin{center}
                    \begin{tikzpicture}
                        \draw (0, 0) -- (4, 0);
                        \draw (0, -.5) -- (4, -.5);

                        \draw (1, 0) rectangle (3, -.5);

                        \node (t) at (-.3, -.25) {$t$};
                        \node (i) at (1, .3) {$i$};

                        \node (e) at (2, -.7) {$=$ ?};

                        \draw (1, -1) rectangle (3, -1.5);
                        \node (x) at (.7, -1.25) {$x$};
                    \end{tikzpicture}
                \end{center}

                Le côté naïf de cet algorithme vient du fait que l'on fait systématiquement glisser la fenêtre d'un rang, quel que soit son contenu. En analysant les raisons de l'échec d'une comparaison, on peut espérer décaler la fenêtre de plusieurs rangs.
            \end{indt}
        \end{indt}

        \vspace{12pt}
        
        \begin{indt}{\subsection{Algorithme de \textsc{Boyer-Moore}}}
            \begin{indt}{\subsubsection{Introduction}}
                L'algorithme de \textsc{Boyer-Moore} est un algorithme de fenêtre glissante, mais la comparaison entre le contenu de la fenêtre et le motif se fait de la droite vers la gauche, afin de repérer en cas d'échec le caractère le plus à droite qui ne correspond pas au motif. \`A partir de cette position qui entraîne l'échec de la comparaison, on peut calculer un décalage pour la fenêtre.

                En pratique le décalage est précalculé pour toutes les positions du motif et il existe de nombreuses variantes suivant la manière dont le décalage est calculé.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Algorithmique de \textsc{Boyer-Moore-Horspool}}}
                \label{1.2.2}
                
                Dans cette variante, si la comparaison de $x_0 \ldots x_{m - 1}$ et $t_i \ldots t_{i + m - 1}$ (la fenêtre) échoue à l'indice $j$, \textit{i.e} $x_{j + 1} \ldots x_{m - 1} = t_{i + j + 1} \ldots t_{i + m - 1}$ et $x_j \neq t_{i + j}$, on cherche à aligner $t_{i + m - 1}$ avec son occurrence la plus à droite dans $x$ (sauf $x_{m - 1}$)
                \begin{center}
                    \begin{tikzpicture}
                        \draw (0, 0) -- (6, 0);
                        \draw (0, -.5) -- (6, -.5);

                        \draw (1, 0) rectangle (2, -.5);
                        \draw (3, 0) rectangle (3.5, -.5);

                        \draw (1, 0) rectangle (5, -.5);

                        \node (t) at (-.3, -.25) {$t$};
                        \node (i) at (1, .3) {$i$};
                        \node at (3, .3) {$i + j$};

                        \node at (4, -.25) {$u$};
                        \node at (4.75, -.25) {$c$};
                        \draw[dashed] (4.5, 0) -- (4.5, -.5);

                        \node at (3.25, -.75) {$\neq$};
                        
                        \draw (3, -1) rectangle (3.5, -1.5);

                        \draw (1, -1) rectangle (5, -1.5);
                        \draw (2, -1) rectangle (2.5, -1.5);

                        \node at (2.25, -1.25) {$c$};
                        \node (x) at (.7, -1.25) {$x$};
                        \node at (3, -1.75) {$j$};
                        
                        \draw[->] (2, -2.5) -- (3.5, -2.5);
                        
                        \draw (3, -3) rectangle (6, -3.5);
                        \draw (3.5, -3) rectangle (4, -3.5);
                        \node at (3.75, -3.25) {$c$};
                        
                        \draw (4.5, -3) rectangle (4.75, -3.5);
                        \node at (4.5, -3.8) {$j$};
                        
                        \node at (5.5, -3.25) {$u$};
                    \end{tikzpicture}
                \end{center}

                Exemple : $x = aababab$ et $t = aabbbababacaabbaba$

                $aab\underset{\times} a bab$

                $a \underset \times a babab$

                $aababa\underset \times b$

                \vspace{12pt}
                
                Algorithme : pour toute lettre $a$, on note $d(a)$ le décalage à effectuer pour aligner cette lettre avec don occurrence la plus à droite  dans $x$ (sauf la dernière lettre) en cas d'échec d'une comparaison avec une fenêtre dont la dernière lettre est $a$.
                \[
                    d(a) =
                    \begin{cases}
                        \abs u\ \text{si $u$ est les plus petit suffixe non vide de $x$ tq $au$ est suffixe de $x$}
                        \\
                        \abs x\ \text{si $u$ n'existe pas, \textit{i.e} si $x$ ne contient pas $a$, ou alors seulement en dernière position}
                    \end{cases}
                \]

                Pseudo-code :
                \begin{pseudocode}
                    $i \leftarrow 0$

                    \begin{indt}{Tant que $i \le n - m$ :}
                        $j \leftarrow m - 1$
                        
                        \vspace{6pt}

                        \begin{indt}{Tant que $j \ge 0$ et $x_j = t_{i + j}$ :}
                            $j \leftarrow j - 1$
                        \end{indt}
                        
                        \vspace{6pt}

                        \begin{indt}{Si $j = -1$ :}
                            $i$ est la position d'une occurrence de $x$

                            $i \leftarrow i + 1$
                        \end{indt}
                        
                        \vspace{6pt}

                        \begin{indt}{Sinon :}
                            $i \leftarrow i + d(t_{i + m - 1})$
                        \end{indt}
                    \end{indt}
                \end{pseudocode}

                Précalcul de $d$ :

                \begin{pseudocode}
                    Pour toute lettre $a$, $d(a) \leftarrow m$
                        
                    \vspace{6pt}

                    \begin{indt}{Pour $i$ de 0 à $m - 2$ :}
                        $d(x_i) \leftarrow m - 1 - i$
                    \end{indt}
                \end{pseudocode}

                \begin{center}
                    \begin{tikzpicture}
                        \draw (0, 0) rectangle (5, -.5);

                        \draw (2, 0) rectangle (2.5, -.5);

                        \node (i) at (2, .3) {$i$};
                        \draw[<->] (2.5, .2) -- (5, .2);
                        \node at (3.75, .5) {$m - i - 1$};
                    \end{tikzpicture}
                \end{center}

                Complexité :

                $-$ Précalcul : $\mathcal O\!\lr{\abs A + m}$ où $A$ est l'alphabet, \textit{i.e} l'ensemble des symboles possibles dans un texte.

                $-$ Algorithme : dans le pire cas, on décale toujours d'un rang (exemple : $t = a^n$ et $x = ba^{m - 1}$) : même complexité que l'algorithme naïf.

                En pratique, c'est plus efficace : $\mathcal O(n)$ en moyenne (admis).
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Algorithme de \textsc{Boyer-Moore} (simplifié)}}
                \label{1.2.3}
                
                L'algorithme de \textsc{Boyer-Moore-Horspool} ne tient pas compte de ce qu'il se passe lors de la lecture de la fenêtre, mais seulement de son dernier caractère.

                Par exemple : si $x = aababab$ et la fenêtre vaut $aabcbab$, le décalage calculé vaut 2 alors que l'absence de $c$ dans $x$ permet un décalage de 4 rangs.

                L'idée de \textsc{Boyer} et \textsc{Moore} est d'aligner plutôt de caractère qui provoque l'échec de la comparaison avec son occurrence la plus à droite dans $x$ (sauf la dernière lettre).

                Plus précisément, si $x_j \neq t_{i + j}$ et $x_{j + 1} \ldots t_{i + j + 1} \ldots t_{i + m - 1}$, alors on décale la fenêtre de $d(t_{i + j}) - (m - 1 - j)$

                \begin{center}
                    \begin{tikzpicture}
                        \draw (0, 0) -- (6, 0);
                        \draw (0, -.5) -- (6, -.5);

                        \draw (1, 0) rectangle (2, -.5);
                        \draw (3.5, 0) rectangle (4, -.5);

                        \draw (1, 0) rectangle (5, -.5);

                        \node (t) at (-.3, -.25) {$t$};
                        \node (i) at (1, .3) {$i$};
                        \node at (3.5, .3) {$i + j$};

                        \node at (3.75, -.25) {$c$};

                        \node at (4.5, -.25) {$u$};

                        \node at (3.75, -.75) {$\neq$};

                        \draw (3.5, -1) rectangle (4, -1.5);
                        \draw (1, -1) rectangle (5, -1.5);
                        \draw (2, -1) rectangle (2.5, -1.5);

                        \node at (2.25, -1.25) {$c$};
                        \node (x) at (.7, -1.25) {$x$};
                        \node at (4.5, -1.25) {$u$};

                        \node at (3.5, -1.75) {$j$};

                        \draw[<->] (2.5, -2) to node [below] {$d(c)$} (5, -2);
                        
                        \draw[<->] (2.5, -3) to node [below] {décalage $= d(c) - u = d(c) - (m - 1 - j)$} (3.5, -3);
                    \end{tikzpicture}
                \end{center}

                Attention : cela ne fait pas toujours progresser la recherche :

                \begin{center}
                    \begin{tikzpicture}
                        \draw (0, 0) -- (6, 0);
                        \draw (0, -.5) -- (6, -.5);

                        \draw (1, 0) rectangle (2, -.5);
                        \draw (3.5, 0) rectangle (4, -.5);

                        \draw (1, 0) rectangle (5, -.5);

                        \node (t) at (-.3, -.25) {$t$};
                        \node (i) at (1, .3) {$i$};
                        \node at (3.5, .3) {$i + j$};
                        
                        \node at (3.75, -.25) {$c$};
                        
                        \node at (3.75, -.75) {$\neq$};
                        
                        \node at (4.5, -.25) {$u$};

                        \draw (3.5, -1) rectangle (4, -1.5);
                        \draw (1, -1) rectangle (5, -1.5);
                        \draw (2, -1) rectangle (2.5, -1.5);
                        
                        \node at (2.25, -1.25) {$c$};
                        \node at (4.5, -1.25) {$u$};
                        
                        \node at (3.5, -1.75) {$j$};
                    \end{tikzpicture}
                \end{center}

                On obtient un décalage négatif !
                Dans ce cas, on décale seulement d'un rang par sécurité.

                %Exemple ....

                Algorithme :

                \begin{pseudocode}
                    $i \leftarrow 0$ 

                    \begin{indt}{Tant que $i \le n - m$ :}
                        $j \leftarrow m - 1$
                        
                        \vspace{6pt}

                        \begin{indt}{Tant que $j \ge 0$ et $x_j = t_{i + j}$ :}
                            $j \leftarrow j + 1$
                        \end{indt}
                        
                        \vspace{6pt}

                        \begin{indt}{Si $j = -1$ :}
                            Occurrence de $x$ à la position $i$
                            
                            $i \leftarrow i + 1$
                        \end{indt}
                        
                        \vspace{6pt}

                        \begin{indt}{Sinon : }
                            $i \leftarrow i + \max(1,\ d(t_{i+j}) - (n - 1 - j))$
                        \end{indt}
                    \end{indt}
                \end{pseudocode}

                Complexité : dans le pire cas, $\mathcal O(nm)$ avec le même exemple qu'en \ref{1.2.2} (page \pageref{1.2.2}).
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Algorithme de \textsc{Boyer-Moore}}}
                La version complète de l'algorithme de \textsc{Boyer-Moore} utilise une seconde fonction de décalage.

                Celle de \ref{1.2.3} (page \pageref{1.2.3}) correspond à la règle du \textit{mauvais caractère} : si un caractère de la fenêtre fait échouer la comparaison avec le motif, on essaie de l'aligner avec sa dernière occurrence dans le motif (sauf la dernière lettre).

                Il y a aussi la règle du \textit{bon suffixe} : lorsqu'un caractère fait échouer la comparaison, on a réussi à lire un suffixe de $x$ dans la fenêtre. On peut essayer d'aligner ce suffixe dans le texte avec son occurrence la plus à droite dans $x$ à condition qu'elle soit précédée d'un caractère différent.

                \begin{center}
                    \begin{tikzpicture}
                        \draw (-1, 0) -- (7, 0);
                        \draw (-1, -.5) -- (7, -.5);

                        \node (t) at (-1.3, -.25) {$t$};

                        \draw (1, 0) rectangle (5, -.5);
                        \node at (1, .3) {$i$};

                        \draw (3, 0) rectangle (3.3, -.5);
                        \node at (3, .3) {$i + j$};

                        \node at (4.15, -.25) {$u$};

                        \node at (3.2, -.75) {$\neq$};

                        \draw (1, -1) rectangle (5, -1.5);
                        \draw (3, -1) rectangle (3.3, -1.5);
                        \node at (4, -1.25) {$u$};
                        
                        \draw (1.5, -1) rectangle (1.8, -1.5);
                        \node at (1.5, -.75) {$k$};
                        \node at (2.1, -1.25) {$u$};
                        \draw (2.4, -1) -- (2.4, -1.5);
                        
                        \node at (3, -1.8) {$j$};
                        
                        \draw[->] (1.6, -1.5) to [out=-45, in=-135, looseness=1] node [below] {$\neq$} (2.7, -1.5);
                        
                        \draw[->] (2, -2.4) to (4, -2.4);

                        \draw (2.5, -3) rectangle (6.5, -3.5);
                        \draw (4.5, -3) rectangle (4.8, -3.5);
                        \node at (5.5, -3.25) {$u$};
                        
                        \draw (3, -3) rectangle (3.3, -3.5);
                        \node at (3, -2.75) {$k$};
                        \node at (3.6, -3.25) {$u$};
                        \draw (3.9, -3) -- (3.9, -3.5);
                        
                        \node at (4.5, -2.75) {$j$};
                        
                        \draw[<->] (3.3, -4) to node [below] {$d_2(j)$} (6.5, -4);
                    \end{tikzpicture}
                \end{center}

                $d_2(j) =$ longueur du plus court suffixe de $x$ qui a $x_{j + 1} \ldots x_{m - 1}$ comme suffixe et préfixe et qui n'est pas précédé dans $x$ de $x_j$.

                Si un tel suffixe n'existe pas, on peut chercher le plus long suffixe de $u$ qui est préfixe de $x$ et l'aligner avec le $u$ de la fenêtre.
                
                \begin{center}
                    \begin{tikzpicture}
                        \draw (-1, 0) -- (8, 0);
                        \draw (-1, -.5) -- (8, -.5);

                        \node (t) at (-1.3, -.25) {$t$};

                        \draw (1, 0) rectangle (5, -.5);
                        \node at (1, .3) {$i$};

                        \draw (3, 0) rectangle (3.3, -.5);
                        \node at (3, .3) {$i + j$};

                        \node at (4.15, -.25) {$u$};

                        \node at (3.2, -.75) {$\neq$};

                        %---
                        \draw (1, -1) rectangle (5, -1.5);
                        \draw (3, -1) rectangle (3.3, -1.5);
                        \node at (4.15, -1.25) {$u$};
                        
                        \node at (3, -1.8) {$j$};
                        
                        \draw[dashed, color=ff4500] (.5, -1) rectangle (1.3, -1.5);
                        \node at (.75, -1.25) {\textcolor{ff4500}{$u$}};

                        %---
                        \draw (4, -2) rectangle (8, -2.5);
                        \draw (6, -2) rectangle (6.3, -2.5);
                        \node at (7.15, -2.25) {$u$};
                        
                        \node at (6, -2.8) {$j$};
                        
                        \draw[dashed, color=ff4500] (3.5, -2) rectangle (4.3, -2.5);
                        \node at (3.75, -2.25) {\textcolor{ff4500}{$u$}};
                        
                        \draw[<->] (3.5, -3) to node [below] {$d_2(j)$} (8, -3);
                    \end{tikzpicture}
                \end{center}

                $d_2(j) =$ longueur de plus court mot $w$ qui a $u$ comme préfixe et $x$ comme suffixe.

                Remarque : $\abs w \le \abs u + \abs x$.

                Remarque : $\forall j,\ d_2(j) \ge 1 + m - j - 1 = m - j$

                \vspace{12pt}
                
                L'algorithme de \textsc{Boyer-Moore} utilise le décalage maximal entre ceux calculés à partir de $d$ et $d_2$.

                Remarque : si on trouve une occurrence de $x$ ($u = x$), alors on tombe dans le deuxième cas du calcul de $d_2$ : on cherche le plus long suffixe de $x$ qui est aussi préfixe de $x$, que l'on appelle le \textit{bord} de $x$.

                Algorithme :

                \begin{pseudocode}
                    $i \leftarrow 0$

                    \begin{indt}{Tant que $i \le n + m$ :}
                        $j \leftarrow m - 1$
                        
                        \vspace{6pt}
                        
                        \begin{indt}{Tant que $j \ge 0$ et $x_j = t_{i + j}$ :}
                            $j \leftarrow j - 1$
                        \end{indt}
                        
                        \vspace{6pt}
                        
                        \begin{indt}{Si $j = -1$ :}
                            Occurrence de $x$ à la position $i$
                            
                            $i \leftarrow i + d_2(j) - m$
                        \end{indt}
                        
                        \vspace{6pt}
                        
                        \begin{indt}{Sinon :}
                            $i \leftarrow i + \max\!\lr{d(t_{i + j}) - (m - j - 1),\ d_2(j) - (m - j - 1)}$
                        \end{indt}
                    \end{indt}
                \end{pseudocode}

                \vspace{12pt}
                
                Exemple :

                \vspace{6pt}
                
                $x = aababab$

                \vspace{6pt}
                
                \begin{tabular}{r|cccccccc}
                    $j$ & $-1$ & 0 & 1 & 2 & 3 & 4 & 5 & 6
                    \\
                    \hline
                    $x$ & & $a$ & $a$ & $b$ & $a$ & $b$ & $a$ & $b$
                    \\
                    \hline
                    $d_2(j)$ & 14 & 13 & 12 & 6 & 10 & 6 & 8 & 1
                \end{tabular}

                \vspace{12pt}
                
                $
                    \begin{array}{rcccccccccccccccccc|}
                        t =
                        & a & a & b & b & b & a & b & a & b & a & c & a & a & b & b & a & b & a
                        \\
                        & a & a & b & \underset\times a & b & a & b &&&&&&&&&&&
                        \\
                        & &&&&&&& a & a & b & a & \underset \times b & a & b &&&&
                        \\
                        & &&&&&&&&&& & a & a & b & a & b & a & \underset \times b
                    \end{array}
                $

                \vspace{12pt}
                
                Complexité : on admet que $d_2$ peut être précalculée en temps $\mathcal O(n)$.
                Dans le pire des cas, la recherche est encore en $\mathcal O(mn)$ (exemple : $x = a^m$ et $t = a^n$)

                Remarque : il existe une version plus complexe avec un prétraitement qui permet une complexité $\mathcal O(n + m)$ (H.P).
            \end{indt}
        \end{indt}

        \vspace{12pt}
        
        \begin{indt}{\subsection{Algorithme de \textsc{Karp-Rabin}}}
            \begin{indt}{\subsubsection{Principe}}
                L'idée de l'algorithme de \textsc{Karp-Rabin} est d'éviter les comparaisons en temps linéaire entre le motif et le contenu d'une fenêtre en utilisant une fonction de hachage.
                On parle d'empreinte pour désigner le haché d'une fenêtre d'une chaîne de caractère par la fonction de hachage choisie et on compare les empreintes du motif et du contenu de la fenêtre. Pour contrer le problème des collisions, en cas d'égalité des empreintes, on compare aussi les deux chaînes de caractères.

                \vspace{12pt}
                
                Algorithme :

                Entrées :
                \begin{tabular}{r|l}
                    Texte & $t = t_0 \ldots t_{n - 1}$
                    \\
                    Motif & $x = x_0 \ldots x_{m - 1}$
                \end{tabular}
                (+ fonction de hachage $h$ choisie à l'avance)

                \begin{pseudocode}
                    $h_x \leftarrow h(x_0 \ldots x_{m - 1})$

                    $h_t \leftarrow h(t_0 \ldots t_{m - 1})$

                    \vspace{6pt}
                    
                    \begin{indt}{Pour $i$ de 0 à $n - m$ :}
                        \begin{indt}{Si $h_x = h_t$ et (paresseux) $x_0 \ldots x_{m - 1} = t_i \ldots t_{i + m - 1}$ :}
                            Occurrence de $x$ à la position $i$
                        \end{indt}

                        \vspace{6pt}
                        
                        \begin{indt}{Si $i < n - m$ :}
                            $h_t \leftarrow h(t_{i + 1} \ldots t_{i + m})$
                        \end{indt}
                    \end{indt}
                \end{pseudocode}
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Choix de la fonction de hachage}}
            
                Plusieurs contraintes :

                $\bullet$ On doit pouvoir comparer des empreintes en temps constant : en pratique, les empreintes sont des entiers machine, donc ce n'est pas un problème.

                $\bullet$ Il doit y avoir peu de collisions avec le haché du motif.

                $\bullet$ On doit pouvoir calculer l'empreinte de la fenêtre à l'itération suivante sans lire tous ses caractères (sinon on retrouve la complexité de l'algorithme naïf).

                On peut par exemple utiliser une fonction de hachage déroulante, \textit{i.e} une fonction $h$ telle qu'il est possible de calculer en temps constant $h(u_1 \ldots u_m)$ à partir de $h(u_0 \ldots u_{m - 1})$

                \begin{center}
                    \begin{tikzpicture}
                        \node (0) at (0, 0) {$u_0 u_1 \ldots u_{m - 1} u_m$};

                        \draw [decoration={brace, mirror, raise=-5pt, amplitude=5pt}, decorate] (-1.5, -.3) -- (1, -.3);
                        \draw [decoration={brace, mirror, raise=-3pt, amplitude=5pt}, decorate] (-1, -.4) -- (1.5, -.4);

                        \node (s) at (-1.5, -1) {$s$};
                        \node (s2) at (1.5, -1) {$s'$};

                        \draw[->] (-.275, -.3) -- (s);
                        \draw[->] (.275, -.5) -- (s2);

                        \node (h) at (-1.5, -2.5) {$h(s)$};
                        \node (h2) at (1.5, -2.5) {$h(s')$};

                        \draw[->] (s) -- (h);
                        \draw[->] (s2) -- (h2);

                        \draw[->] (h) to node [above] {$\delta(u_0, u_m)$} (h2);
                    \end{tikzpicture}
                \end{center}

                Exemple : on considère que les caractères sont codés sur un octet, \textit{i.e} on les assimiles à des entiers compris entre 0 et $r - 1$ (avec $r = 2^8$).
                On peut voir une chaîne de caractères de longueur $m$ comme l'écriture en base $r$ d'un entier compris entre 0 et $r^m - 1$.

                \vspace{12pt}
                
                $
                    P(u_0 \ldots u_{m - 1}) = \displaystyle
                    \sum_{i = 0}^{n - 1} u_i r^{m - 1 - i}
                    = u_0r^{m - 1} + u_1 r^{m - 2} + \cdots + u_{m - 1}
                $

                On choisit un nombre premier $p$ et on définit $h(u) = P(u) \mod p$

                \[
                    \begin{array}{rcl}
                        h(u_1 \cdots u_m)
                        &=& \displaystyle
                        \sum_{i = 1}^m u_i r^{m - 1 - i + 1} \mod p
                        \vspace{6pt}
                        \\
                        &=& \displaystyle
                        \lr{\sum_{i = 1}^{m - 1} u_i r^{m - i} + u_m} \mod p
                        \vspace{6pt}
                        \\
                        &=& \displaystyle
                        \lr{r\sum_{i = 1}^{m - 1} u_i r^{m - 1 - i} + u_m} \mod p
                        \vspace{6pt}
                        \\
                        &=& \displaystyle
                        \lr{r\lr{\sum_{i = 0}^{m - 1} u_i r^{m - 1 - i} - u_0 r^{m - 1}} + u_m} \mod p
                        \vspace{6pt}
                        \\
                        &=& \displaystyle
                        \lr{r\lr{h(u_0 \ldots u_{m - 1}) - u_0 r^{m - 1}} + u_m} \mod p
                    \end{array}
                \]
                
                Donc
                \[
                    \delta(u_0, u_m) : e \longmapsto \lr{r \lr{e - u_0 r^{m - 1}} + u_m} \mod p
                \]

                Remarque : si on précalcule $r^{m - 1}$ alors $\delta(u_0, u_m)$ est bien calculable en temps constant.

                Complexité du précalcul : $\mathcal O(\log m)$ avec l'exponentiation rapide (modulaire).
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Implémentation en OCaml}}
                \begin{lstlisting}[language=Caml, xleftmargin=80pt]
let hash (r : int) (p : int) (s : string) : int =
    let e = ref 0 in
    for i = 0 to String.length s - 1 do
        e := (r * !e + (Char.code s.[i])) mod p
        (*Schema de Horner*)
    done;
    !e;;

let delta (r : int) (p : int) (rm : int) (u0 : char) (um : char) (e : int) : int =
    (r * (e - (Char.code u0) * rm) + Char.code um) mod p;;

let harp_rabin (t : string) (x : string) : int list =
    let n = String.length t
    and m = String.length x in
    let l = ref [] in
    let r = 256
    and p = 0x7fffffff in (*p = 2^31 - 1*)
    let rm = fast_exp_mod r (m - 1) p in (*r^(m - 1) mod p*)
    let hx = hash r p x
    and e = ref (hash r p (String.sub 0 m t)) in

    for i = 0 to n - m do
        if hx = !e && x = String.sub i n t then
            l := i::!l;

        if i < n - m then
            e := delta r p rm t.[i] t.[i + m] !e
    done;
    !l\end{lstlisting}
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{\'Etude de la complexité}}
                \begin{indt}{$\bullet$ Complexité de l'initialisation :}
                    $-$ Complexité de $r_m$ (\texttt{rm}) : $\mathcal O(\log m)$

                    $-$ Calcul de $h_x$ et $e = h(t_0 \ldots t_{n - 1})$ : $\mathcal O(m)$

                    \vspace{6pt}
                    
                    $\rightarrow$ $\mathcal O(m)$ au total pour l'initialisation ;
                \end{indt}

                \vspace{12pt}
                
                \begin{indt}{$\bullet$ Complexité de la boucle :}
                    $-$ \`A chaque itération :  une comparaison et un calcul de delta en $\mathcal O(1)$ ;

                    $-$ En cas d'égalité d'empreintes : une extraction et une comparaison de chaîne de taille $m$ : $\mathcal O(m)$
                \end{indt}

                \vspace{12pt}
                
                Au total : $\mathcal O(m) + (n - m) \mathcal O(1) + \#\mathrm{collisions} \cdot \mathcal O(m) = \mathcal O(n + m \cdot \#\mathrm{collisions})$

                Avec $t = a^n$ et $x = a^m$, on a égalité à chaque itération et on obtient une complexité $\mathcal O((n - m)m)$.

                \vspace{6pt}
                
                Exemple de cas où le pire cas est atteint sans occurrence de $x$ dans $t$ :
                $x = aa$, $t = arar \ldots ar$, $p = 17$, $r = 26$.

                $h(aa) = 0 = h(ar) = h(ra)$.

                \vspace{12pt}
                
                Remarque : dans la publication de \textsc{Karp} et \textsc{Rabin}, l'idée est de choisir un nombre premier $p$ au hasard parmi un ensemble prédéfini pour limiter le risque de collisions.

                \vspace{12pt}
                
                Admis : si on choisit deux chaînes de taille $m$ aléatoirement, uniformément, la probabilité de collision avec la fonction de hachage choisie est de l'ordre de $\dfrac 1 p$ (qui est $< 10^{-9}$ si $p = 2^{31} - 1$)

                Attention, en pratique les chaînes étudiées ne sont pas du tout choisies uniformément.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Extension à la recherche de plusieurs motifs}}
                Même si cet algorithme est moins efficace que l'algorithme de \textsc{Boyer-Moore} pour la recherche d'un seul motif, il devient plus intéressant pour la recherche de plusieurs motifs car on peut l'adapter pour éviter de lancer une recherche par motif.

                En choisissant une structure d'ensemble adaptée, il est possible de vérifier en temps constant si l'empreinte d'une sous-chaîne est égale à l'empreinte de l'un des motifs (test d'appartenance).

                Il suffit de remplacer le test d'égalité par un test d'appartenance à l'ensemble des empreintes des motifs (précalculées) dans l'algorithme de \textsc{Karp-Rabin}
            \end{indt}
        \end{indt}
        
    \end{indt}

    \vspace{12pt}
    
    \begin{indt}{\section{Algorithmes de compression}}
        \begin{indt}{\subsection{Contexte}}
            \begin{indt}{\subsubsection{Principe}}
                On dispose d'un texte (en fait, d'un fichier, quel que soit son contenu, puisque c'est une séquence finie d'octets) et on souhaite réduire l'espace mémoire qu'il occupe \textit{via} un changement d'encodage.
                On s'intéresse ici à la compression sans perte, \textit{i.e} on doit pouvoir retrouver l'intégralité de l'information initiale à partir du texte compressé.

                Formellement, on note $\Sigma$ l'ensemble des symboles autorisés dans le texte, appelé alphabet (en pratique, $\Sigma = \set{0, 1}$), et $\Sigma^*$ l'ensemble des séquences finies d'éléments de $\Sigma$.
                On cherche alors une fonction de $\Sigma^*$ dans $\Sigma^*$, nommée \texttt{compression}, telle qu'il existe $\mathtt{decompression} : \Sigma^* \longrightarrow \Sigma^* \ |\ \forall t \in \Sigma^*, \mathtt{decompression}(\mathtt{compression}(t)) = t$
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Remarque}}
                On ne peut pas avoir $\forall t \in \Sigma^*,\ \abs{\mathtt{compression}(t)} < \abs t$.

                En effet, la condition $\mathtt{decompression} \circ \mathtt{compression} = \mathrm{id}$ impose que \texttt{compression} soit injective.
                Mais dans ce cas, on aurait une fonction injective de l'ensemble des textes d'une taille donnée vers l'ensemble des textes de taille strictement inférieure : impossible car le cardinal du second ensemble est strictement inférieur à celui du premier.

                Il existe donc toujours des textes dont la version compressée est plus grande que la version décompressée.

                L'important est alors de trouver des algorithmes qui compressent efficacement les textes qui sont pertinents pour l'utilisateur.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Algorithmes au programme}}
                On va étudier l'algorithme de \textsc{Huffman}, qui exploite des données sur la fréquence d'apparition des caractères dans le texte pour déterminer un encodage, et l'algorithme de \textsc{Lenpel-Ziv-Welch}, qui ne nécessite pas la connaissance de l'intégrité du texte pour calculer un encodage car il construit incrémentalement un dictionnaire de codes pour les motifs apparaissant dans le texte.
            \end{indt}
        \end{indt}

        \vspace{12pt}
        
        \begin{indt}{\subsection{Algorithme de \textsc{Huffman}}}
            \begin{indt}{\subsubsection{Principe}}
                L'idée principale de cet algorithme est d'associer un code plus court aux caractères les plus fréquents pour diminuer la taille du texte.

                \vspace{12pt}
                
                Exemple : \texttt{abaabc} nécessite 12 bits avec un code de taille fixe (3 lettres avec 2 bits par caractère) mais seulement 9 bits avec un code de taille variable (ex : \texttt a = 0, \texttt b = 10, \texttt c = 11).

                \vspace{6pt}
                
                Remarque : pour pouvoir décompresser sans ambiguïté un encodage de taille variable, one ne peut pas encoder un caractère avec un préfixe du code d'un autre caractère. On appelle cela un \textit{code préfixe}.

                L'algorithme de \textsc{Huffman} est un algorithme qui, étant donné un texte, produit un code préfixe optimal pour la compression de ce texte, en termes de la taille du texte compressé.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Représentation de l'encodage des symboles}}
                \label{2.2.2}

                On s'intéresse uniquement à des encodages binaires.
                
                Un code préfixe binaire peut être représenté à l'aide d'un arbre binaire (strict) : dans cet arbre, les caractères sont placés aux feuilles, et le chemin de la racine vers une feuille donne le code du caractère correspondant (descendre à gauche correspond au bit 0, et descendre à droite au bit 1).

                \vspace{12pt}
                
                Exemple : le code
                \begin{tabular}{|c|c|c|}
                    \hline
                    $a$ & $b$ & $c$
                    \\
                    \hline
                    0 & 10 & 11
                    \\
                    \hline
                \end{tabular}
                est représenté par :

                \begin{center}
                    \begin{tikzpicture}
                        \node {$\bullet$}
                            child {node {$a$}}
                            child {node {$\bullet$}
                                child {node {$b$}}
                                child {node {$c$}}
                            }
                        ;
                    \end{tikzpicture}
                \end{center}

                Autre exemple :
                \begin{center}
                    \begin{tabular}{cp{100pt}}
                        \begin{tikzpicture}
                            \node {$\bullet$}
                                child {node [xshift=-10pt] {$\bullet$}
                                    child {node {$a$}}
                                    child {node {$b$}}
                                }
                                child {node [xshift=10pt] {$\bullet$}
                                    child {node {$c$}}
                                    child {node {$d$}}
                                }
                            ;
                        \end{tikzpicture}
                        &
                        \vspace{-60pt}
                        \begin{tabular}{|c|c|c|c|}
                            \hline
                            $a$ & $b$ & $c$ & $d$
                            \\
                            \hline
                            00 & 01 & 10 & 11
                            \\
                            \hline
                        \end{tabular}
                    \end{tabular}
                \end{center}
                
                \vspace{12pt}
                
                \begin{center}
                    \begin{tikzpicture}
                        \node at (0, 0) {$\bullet$}
                            child {node [xshift=-20pt] {$\bullet$}
                                child {node {$\bullet$}}
                                child {node {$\bullet$}}
                            }
                            child {node [xshift=20pt, circle, draw, color=ff4500] {}
                                child {node [xshift=20pt] {$\bullet$}
                                    child {node {$\bullet$}}
                                    child {node {$\bullet$}}
                                }
                            }
                        ;
                        
                        \draw[->] (2.5, -2) -- (3.5, -2);
                        
                        \node at (6, 0) {$\bullet$}
                            child {node [xshift=-20pt] {$\bullet$}
                                child {node {$\bullet$}}
                                child {node {$\bullet$}}
                            }
                            child {node [xshift=20pt] {$\bullet$}
                                child {node {$\bullet$}}
                                child {node {$\bullet$}}
                            }
                        ;
                    \end{tikzpicture}
                \end{center}

                Pour avoir un code optimal, l'arbre doit être binaire strict.

                \vspace{12pt}
                
                Remarque : la longueur du code d'un caractère est la profondeur de la feuille correspondante dans l'arbre représentant l'encodage. Déterminer un code préfixe optimal revient à chercher un minimum pour
                \[
                    \varphi(t) = \sum_{x \in \mathrm{feuilles}(t)} f(x) \cdot p(x, t)
                \]
                où $p(x, t)$ est la profondeur de la feuille $x$ dans l'arbre $t$, et $f(x)$ est la fréquence du caractère $x$ dans le texte.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Encodage et décodage}}
                On considère un arbre binaire $t$ représentant un code préfixe et on suppose que l'on travaille sur l'alphabet des octets (type \texttt{char}).

                \vspace{6pt}
                
                $\bullet$ Pour décoder une séquence de bits, il suffit de descendre dans l'arbre selon les bits lus et, lorsque l'on atteint une feuille, de produire le caractère correspondant et de poursuivre la lecture en repartant de la racine.

                \vspace{6pt}
                
                Code (on représente un bit par un booléen (0 : \texttt{false}, 1 : \texttt{true})) :
                
                \vspace{12pt}

                \begin{lstlisting}[language=Caml, xleftmargin=80pt]
type arbre =
    | Feuille of char
    | Noeud of arbre*arbre\end{lstlisting}
                
                \newpage
                
                \begin{lstlisting}[language=Caml, xleftmargin=80pt]
let decode (l : bool list) (t : arbre) : char list =
    let rec aux (l : bool list) (a : arbre) : char list =
        match l, a with
        | _, Feuille c -> c :: aux l t
        | [], _ -> [] (*match order is important here*)
        | b::q, Noeud(g, d) -> if b then aux q d else aux q g
    in aux l t\end{lstlisting}

                Complexité : $\mathcal O(\text{nombre de bits dans le texte compressé})$.

                \vspace{12pt}
                
                $\bullet$ Pour encoder un texte, étant donné un arbre représentant un encodage pour chacun des caractères du texte, on ne veut pas parcourir l'arbre à chaque caractère pour déterminer son code. On calcule d'abord une table d'encodage associant à chaque caractère son code. On peut la calculer avec un unique parcours de l'arbre :

                \begin{lstlisting}[language=Caml, xleftmargin=80pt]
let codes (t : arbre) : bool list array =
    let a = Array.make 256 [] in (*on travaille sur les octets*)
    let rec aux (t : arbre) (acc : bool list) : unit =
        match t with
        | Feuille c -> a.(Char.code c) <- List.rev acc
        | Noeud(g, d) -> aux g (false::acc) ; aux d (true::acc)
    in aux t [];
    a\end{lstlisting}

                Complexité : chaque n\oe ud interne est traité en $\mathcal O(1)$, et chaque feuille $x$ en $\mathcal O(p(x ,t))$.

                En notant $n$ le nombre de caractères encodés ($n \le \abs \Sigma$), il y a $n$ feuilles, et $n - 1$ n\oe uds internes car l'arbre est binaire strict (\textit{cf} chapitre 6,  §1.1.10). La hauteur de l'arbre est comprise entre $\ceil{\log_2(n)}$ et $n$.

                Donc la complexité est en $\Omega(n\log n)$ et $\mathcal O(n^2)$.

                \vspace{6pt}
                
                Une fois la table d'encodage calculée, il suffit de remplacer chaque caractère par son code :

                \begin{lstlisting}[language=Caml, xleftmargin=80pt]
let encode (l : char list) (t : arbre) : bool list =
    let a = codes t in
    List.flatten (List.map (fun c -> a.(Char.code c)) l)\end{lstlisting}
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Arbre de \textsc{Huffman}}}
                Il reste à déterminer comment calculer un arbre représentant un code préfixe adapté à la compression d'un texte donné.
                L'algorithme de \textsc{Huffman} est un algorithme glouton déterminant un arbre optimal.

                Cet algorithme part d'une forêt de feuilles et les fusionne deux à deux jusqu'à l'obtention d'un unique arbre.
                La fusion de deux arbres la construction d'un nouveau n\oe ud dont les deux arbres sont les fils.
                
                \vspace{12pt}

                Exemple :
                
                \begin{center}
                    \begin{tikzpicture}
                        \node at (-.35, 0) {$a$};
                        \node at (.35, 0) {$b$};
                        \node at (1, 0) {$c$};
                        
                        \draw[->] (1.5, 0) -- (2.5, 0);
                        
                        \node at (3, 0) {$a$};
                        
                        \node at (4.1, .75) {$\bullet$}
                            child {node {$b$}}
                            child {node {$c$}}
                        ;
                        
                        \draw[->] (5, 0) -- (6, 0);
                        
                        \node at (7.5, 1.8) {$\bullet$}
                            child {node {$a$}}
                            child {node {$\bullet$}
                                child {node {$b$}}
                                child {node {$c$}}
                            }
                        ;
                    \end{tikzpicture}
                \end{center}

                L'idée du choix glouton est la suivante : la fusion incrémente la longueur du code des feuilles des deux arbres concernés donc les arbres contenant les caractères les moins fréquents doivent subir le plus de fusion donc être fusionnés en priorité.

                On généralise la fonction $f$ de \ref{2.2.2} (page \pageref{2.2.2}) aux arbres en définissant :
                \[
                    f(t) = \sum_{x \in \mathrm{feuilles}(t)} f(x)
                \]

                L'algorithme de \textsc{Huffman} s'écrit alors ainsi :

                Entrée : texte $s$

                \begin{pseudocode}
                    $\mathtt{occ} \leftarrow$ table des occurrences des caractères de $s$

                    $F \leftarrow$ ensemble des Feuille $c$ où $c$ est tel que $\mathtt{occ}(c) > 0$

                    \vspace{6pt}
                    
                    \begin{indt}{Tant que $\abs F \ge 2$ :}
                        Extraire $t_1$ de $F$ tel que $f(t_1)$ est minimale

                        Extraire $t_2$ de $F$ tel que $f(t_2)$ est minimale

                        $F \leftarrow F \cup \set{\mathtt{fusion}(t_1, t_2)}$
                    \end{indt}

                    \vspace{6pt}
                    
                    Renvoyer l'unique élément de $F$
                \end{pseudocode}

                \vspace{6pt}
                
                Implémentation : la forêt $F$ se comporte comme une file de priorité min où la priorité d'un arbre $t$ est $f(t)$.

                \begin{indt}{On suppose donné un type \texttt{fp} associé aux primitives suivantes :}
                    $-$ \texttt{create : unit -> fp} qui crée une file de priorité vide ;

                    $-$ \texttt{add : arbre -> int -> fp -> unit} qui insère un arbre avec la priorité (entière) donnée dans la file ;

                    $-$ \texttt{take\_min : fp -> arbre*int} qui extrait un arbre de priorité min et qui renvoie aussi sa priorité ;

                    $-$ \texttt{size : fp -> int} qui renvoie la taille de la file
                \end{indt}

                \begin{lstlisting}[language=Caml, xleftmargin=80pt]
let huffmann (s : char list) : arbre =
    let occ = Array.make 256 0 in (*On travaille sur des octets*)
    List.iter (fun c -> occ.(Char.code c) <- 1 + occ.(Char.code c)) s;
    let f = create () in
    for i = 0 to 255 do
        if occ.(i) <> 0 then
            add (Feuille (Char.chr i)) occ.(i) f
    done;
    while size f > 1 do
        let t1, f1 = take_min f in
        let t2, f2 = take_min f in
        add (Noeud(t1, t2)) (f1 + f2) f
    done;
    fst (take_min f)\end{lstlisting}

                Complexité : on note $n(s)$ le nombre de caractères distincts de $s$

                \vspace{6pt}
                
                $\bullet$ Le comptage des occurrences : $\mathcal O(\abs s)$

                $\bullet$ Création de la file : avec une implémentation par tas : $\mathcal O\!\lr{n(s) \log(n(s))}$ (insertion en $\mathcal O(\log(n(s)))$)

                $\bullet$ Une itération de la boucle : $\mathcal O(\log(n(s)))$.

                Il y a $\mathcal O(n(s))$ itérations.

                Au total : $\mathcal O(\abs s + n(s)\log(n(s))) = \mathcal O(\abs s)$ car $n(s) \le 256$ car on travaille sur des octets.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Optimalité de l'arbre de \textsc{Huffman}}}
                Rappel : on cherche à trouver un arbre $t$ minimisant
                \[
                    \varphi(t) = \displaystyle \sum_{x \in \mathrm{feuille}(t)} f(x) p(x, t)
                \]
                où $f(x)$ est la fréquence d'apparition de $x$ dans le texte et $p(x, t)$ la profondeur de $x$ dans $t$.
                On généralise $f$ aux arbres par
                \[
                    f(t) = \sum_{x \in \mathrm{feuille}(t)} f(x)
                \]
                et on généralise $\varphi$ aux forêts par
                \[
                    \varphi(F) = \sum_{t \in F} \varphi(t)
                \]

                \vspace{6pt}
                
                \begin{pseudocode}
                    \textit{Lemme} :
                    en notant $F'$ la forêt obtenue après un tour de boucle appliquée à $F$, \textit{i.e}
                    $F' = (F \setminus \set{t_1, t_2}) \cup \set{\mathrm{Noeud}(t_1, t_2)}$
                    où $t_1$ et $t_2$ sont deux éléments de $F$ qui minimisent $f$, on a :
                    \[
                        \varphi(F') = \varphi(F) + f(t_1) + f(t_2)
                    \]
                \end{pseudocode}

                \vspace{12pt}
                
                \begin{indt}{$\square$ Démonstration :}
                    On a :
                    \[
                        \begin{array}{rcl}
                            \varphi(F')
                            &=&
                            \displaystyle
                            \sum_{t \in F'} \varphi(t)
                            \vspace{6pt}
                            \\
                            &=& \displaystyle
                            \underbrace{\sum_{t \in F} \varphi(t)}_{\varphi(F)}
                            - \varphi(t_1) - \varphi(t_2)
                            + \varphi(\mathrm{Noeud}(t_1, t_2))
                        \end{array}
                    \]

                    Or
                    \[
                        \begin{array}{rcl}
                            && \varphi(\mathrm{Noeud}(t_1, t_2))
                            \vspace{6pt}
                            \\
                            &=& \displaystyle
                            \sum_{\substack{x \in \mathrm{feuille}(t_1) \cup \mathrm{feuille}(t_2)}} f(x) p(x, \mathrm{Noeud}(t_1, t_2))
                            \vspace{12pt}
                            \\
                            &=& \displaystyle
                            \underbrace{\sum_{x \in \mathrm{feuilles}(t_1)} f(x)
                            \underbrace{p(x, \mathrm{Noeud}(t_1, t_2))}_{1 + p(x, t_1)}}_{
                                \displaystyle
                                \underbrace{\sum_{x \in \mathrm{feuilles}(t_1)} f(x)}_{f(t_1)}
                                + \underbrace{\sum_{x \in \mathrm{feuilles}(t_1)} f(x) p(x, t_1)}_{\varphi(t_1)}
                            }
                            +
                            \underbrace{\sum_{x \in \mathrm{feuilles}(t_2)} f(x) p(x, \mathrm{Noeud}(t_1, t_2))}_{f(t_2) + \varphi(t_2)}
                        \end{array}
                    \]

                    d'où $\varphi(F') = \varphi(F) + f(t_1) + f(t_2)$ $\blacksquare$
                \end{indt}

                \vspace{12pt}
                
                \begin{pseudocode}
                    \textit{Proposition} :
                    Si les lettres les moins fréquentes sont $a$ et $b$, alors il existe un arbre optimal tel que les feuilles associées à $a$ et $b$ sont s\oe urs dans l'arbre et de profondeur maximale.
                \end{pseudocode}
                
                \vspace{6pt}

                \begin{indt}{$\square$ Démonstration :}
                    On considère un arbre optimal $t_{\mathrm{opt}}$ et on note $c$ et $d$ deux feuilles s\oe urs de profondeur maximale dans $t_{\rm opt}$ (possible car $t_{\rm opt}$ est binaire \textit{strict}).

                    Sans perte de généralité, on suppose
                    $f(a) \le f(b)$ et
                    $f(c) \le f(d)$.

                    Par définition de $a$ et $b$, on sait que
                    $f(a) \le f(c)$ et
                    $f(b) \le f(d)$

                    En échangeant dans $t_{\rm opt}$ la feuille $a$ et $c$, on obtient $t$ tel que
                    \[
                        \begin{array}{rcl}
                            \varphi(t)
                            &=&
                            \varphi(t_{\rm opt})
                            - f(a) p(a, t_{\rm opt})
                            - f(c) p(c, t_{\rm opt})
                            + f(a) p(c, t_{\rm opt})
                            + f(c) p(a, t_{\rm opt})
                            \vspace{6pt}
                            \\
                            &=&
                            \varphi(t_{\rm opt})
                            + \underbrace{(f(a) - f(c))}_{\le 0}
                            \underbrace{(p(c, t_{\rm opt}) - p(a, t_{\rm opt}))}_{\ge 0}
                        \end{array}
                    \]

                    Donc $\varphi(t) \le \varphi(t_{\rm opt})$.

                    En échangeant de même les feuilles $b$ et $d$ dans $t$, on obtient $t'$ avec $a$ et $b$ feuilles s\oe urs de profondeur maximale et telles que
                    $\varphi(t') \le \varphi(t) \le \varphi(t_{\rm opt})$
                    donc telle que $t'$ est optimal. $\blacksquare$
                \end{indt}

                \vspace{12pt}
                
                \begin{pseudocode}
                    \textit{Théorème} :
                    l'algorithme de \textsc{Huffman} renvoie un arbre optimal.
                \end{pseudocode}

                \vspace{12pt}
                
                \begin{indt}{$\square$ Démonstration :}
                    On procède par récurrence sur le nombre de caractères distincts dans le texte :

                    $-$ Si le texte est écrit à l'aide d'un unique caractère, il n'y a qu'un seul arbre possible donc l'algorithme est optimal.

                    $-$ Si l'algorithme est optimal pour les textes à $n$ caractères distincts, considérons un texte à $n + 1 \ge 2$ caractères distincts.
                    Notons $a$ et $b$ les deux caractères les moins fréquents dans le texte.

                    La première étape de l'algorithme de \textsc{Huffman} consiste à fuisonner les feuilles associées à $a$ et $b$.
                    Cela revient à considérer un nouveau texte où $a$ et $b$ sont remplacés par un nouveau caractère $z$ dont la fréquence d'apparition est donc $f(a) + f(b) = f(\mathrm{Noeud}(a, b))$.

                    Ce nouveau texte ayant $n$ caractères distincts, on sait que l'algorithme de \textsc{Huffman} produit un arbre $t_{\rm opt}$ optimal pour ce texte par hypothèse de récurrence.

                    L'arbre obtenu par l'algorithme de \textsc{Huffman} pour le texte initial est $t_{\rm opt}$ où la feuille associée à $z$ est remplacée par le $\mathrm{Noeud}(a, b)$.
                    \[
                        \begin{array}{rcl}
                            \varphi(t)
                            &=& \displaystyle
                            \varphi(t_{\rm opt})
                            + f(a)
                            + f(b)
                        \end{array}
                    \]
                    (même démonstration que le lemme)

                    On sait qu'il existe une solution optimale $t_{\rm opt}$ telle que $a$ et $b$ sont des feuilles s\oe urs de profondeur maximale.

                    On construit $t'$ en remplaçant dans $t_{\rm opt}$ $\mathrm{Noeud}(a, b)$ par $\mathrm{Feuille}(z)$.

                    Donc
                    $
                        \varphi(t_{\rm opt})
                        =
                        \varphi(t') + f(a) + f(b)
                        \underset{\text{de}\ t_{\rm opt}}{\overset{\text{optimalité}}{\ge}
}
                        \varphi(t_{\rm opt}) + f(a) + f(b)
                        =
                        \varphi(t)
                    $, et ainsi $t$ est optimal $\blacksquare$
                \end{indt}
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Aspects pratiques}}
                $\bullet$ Lectures / écritures : en pratique, on lit et on écrit dans un fichier octet par octet.
                Or le codage calculé par l'algorithme de \textsc{Huffman} n'est pas de taille fixe, donc on aurait plutôt besoin de lire / écrire bit par bit.

                Une solution simple pour l'écriture consiste à accumuler les bits en attendant d'en avoir assez.
                Il suffit d'un entier pour implémenter cet accumulateur :
                si $n = \lrangle{b_1 \ldots b_k}_2$ avec $k < 8$, on peut ajouter le bit $b_{k + 1}$ en calculant
                $
                    \lrangle{b_1 \ldots b_k b_{k + 1}}_2
                    = 2\lrangle{b_1 \ldots b_k}_2
                    + b_{k + 1}
                    = 2n + b_{k + 1}
                $

                \vspace{6pt}
                
                Problème s'il n'y a pas assez de bits pour construire un octet en fin de fichier.

                Solution : on complète avec des $0$ à la fin pour finir l'octet (cela s'appelle du \textit{padding}).

                \vspace{6pt}
                
                Problème : comment ne pas confondre ces $0$ avec le code d'un caractère ?

                Solution : on ajoute un octet supplémentaire en fin de fichier qui représente le nombre de $0$ ajoutés.

                \vspace{6pt}
                
                Pour la décompression, il faut déterminer quand on arrive à l'avant-dernier octet pour savoir qu'il faut lire l'octet suivant afin de connaître le nombre de $0$ à ignorer dans cet avant-dernier octet.

                Pour cela, on peut lire le fichier avec 2 octets d'avance pour repérer la fin du fichier, ou alors on peut déterminer à l'avance la taille du fichier et compter le nombre d'octets lus.

                \vspace{12pt}
                
                $\bullet$ Stockage de l'arbre : la connaissance de l'arbre de \textsc{Huffman} est nécessaire pour pouvoir décompresser le fichier. Il faut donc pouvoir le stocker sous la forme d'un fichier, qui sera transmis avec le fichier compressé.

                La transformation de l'arbre en fichier s'appelle \textit{sérialisation de l'arbre}.
                Comme l'arbre de \textsc{Huffman} est binaire strict, il est aisé de la sérialiser : on définit $\mathrm{repr}(t)$ par induction structurelle sur $t$ :
                \[
                    \mathrm{repr}(\mathrm{Feuille c}) = 0 \underbrace{\mathrm{code}(c)}_{\text{octet représentant $c$}}
                \]
                \[
                    \mathrm{repr}(\mathrm{Noeud}(g, d)) = 1 \mathrm{repr}(g) \mathrm{repr}(d)
                \]
                
                \vspace{6pt}

                \begin{lstlisting}[language=Caml, xleftmargin=80pt]
let rec output_tree (f : out_channel) (t : arbre) : unit =
    match t with
    | Feuille c ->
        output_byte f 0;
        output_byte f (Char.code c)
    | Noeud(g, d) ->
        output_byte f 1;
        out_tree f g;
        output_tree f d

let rec input_tree (f : in_channel) : arbre =
    match input_byte f with
    | 0 -> Feuille (Char.chr (input_byte f))
    | _ ->
        let g = input_tree f in
        let d = input_tree f in
        Noeud(g, f)\end{lstlisting}

                Remarque : la sérialisation est bien sûr plus générale que son application aux arbres binaires.

                Contrainte importante : il faut connaître \textit{a priori} l'encodage utilisé dans la sérialisation pour être capable de désérialiser.

                Il existe des formats standards pour la sérialisation, qui peuvent être génériques, par exemple le format JSON, ou bien dédiés à certaines applications, comme le format DIMACS CNF ou le language DOT pour représenter les graphes.

                Exemple pour le language DOT :

                \begin{lstlisting}[xleftmargin=80pt]
graph G {
    a -- b -- c;
    a -- d;
}\end{lstlisting}
                
                \begin{center}
                    \begin{tikzpicture}
                        \node [circle, draw] {a}
                            child {node [circle, draw] {b}
                                child {node [circle, draw] {c}}
                            }
                            child {node [circle, draw] {d}}
                        ;
                    \end{tikzpicture}
                \end{center}
            \end{indt}
        \end{indt}

        \vspace{12pt}
        
        \begin{indt}{\subsection{Algorithme de \textsc{Lempel-Ziv-Welch} (LZW)}}
            \begin{indt}{\subsubsection{Introduction}}
                L'algorithme de \textsc{Huffman} a deux inconvénients principaux : il est nécessaire de connaître à l'avance l'intégrité du texte pour construire l'encodage, et le texte compressé seul ne suffit pas pour effectuer la décompression : il est nécessaire de l'accompagner par un fichier représentant l'arbre d'encodage.
                L'algorithme de LZW répond à ces deux problèmes : il est possible de compresser un flux de données \textit{via} la construction incrémentale d'un dictionnaire de codes pour les motifs apparaissant dans le texte, et il n'y a pas besoin d'informations supplémentaires pour décompresser car il est possible de reconstruire le dictionnaire à la volée lors de la lecture du flux compressé.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Principe}}
                On construit incrémentalement le dictionnaire en garantissant que pour chaque motif introduit, tous ses préfixes sont déjà présents dans le dictionnaire.
                En particulier, le dictionnaire est initialisé en stockant un code pour chaque caractère possible (\textit{via} la table ASCII). Les codes choisis pour les motifs sont consécutifs et ne dépendent que de l'ordre d'apparition des motifs dans le texte.
                C'est ce qui permet de reconstruire le dictionnaire lors de la décompression en fonction de l'ordre d'apparition des codes.
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Compression}}
                On note $t_0 \ldots t_{n - 1}$ le texte.

                \begin{pseudocode}
                    $d \leftarrow$ dictionnaire construit à partir de la table ASCII (entier entre 0 et 255 associé à chaque caractère, \textit{i.e} octet possible)

                    $m \leftarrow t_0$

                    \vspace{6pt}
                    
                    \begin{indt}{Pour $i$ de 1 à $ n - 1$ :}
                        \begin{indt}{Si $d(m t_i)$ est défini :}
                            $m \leftarrow m t_i$
                        \end{indt}

                        \vspace{6pt}
                        
                        \begin{indt}{Sinon :}
                            Produire $d(m)$ en sortie

                            Ajouter $m t_i$ à $d$ (avec le dernier code dans $d$ plus 1)

                            $m \leftarrow t_i$
                        \end{indt}
                    \end{indt}

                    \vspace{6pt}
                    
                    Produire $d(m)$ en sortie
                \end{pseudocode}

                \vspace{12pt}
                
                Exemple :

                $t = aababaaab$.
                Rappel : table ASCII :
                \begin{tabular}{|c|c|c|c|}
                    \hline
                    $a$ & $b$ & $\cdots$ & $z$
                    \\
                    \hline
                    97 & 98 & $\cdots$ & 122
                    \\
                    \hline
                \end{tabular}

                \vspace{6pt}
                
                \begin{tabular}{r|ccccccccc}
                    $i$ & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8
                    \\
                    $m$ & $a$ & $a$ & $b$ & $a$ & $ab$ & $a$ & $aa$ & $a$ & $ab$
                    \\
                    Sortie & 97 & 97 & 98 & & 257 & & 256 & & 257
                \end{tabular}

                Dictionnaire : $\set{(aa, 256), (ab, 257), (ba, 258), (aba, 259), (aaa, 260)}$

                \vspace{6pt}
                
                Attention : ce n'est pas un code préfixe, donc les code doivent être de taille fixe pour permettre la décompression.

                Problème : si tous les codes sont sur $k$ bits, le dictionnaire peut contenir au plus $2^k$ entrées, donc il y a un risque de saturation.

                \vspace{6pt}
                
                \begin{indt}{Pour résoudre ce problème, il y a plusieurs options :}
                    $-$ On efface le dictionnaire lorsqu'il arrive à saturation et on repart de zéro comme si on travaillait sur un nouveau fichier. On produit un code spécial pour signaler l'effacement.
                    Un code pet donc représenter plusieurs motifs selon sa position dans le texte compressé.

                    $-$ On ajoute un bit aux codes, ce qui revient à doubler la taille du dictionnaire (comme un tableau dynamique). Comme l'algorithme de décompression reconstruit incrémentalement le dictionnaire, la saturation est détectée et on sait quand il faut lire des codes de taille $k + 1$.
                \end{indt}
            \end{indt}

            \vspace{12pt}
            
            \begin{indt}{\subsubsection{Décompression}}
                On reconstruit le dictionnaire en parallèle de la lecture des codes.

                Le premier code est nécessairement le code ASCII du premier caractère du fichier.
                Pour les codes suivants, on a besoin de se souvenir du dernier code lu : notons $c_0$ le dernier code lu, et $c_1$ le code en cours de lecture. Le code $c_1$ correspond à un mot de la forme $xs$, où $x$ est un caractère, et $s$ un mot potentiellement vide, et $c_0$ correspond à un certain mot $u$.
                Au moment de la production de $c_0$, le motif $m$ vaut $u$ et est remplacé par le caractère $t_i$ au cours de la lecture.
                Comme ce caractère est le premier du motif associé au prochain code produit, \textit{i.e} $c_1$, on sait que $t_i = x$.
                On sait alors que le motif $ux$ doit être inséré dans le dictionnaire.
                Ainsi, on effectue les mêmes opérations sur le dictionnaire que l'algorithme de compression, mais avec un temps de retard.

                \vspace{12pt}
                
                Exemple :

                \begin{tabular}{r|cccccc}
                    & 97 & 97 & 98 & 257 & 256 & 257
                    \\
                    $i$ & 0 & 1 & 2 & 3 & 4 & 5
                    \\
                    $u$ & $a$ & $a$ & $b$ & $ab$ & $aa$ & $ab$
                \end{tabular}

                \vspace{6pt}
                
                \begin{tabular}{lcl}
                    Sortie &:& $aababaaab$
                    \\
                    Dictionnaire &:& $\set{(aa, 256), (ab, 257), (ba, 258), (aba, 259), (aaa, 260)}$
                \end{tabular}

                \vspace{18pt}
                
                Problème : comme on construit le dictionnaire avec un temps de retard, il est possible que le dernier code lu ne soit pas encore dans le dictionnaire.

                \vspace{12pt}
                
                Exemple : $t = aaa$

                \begin{tabular}{ccc}
                    \begin{tabular}{r|ccc}
                        $i$ & 0 & 1 & 2
                        \\
                        $m$ & $a$ & $a$ & $aa$
                        \\
                        Sortie & 97 & & 256
                    \end{tabular}
                    &&
                    Dictionnaire : $\set{(aa, 256)}$
                \end{tabular}

                \newpage
                
                Décompression :

                \begin{tabular}{ccp{200pt}}
                    \begin{tabular}{r|cc}
                        & 97 & 256
                        \\
                        $i$ & 0 & 1
                        \\
                        $u$ & $a$
                    \end{tabular}
                    &&
                    Sortie : $a?$
                    \newline
                    Dictionnaire : $\varnothing$ (la table ASCII)
                \end{tabular}

                \vspace{12pt}
                
                Remarque : le code qui pose problème vaut nécessairement la taille du dictionnaire, donc correspond au dernier code inséré dans le dictionnaire par l'algorithme de compression à ce stade de la lecture.

                Solution : en reprenant les notations précédentes, $c_1 = \abs d$ est le code inséré dans le dictionnaire par l'algorithme de compression au moment de la production de $c_0$. Donc le motif associé à $c_1$ s'écrit $ux$ où $u$ est associé à $c_0$ et $x$ est la lettre lue à ce moment.
                Or, comme l'algorithme de compression repart du motif $m = x$ au moment de la production de $c_0$, $x$ est la première lettre du motif associé à $c_1$, \textit{i.e} $ux$.
                Comme $u$ est non vide, $x$ est donc aussi la première lettre de $u$ et on peut reconstruire le motif $ux$ associé à $c_1$.

                \vspace{12pt}
                
                Algorithme (code $c_0 \ldots c_{m - 1}$) :

                \begin{pseudocode}
                    $d \leftarrow$ dictionnaire construit à partir de la table ASCII

                    Produire $d(c_0)$ en sortie

                    \vspace{6pt}
                    
                    \begin{indt}{Pour $i$ de 1 à $m - 1$ :}
                        \begin{indt}{Si $c_i < \abs d$ :}
                            Produire $d(c_i)$ en sortie

                            $x \leftarrow$ première lettre de $d(c_i)$
                        \end{indt}

                        \vspace{6pt}
                        
                        \begin{indt}{Sinon (on sait que $c_i = \abs d$) :}
                            $x \leftarrow$ première lettre de $d(c_{i - 1})$

                            Produire $d(c_{i - 1}) x$ en sortie
                        \end{indt}

                        \vspace{6pt}
                        
                        Ajouter $d(c_{i - 1})x$ au dictionnaire
                    \end{indt}
                \end{pseudocode}
            \end{indt}
        \end{indt}
    \end{indt}
    
    
    
\end{document}
%--------------------------------------------End
